# ChatGPT, GenerativeAI and LLMs Timeline 

This repository organizes a timeline of key events (products, services, papers, GitHub, blog posts and news) that occurred before and after the ChatGPT announcement. 

It's curating a variety of information in this timeline, with a particular focus on LLM and Generative AI. 

Maybe it's a scene from the hottest history, so I thought it would be important to keep those memories well, so I organized them.

## Contributing

Issues and Pull Requests are greatly appreciated. If you've never contributed to an open source project before I'm more than happy to walk you through how to create a pull request.

You can start by [opening an issue](https://github.com/hollobit/BCAC_timeline/issues/new) describing the problem that you're looking to resolve and we'll go from there.

## Emoji 

arXiv :x:, PDF :paperclip:, arxiv-vanity :orange_book:, paper page :house:, papers with code :eight_spoked_asterisk:, Github :octocat:

## License

This document is licensed under the [MIT license](https://opensource.org/licenses/mit-license.php) © Jonghong Jeon

|	Date	|	Announcement	|
|:-:|:--|
| 7.1 | The Rise of the AI Engineer ([Blog](https://www.latent.space/p/ai-engineer)) |  
| 6.30 | Doctor Chatbot: The EUʼs Regulatory Prescription for Generative Medical AI (Oslo Law Review, [https://doi.org/10.18261/olr.10.1.1](https://www.idunn.no/doi/10.18261/olr.10.1.1)), ([PDF](https://www.idunn.no/doi/epdf/10.18261/olr.10.1.1)) |
| 6.30 | Reliability of Medical Information Provided by ChatGPT: Assessment Against Clinical Guidelines and Patient Information Quality Instrument (JMIR, [doi: 10.2196/47479](https://www.jmir.org/2023/1/e47479)), ([PDF](https://www.jmir.org/2023/1/e47479/PDF)) |
| 6.30 | Large language model AI chatbots require approval as medical devices (Nature Medicine, [https://doi.org/10.1038/s41591-023-02412-6](https://www.nature.com/articles/s41591-023-02412-6)) | 
| 6.30 | LLaVAR: Enhanced Visual Instruction Tuning for Text-Rich Image Understanding ([:x:](https://arxiv.org/abs/2306.17107)), ([:paperclip:](https://arxiv.org/pdf/2306.17107.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.17107)), ([:house:](https://huggingface.co/papers/2306.17107)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/llavar-enhanced-visual-instruction-tuning-for)) |
| 6.30 | Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors ([:x:](https://arxiv.org/abs/2306.17156)), ([:paperclip:](https://arxiv.org/pdf/2306.17156.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.17156)), ([:house:](https://huggingface.co/papers/2306.17156)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/generative-ai-for-programming-education)) |
| 6.30 | Michelangelo: Conditional 3D Shape Generation based on Shape-Image-Text Aligned Latent Representation ([:x:](https://arxiv.org/abs/2306.17115)), ([:paperclip:](https://arxiv.org/pdf/2306.17115.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.17115)), ([:house:](https://huggingface.co/papers/2306.17115)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/michelangelo-conditional-3d-shape-generation)) |
| 6.30 | Generate Anything Anywhere in Any Scene ([:x:](https://arxiv.org/abs/2306.17154)), ([:paperclip:](https://arxiv.org/pdf/2306.17154.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.17154)), ([:house:](https://huggingface.co/papers/2306.17154)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/generate-anything-anywhere-in-any-scene)) |
| 6.30 | Benchmarking Large Language Model Capabilities for Conditional Generation ([:x:](https://arxiv.org/abs/2306.16793)), ([:paperclip:](https://arxiv.org/pdf/2306.16793.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.16793)), ([:house:](https://huggingface.co/papers/2306.16793)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/benchmarking-large-language-model)) |
| 6.29 | Towards Language Models That Can See: Computer Vision Through the LENS of Natural Language ([:x:](https://arxiv.org/abs/2306.16410)), ([:paperclip:](https://arxiv.org/pdf/2306.16410.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.16410)), ([:house:](https://huggingface.co/papers/2306.16410)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/towards-language-models-that-can-see-computer)), ([:octocat:](https://github.com/contextualai/lens)![GitHub Repo stars](https://img.shields.io/github/stars/contextualai/lens?style=social)) |
| 6.29 | Towards Measuring the Representation of Subjective Global Opinions in Language Models ([:x:](https://arxiv.org/abs/2306.16388)), ([:paperclip:](https://arxiv.org/pdf/2306.16388.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.16388)), ([:house:](https://huggingface.co/papers/2306.16388)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/towards-measuring-the-representation-of)) |
| 6.29 | REFLECT: Summarizing Robot Experiences for Failure Explanation and Correction ([:x:](https://arxiv.org/abs/2306.15724)), ([:paperclip:](https://arxiv.org/pdf/2306.15724.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.15724)), ([:house:](https://huggingface.co/papers/2306.15724)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/reflect-summarizing-robot-experiences-for)) |
| 6.29 | One-2-3-45: Any Single Image to 3D Mesh in 45 Seconds without Per-Shape Optimization ([:x:](https://arxiv.org/abs/2306.16928)), ([:paperclip:](https://arxiv.org/pdf/2306.16928.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.16928)), ([:house:](https://huggingface.co/papers/2306.16928)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/one-2-3-45-any-single-image-to-3d-mesh-in-45)) |
| 6.29 | DreamDiffusion: Generating High-Quality Images from Brain EEG Signals ([:x:](https://arxiv.org/abs/2306.16934)), ([:paperclip:](https://arxiv.org/pdf/2306.16934.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.16934)), ([:house:](https://huggingface.co/papers/2306.16934)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/dreamdiffusion-generating-high-quality-images)) |
| 6.28 | Extending Context Window of Large Language Models via Positional Interpolation ([:x:](https://arxiv.org/abs/2306.15595)), ([:paperclip:](https://arxiv.org/pdf/2306.15595.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.15595)), ([:house:](https://huggingface.co/papers/2306.15595)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/extending-context-window-of-large-language)) |
| 6.28 | CLIPA-v2: Scaling CLIP Training with 81.1% Zero-shot ImageNet Accuracy within a \10,000 Budget; An Extra 4,000 Unlocks 81.8% Accuracy  ([:x:](https://arxiv.org/abs/2306.15658)), ([:paperclip:](https://arxiv.org/pdf/2306.15658.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.15658)), ([:house:](https://huggingface.co/papers/2306.15658)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/clipa-v2-scaling-clip-training-with-81-1-zero)), ([:octocat:](https://github.com/ucsc-vlaa/clipa)![GitHub Repo stars](https://img.shields.io/github/stars/ucsc-vlaa/clipa?style=social)) |
| 6.28 | Automatic Calibration and Error Correction for Large Language Models via Pareto Optimal Self-Supervision ([:x:](https://arxiv.org/abs/2306.16564)), ([:paperclip:](https://arxiv.org/pdf/2306.16564.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.16564)), ([:house:](https://huggingface.co/papers/2306.16564)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/automatic-calibration-and-error-correction) |
| 6.28 | PoseDiffusion: Solving Pose Estimation via Diffusion-aided Bundle Adjustment ([project](https://posediffusion.github.io/)), ([:paperclip:](https://posediffusion.github.io/resources/pose_diffusion.pdf)), ([:octocat:](https://github.com/facebookresearch/PoseDiffusion)![GitHub Repo stars](https://img.shields.io/github/stars/facebookresearch/PoseDiffusion?style=social)) |
| 6.28 | BrainGPT - A Large Language Model tool to assist neuroscientific research ([home](https://braingpt.org/)) |
| 6.28 | Toward Actionable Generative AI - LAMs: From Large Language Models to Large Action Models ([blog](https://blog.salesforceairesearch.com/large-action-models/)) |
| 6.28 | The official #DragGAN app and code ([tweet](https://twitter.com/OpenMMLab/status/1673884887768784896)), ([application](https://openxlab.org.cn/apps/detail/XingangPan/DragGAN)), ([:octocat:](https://github.com/XingangPan/DragGAN)![GitHub Repo stars](https://img.shields.io/github/stars/XingangPan/DragGAN?style=social)) |
| 6.27 | Vision Augmented Language Models: Computer vision through the LENS of natural language ([blog](https://contextual.ai/introducing-lens/)), ([demo](https://lens.contextual.ai/#intro)), ([:octocat:](https://github.com/ContextualAI/lens)![GitHub Repo stars](https://img.shields.io/github/stars/ContextualAI/lens?style=social)) |
| 6.27 | Restart Sampling for Improving Generative Processes  ([:x:](https://arxiv.org/abs/2306.14878)), ([:paperclip:](https://arxiv.org/pdf/2306.14878.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14878)), ([:house:](https://huggingface.co/papers/2306.14878)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/restart-sampling-for-improving-generative)), ([:octocat:](https://github.com/newbeeer/diffusion_restart_sampling)![GitHub Repo stars](https://img.shields.io/github/stars/newbeeer/diffusion_restart_sampling?style=social)) |
| 6.27 | 3D-Speaker: A Large-Scale Multi-Device, Multi-Distance, and Multi-Dialect Corpus for Speech Representation Disentanglement  ([:x:](https://arxiv.org/abs/2306.15354)), ([:paperclip:](https://arxiv.org/pdf/2306.15354.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.15354)), ([:house:](https://huggingface.co/papers/2306.15354)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/3d-speaker-a-large-scale-multi-device-multi)), ([:octocat:](https://github.com/alibaba-damo-academy/3D-Speaker)![GitHub Repo stars](https://img.shields.io/github/stars/alibaba-damo-academy/3D-Speaker?style=social)) |
| 6.27 | MIMIC: Masked Image Modeling with Image Correspondences ([:x:](https://arxiv.org/abs/2306.15128)), ([:paperclip:](https://arxiv.org/pdf/2306.15128.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.15128)), ([:house:](https://huggingface.co/papers/2306.15128)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/mimic-masked-image-modeling-with-image)), ([:octocat:](https://github.com/raivnlab/mimic)![GitHub Repo stars](https://img.shields.io/github/stars/raivnlab/mimic?style=social)) |
| 6.27 | LeanDojo: Theorem Proving with Retrieval-Augmented Language Models ([project](https://leandojo.org/)), ([:x:](https://arxiv.org/abs/2306.15626)), ([:paperclip:](https://arxiv.org/pdf/2306.15626.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.15626)), ([:house:](https://huggingface.co/papers/2306.15626)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/leandojo-theorem-proving-with-retrieval)), ([:octocat:](https://github.com/lean-dojo/leandojo)![GitHub Repo stars](https://img.shields.io/github/stars/lean-dojo/leandojo?style=social)) |
| 6.27 | Any Image to 3D ([blog](https://csm.ai/any-image-to-3d)) |
| 6.27 | ⭐️LangChain Integrations⭐️ Hub ([link](https://integrations.langchain.com/)) |
| 6.27 | MVDiffusion: Enabling Holistic Multi-view Image Generation with Correspondence-Aware Diffusion ([project](https://mvdiffusion.github.io/)), ([demo](https://huggingface.co/spaces/tangshitao/MVDiffusion)) |
| 6.27 | Extending Context Window of Large Language Models via Positional Interpolation ([:x:](https://arxiv.org/abs/2306.15595)), ([:paperclip:](https://arxiv.org/pdf/2306.15595.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.15595)), ([:house:](https://huggingface.co/papers/2306.15595)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/extending-context-window-of-large-language)) |
| 6.27 | Salesforce open-source LLMs with 8k sequence length - Xgen 7B ([tweet](https://twitter.com/CaimingXiong/status/1674123308177178624)), ([blog](https://blog.salesforceairesearch.com/xgen/)), ([:octocat:](https://github.com/salesforce/xgen)![GitHub Repo stars](https://img.shields.io/github/stars/salesforce/xgen?style=social)) |
| 6.27 | Embracing change and resetting expectations ([blog](https://unlocked.microsoft.com/ai-anthology/terence-tao/)) | 
| 6.27 | Baby steps in evaluating the capacities of large language models (Nature Reviews Psychology, [https://doi.org/10.1038/s44159-023-00211-x](https://www.nature.com/articles/s44159-023-00211-x)), ([preview](https://www.nature.com/articles/s44159-023-00211-x.epdf?sharing_token=PYbU8twpfLCX_0iUnZ5uHdRgN0jAjWel9jnR3ZoTv0PTYDivHgU9XA-WV7YjPPGbQEAeKTPDC7dr9mwqTIpkLUsmlJssgvX6OrpHW0tUqyl6eOBgbVyX3hTm3yuWSHL8TstCrNpVavi8oMDsWvz2M2PcFa-YYEJruKabaEqbDMo%3D)) |
| 6.26 | MotionGPT: Human Motion as a Foreign Language ([:x:](https://arxiv.org/abs/2306.14795)), ([:paperclip:](https://arxiv.org/pdf/2306.14795.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14795)), ([:house:](https://huggingface.co/papers/2306.14795)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/motiongpt-human-motion-as-a-foreign-language)), ([:octocat:](https://github.com/openmotionlab/motiongpt)![GitHub Repo stars](https://img.shields.io/github/stars/openmotionlab/motiongpt?style=social)) |
| 6.26 | Faster Segment Anything: Towards Lightweight SAM for Mobile Applications ([:x:](https://arxiv.org/abs/2306.14289)), ([:paperclip:](https://arxiv.org/pdf/2306.14289.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14289)), ([:house:](https://huggingface.co/papers/2306.14289)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/faster-segment-anything-towards-lightweight)), ([:octocat:](https://github.com/chaoningzhang/mobilesam)![GitHub Repo stars](https://img.shields.io/github/stars/chaoningzhang/mobilesam?style=social)) |
| 6.26 | Aligning Large Multi-Modal Model with Robust Instruction Tuning ([:x:](https://arxiv.org/abs/2306.14565)), ([:paperclip:](https://arxiv.org/pdf/2306.14565.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14565)), ([:house:](https://huggingface.co/papers/2306.14565)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/aligning-large-multi-modal-model-with-robust)) |
| 6.26 | InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback ([project](https://intercode-benchmark.github.io/)), ([:x:](https://arxiv.org/abs/2306.14898)), ([:paperclip:](https://arxiv.org/pdf/2306.14898.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14898)), ([:house:](https://huggingface.co/papers/2306.14898)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/intercode-standardizing-and-benchmarking)) |
| 6.26 | LongCoder: A Long-Range Pre-trained Language Model for Code Completion ([:x:](https://arxiv.org/abs/2306.14893)), ([:paperclip:](https://arxiv.org/pdf/2306.14893.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14893)), ([:house:](https://huggingface.co/papers/2306.14893)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/longcoder-a-long-range-pre-trained-language)) |
| 6.26 | Kosmos-2: Grounding Multimodal Large Language Models to the World ([:x:](https://arxiv.org/abs/2306.14824)), ([:paperclip:](https://arxiv.org/pdf/2306.14824.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14824)), ([:house:](https://huggingface.co/papers/2306.14824)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/kosmos-2-grounding-multimodal-large-language)) |
| 6.26 | ViNT: A Foundation Model for Visual Navigation ([project](https://visualnav-transformer.github.io/)), ([:x:](https://arxiv.org/abs/2306.14846)), ([:paperclip:](https://arxiv.org/pdf/2306.14846.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14846)), ([:house:](https://huggingface.co/papers/2306.14846)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/vint-a-foundation-model-for-visual-navigation)), ([video](https://www.youtube.com/watch?v=6kNex5dJ5sQ)) |
| 6.26 | DragDiffusion: Harnessing Diffusion Models for Interactive Point-based Image Editing ([:x:](https://arxiv.org/abs/2306.14435)), ([:paperclip:](https://arxiv.org/pdf/2306.14435.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14435)), ([:house:](https://huggingface.co/papers/2306.14435)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/dragdiffusion-harnessing-diffusion-models-for)) |
| 6.25 | Generative AI — LLMOps Architecture Patterns ([blog](https://medium.datadriveninvestor.com/generative-ai-llmops-deployment-architecture-patterns-6d45d1668aba)) |
| 6.25 | DomainStudio: Fine-Tuning Diffusion Models for Domain-Driven Image Generation using Limited Data ([:x:](https://arxiv.org/abs/2306.14153)), ([:paperclip:](https://arxiv.org/pdf/2306.14153.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14153)), ([:house:](https://huggingface.co/papers/2306.14153)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/domainstudio-fine-tuning-diffusion-models-for)) |
| 6.25 | H_2O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models ([:x:](https://arxiv.org/abs/2306.14048)), ([:paperclip:](https://arxiv.org/pdf/2306.14048.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14048)), ([:house:](https://huggingface.co/papers/2306.14048)), ([:eight_spoked_asterisk:]()) |
| 6.25 | Thinking Like an Annotator: Generation of Dataset Labeling Instructions ([:x:](https://arxiv.org/abs/2306.14035)), ([:paperclip:](https://arxiv.org/pdf/2306.14035.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14035)), ([:house:](https://huggingface.co/papers/2306.14035)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/thinking-like-an-annotator-generation-of)) |
| 6.25 | Language models are weak learners ([:x:](https://arxiv.org/abs/2306.14101)), ([:paperclip:](https://arxiv.org/pdf/2306.14101.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14101)), ([:house:](https://huggingface.co/papers/2306.14101)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/language-models-are-weak-learners)) |
| 6.25 | Let's Do a Thought Experiment: Using Counterfactuals to Improve Moral Reasoning ([:x:](https://arxiv.org/abs/2306.14308)), ([:paperclip:](https://arxiv.org/pdf/2306.14308.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.14308)), ([:house:](https://huggingface.co/papers/2306.14308)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/let-s-do-a-thought-experiment-using)) |
| 6.25 | Chat with Hacker News in real-time using natural language ([demo](https://chathn.vercel.app/)) |
| 6.24 | Zero-shot spatial layout conditioning for text-to-image diffusion models ([:x:](https://arxiv.org/abs/2306.13754)), ([:paperclip:](https://arxiv.org/pdf/2306.13754.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.13754)), ([:house:](https://huggingface.co/papers/2306.13754)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/zero-shot-spatial-layout-conditioning-for)) |
| 6.24 | Beyond Scale: the Diversity Coefficient as a Data Quality Metric Demonstrates LLMs are Pre-trained on Formally Diverse Data  ([:x:](https://arxiv.org/abs/2306.13840)), ([:paperclip:](https://arxiv.org/pdf/2306.13840.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.13840)), ([:house:](https://huggingface.co/papers/2306.13840)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/beyond-scale-the-diversity-coefficient-as-a)) |
| 6.24 | On the paper “Exploring the MIT Mathematics and EECS Curriculum Using Large Language Models” ([MIT](https://people.csail.mit.edu/asolar/CoursesPaperStatement.pdf)) |
| 6.24 | A critical analysis of “Exploring the MIT Mathematics and EECS Curriculum Using Large Language Models” ([blog](https://flower-nutria-41d.notion.site/No-GPT4-can-t-ace-MIT-b27e6796ab5a48368127a98216c76864)) |
| 6.24 | System-Level Natural Language Feedback  ([:x:](https://arxiv.org/abs/2306.13588)), ([:paperclip:](https://arxiv.org/pdf/2306.13588.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.13588)), ([:house:](https://huggingface.co/papers/2306.13588)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/system-level-natural-language-feedback)) |
| 6.24 | OpenMask3D: Open-Vocabulary 3D Instance Segmentation ([:x:](https://arxiv.org/abs/2306.13631)), ([:paperclip:](https://arxiv.org/pdf/2306.13631.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.13631)), ([:house:](https://huggingface.co/papers/2306.13631)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/openmask3d-open-vocabulary-3d-instance)) |
| 6.24 | Scaling MLPs: A Tale of Inductive Bias ([:x:](https://arxiv.org/abs/2306.13575)), ([:paperclip:](https://arxiv.org/pdf/2306.13575.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.13575)), ([:house:](https://huggingface.co/papers/2306.13575)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/scaling-mlps-a-tale-of-inductive-bias)) |
| 6.23 | What's going on with the Open LLM Leaderboard? ([blog](https://huggingface.co/blog/evaluating-mmlu-leaderboard)) |
| 6.23 | A Survey on Multimodal Large Language Models ([:x:](https://arxiv.org/abs/2306.13549)), ([:paperclip:](https://arxiv.org/pdf/2306.13549.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.13549)), ([:house:](https://huggingface.co/papers/2306.13549)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-survey-on-multimodal-large-language-models)), ([:octocat:](https://github.com/bradyfu/awesome-multimodal-large-language-models)![GitHub Repo stars](https://img.shields.io/github/stars/bradyfu/awesome-multimodal-large-language-models?style=social)) |
| 6.23 | LLM Powered Autonomous Agents ([blog](https://lilianweng.github.io/posts/2023-06-23-agent/)) |
| 6.23 | DreamEditor: Text-Driven 3D Scene Editing with Neural Fields ([:x:](https://arxiv.org/abs/2306.13455)), ([:paperclip:](https://arxiv.org/pdf/2306.13455.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.13455)), ([:house:](https://huggingface.co/papers/2306.13455)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/dreameditor-text-driven-3d-scene-editing-with)) |
| 6.23 | Long-range Language Modeling with Self-retrieval  ([:x:](https://arxiv.org/abs/2306.13421)), ([:paperclip:](https://arxiv.org/pdf/2306.13421.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.13421)), ([:house:](https://huggingface.co/papers/2306.13421)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/long-range-language-modeling-with-self)) |
| 6.23 | Bring Your Own Data! Self-Supervised Evaluation for Large Language Models ([:x:](https://arxiv.org/abs/2306.13651)), ([:paperclip:](https://arxiv.org/pdf/2306.13651.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.13651)), ([:house:](https://huggingface.co/papers/2306.13651)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/bring-your-own-data-self-supervised)), ([:octocat:](https://github.com/neelsjain/byod)![GitHub Repo stars](https://img.shields.io/github/stars/neelsjain/byod?style=social)) |
| 6.22 | reliableGPT: Stop OpenAI Errors in Production ([:octocat:](https://github.com/BerriAI/reliableGPT)![GitHub Repo stars](https://img.shields.io/github/stars/BerriAI/reliableGPT?style=social)) |
| 6.22 | Lit-GPT : Implementation of Falcon, StableLM, Pythia, INCITE language models based on nanoGPT ([:octocat:](https://github.com/Lightning-AI/lit-gpt)![GitHub Repo stars](https://img.shields.io/github/stars/Lightning-AI/lit-gpt?style=social)) |
| 6.22 | Perspective Fields for Single Image Camera Calibration ([project page](https://jinlinyi.github.io/PerspectiveFields/)), ([video](https://www.youtube.com/watch?v=sN5B_ZvMva8)), ([demo](https://huggingface.co/spaces/jinlinyi/PerspectiveFields)), ([:x:](https://arxiv.org/abs/2212.03239)), ([:paperclip:](https://arxiv.org/pdf/2212.03239.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2212.03239)), ([:house:](https://huggingface.co/papers/2212.03239)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/perspective-fields-for-single-image-camera)), ([:octocat:](https://github.com/jinlinyi/PerspectiveFields)![GitHub Repo stars](https://img.shields.io/github/stars/jinlinyi/PerspectiveFields?style=social)), (CVPR 2023) |
| 6.22 | Event Stream GPT (ESGPT), for "event stream" datasets, particularly Electronic Health Record (EHR) datasets ([tweet](https://twitter.com/MattBMcDermott/status/1671912624366166018)), ([:octocat:](https://github.com/mmcdermott/EventStreamGPT)![GitHub Repo stars](https://img.shields.io/github/stars/mmcdermott/EventStreamGPT?style=social)) |
| 6.22 | MPT-30B is here ([tweet](https://twitter.com/jefrankle/status/1671897555435913220)), ([blog](https://www.mosaicml.com/blog/mpt-30b)), ([HF](https://huggingface.co/mosaicml/mpt-30b)), ([MosaicML MPT-30B-Chat](https://huggingface.co/spaces/mosaicml/mpt-30b-chat)) |
| 6.22 | How continuous batching enables 23x throughput in LLM inference while reducing p50 latency ([blog](https://www.anyscale.com/blog/continuous-batching-llm-inference)) |
| 6.22 | DreamTime: An Improved Optimization Strategy for Text-to-3D Content Creation ([:x:](https://arxiv.org/abs/2306.12422)), ([:paperclip:](https://arxiv.org/pdf/2306.12422.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.12422)), ([:house:](https://huggingface.co/papers/2306.12422)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/dreamtime-an-improved-optimization-strategy)) |
| 6.22 | Stability AI launches SDXL 0.9: A Leap Forward in AI Image Generation ([news](https://stability.ai/blog/sdxl-09-stable-diffusion)) |
| 6.21 | Understanding Social Reasoning in Language Models with Language Models ([:x:](https://arxiv.org/abs/2306.15448)), ([:paperclip:](https://arxiv.org/pdf/2306.15448.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.15448)), ([:house:](https://huggingface.co/papers/2306.15448)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/understanding-social-reasoning-in-language)) |
| 6.21 | Opportunities and Risks of LLMs for Scalable Deliberation with Polis ([:x:](https://arxiv.org/abs/2306.11932)), ([:paperclip:](https://arxiv.org/pdf/2306.11932.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.11932)), ([:house:](https://huggingface.co/papers/2306.11932)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/opportunities-and-risks-of-llms-for-scalable)) |
| 6.21 | Training Transformers with 4-bit Integers ([:x:](https://arxiv.org/abs/2306.11987)), ([:paperclip:](https://arxiv.org/pdf/2306.11987.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.11987)), ([:house:](https://huggingface.co/papers/2306.11987)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/training-transformers-with-4-bit-integers)) |
| 6.21 | Fast Segment Anything ([:x:](https://arxiv.org/abs/2306.12156)), ([:paperclip:](https://arxiv.org/pdf/2306.12156.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.12156)), ([:house:](https://huggingface.co/papers/2306.12156)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/fast-segment-anything)), ([:octocat:](https://github.com/casia-iva-lab/fastsam)![GitHub Repo stars](https://img.shields.io/github/stars/casia-iva-lab/fastsam?style=social)) |
| 6.21 | DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models ([:x:](https://arxiv.org/abs/2306.11698)), ([:paperclip:](https://arxiv.org/pdf/2306.11698.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.11698)), ([:house:](https://huggingface.co/papers/2306.11698)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/decodingtrust-a-comprehensive-assessment-of)) |
| 6.20 | Visual Foundation Models for Medical Image Analysis ([blog](https://developer.nvidia.com/blog/visual-foundation-models-for-medical-image-analysis/)) |
| 6.20 | Learning to Generate Better Than Your LLM ([:x:](https://arxiv.org/abs/2306.11816)), ([:paperclip:](https://arxiv.org/pdf/2306.11816.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.11816)), ([:house:](https://huggingface.co/papers/2306.11816)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/learning-to-generate-better-than-your-llm)) |
| 6.20 | Sound reconstruction from human brain activity via a generative model with brain-like auditory features ([:x:](https://arxiv.org/abs/2306.11629)), ([:paperclip:](https://arxiv.org/pdf/2306.11629.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.11629)), ([:house:](https://huggingface.co/papers/2306.11629)), ([:eight_spoked_asterisk:](https://cs.paperswithcode.com/paper/sound-reconstruction-from-human-brain)), ([:octocat:](https://github.com/KamitaniLab/DeepImageReconstruction)![GitHub Repo stars](https://img.shields.io/github/stars/KamitaniLab/DeepImageReconstruction?style=social)) |
| 6.20 | A Simple and Effective Pruning Approach for Large Language Models ([:x:](https://arxiv.org/abs/2306.11695)), ([:paperclip:](https://arxiv.org/pdf/2306.11695.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.11695)), ([:house:](https://huggingface.co/papers/2306.11695)), ([:eight_spoked_asterisk:]([https://paperswithcode.com/paper/fast-segment-anything](https://paperswithcode.com/paper/a-simple-and-effective-pruning-approach-for))), ([:octocat:](https://github.com/locuslab/wanda)![GitHub Repo stars](https://img.shields.io/github/stars/locuslab/wanda?style=social)) |
| 6.20 | Radiology Report Expert Evaluation (ReXVal) Dataset (PhysioNet [https://doi.org/10.13026/2fp8-qr71](https://physionet.org/content/rexval-dataset/1.0.0/)) |
| 6.20 | RoboCat: A Self-Improving Foundation Agent for Robotic Manipulation ([:x:](https://arxiv.org/abs/2306.11706)), ([:paperclip:](https://arxiv.org/pdf/2306.11706.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.11706)), ([:house:](https://huggingface.co/papers/2306.11706)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/robocat-a-self-improving-foundation-agent-for)), ([:octocat:](https://github.com/kyegomez/RoboCAT)![GitHub Repo stars](https://img.shields.io/github/stars/kyegomez/RoboCAT?style=social)) |
| 6.20 | Segment Anything Model (SAM) for Radiation Oncology ([:x:](https://arxiv.org/abs/2306.11730)), ([:paperclip:](https://arxiv.org/pdf/2306.11730.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.11730)), ([:house:](https://huggingface.co/papers/2306.11730)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/segment-anything-model-sam-for-radiation)) |
| 6.20 | RepoFusion: Training Code Models to Understand Your Repository  ([:x:](https://arxiv.org/abs/2306.10998)), ([:paperclip:](https://arxiv.org/pdf/2306.10998.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.10998)), ([:house:](https://huggingface.co/papers/2306.10998)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/repofusion-training-code-models-to-understand)) |
| 6.20 | Textbooks Are All You Need ([:x:](https://arxiv.org/abs/2306.11644)), ([:paperclip:](https://arxiv.org/pdf/2306.11644.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.11644)), ([:house:](https://huggingface.co/papers/2306.11644)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/textbooks-are-all-you-need)) |
| 6.19 | CounselGPT - Korean psychological counseling dataset ([:octocat:](https://github.com/MrBananaHuman/CounselGPT)![GitHub Repo stars](https://img.shields.io/github/stars/MrBananaHuman/CounselGPT?style=social)) |
| 6.19 | MotionGPT: Finetuned LLMs are General-Purpose Motion Generators ([:x:](https://arxiv.org/abs/2306.10900)), ([:paperclip:](https://arxiv.org/pdf/2306.10900.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.10900)), ([:house:](https://huggingface.co/papers/2306.10900)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/motiongpt-finetuned-llms-are-general-purpose)) |
| 6.18 | Point-Cloud Completion with Pretrained Text-to-image Diffusion Models ([:x:](https://arxiv.org/abs/2306.10533)), ([:paperclip:](https://arxiv.org/pdf/2306.10533.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.10533)), ([:house:](https://huggingface.co/papers/2306.10533)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/point-cloud-completion-with-pretrained-text)) |
| 6.18 | Mercedes-Benz Installs ChatGPT Artificial Intelligence in 900,000 Cars ([Newsweek](https://www.newsweek.com/mercedes-benz-installs-chatgpt-artificial-intelligence-900000-cars-1807384)), ([Mercedes Benz](https://media.mercedes-benz.com/article/323212b5-1b56-458a-9324-20b25cc176cb)) |
| 6.18 | OpenLLaMA-13B released ([tweet](https://twitter.com/hardmaru/status/1670628627057197059)), ([:octocat:](https://github.com/openlm-research/open_llama)![GitHub Repo stars](https://img.shields.io/github/stars/openlm-research/open_llama?style=social)) |
| 6.17 | Beware of Unreliable Data in Model Evaluation: A LLM Prompt Selection case study with Flan-T5 ([blog](https://towardsdatascience.com/beware-of-unreliable-data-in-model-evaluation-a-llm-prompt-selection-case-study-with-flan-t5-88cfd469d058)) | 
| 6.17 | GPT Engineer - specify what you want it to build, the AI asks for clarification, and then builds it ([:octocat:](https://github.com/AntonOsika/gpt-engineer)![GitHub Repo stars](https://img.shields.io/github/stars/AntonOsika/gpt-engineer?style=social)) |
| 6.17 | Demystifying GPT Self-Repair for Code Generation ([:x:](https://arxiv.org/abs/2306.09896)), ([:paperclip:](https://arxiv.org/pdf/2306.09896.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09896)), ([:house:](https://huggingface.co/papers/2306.09896)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/demystifying-gpt-self-repair-for-code)) |
| 6.17 | Introducing GAIA-1: A Cutting-Edge Generative AI Model for Autonomy ([blog](https://wayve.ai/thinking/introducing-gaia1/)) |
| 6.17 | Understanding Encoder And Decoder LLMs ([blog](https://magazine.sebastianraschka.com/p/understanding-encoder-and-decoder)) | 
| 6.16 | AvatarBooth: High-Quality and Customizable 3D Human Avatar Generation ([project](https://zeng-yifei.github.io/avatarbooth_page/)), ([:x:](https://arxiv.org/abs/2306.09864)), ([:paperclip:](https://arxiv.org/pdf/2306.09864.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09864)), ([:house:](https://huggingface.co/papers/2306.09864)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/avatarbooth-high-quality-and-customizable-3d)) |
| 6.16 | Gradient is All You Need? ([:x:](https://arxiv.org/abs/2306.09778)), ([:paperclip:](https://arxiv.org/pdf/2306.09778.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09778)), ([:house:](https://huggingface.co/papers/2306.09778)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/gradients-are-not-all-you-need)), ([:octocat:](https://github.com/google/learned_optimization)![GitHub Repo stars](https://img.shields.io/github/stars/google/learned_optimization?style=social)) |
| 6.16 | LabelBench: A Comprehensive Framework for Benchmarking Label-Efficient Learning ([:x:](https://arxiv.org/abs/2306.09910)), ([:paperclip:](https://arxiv.org/pdf/2306.09910.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09910)), ([:house:](https://huggingface.co/papers/2306.09910)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/labelbench-a-comprehensive-framework-for)), ([:octocat:](https://github.com/efficienttraining/labelbench)![GitHub Repo stars](https://img.shields.io/github/stars/efficienttraining/labelbench?style=social)) |
| 6.16 | AD-AutoGPT: An Autonomous GPT for Alzheimer's Disease Infodemiology ([:x:](https://arxiv.org/abs/2306.10095)), ([:paperclip:](https://arxiv.org/pdf/2306.10095.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.10095)), ([:house:](https://huggingface.co/papers/2306.10095)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/ad-autogpt-an-autonomous-gpt-for-alzheimer-s)) |
| 6.16 | Meta - Introducing Voicebox: The Most Versatile AI for Speech Generation ([news](https://about.fb.com/news/2023/06/introducing-voicebox-ai-for-speech-generation/)) |
| 6.16 | Explore, Establish, Exploit: Red Teaming Language Models from Scratch  ([:x:](https://arxiv.org/abs/2306.09442)), ([:paperclip:](https://arxiv.org/pdf/2306.09442.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09442)), ([:house:](https://huggingface.co/papers/2306.09442)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/explore-establish-exploit-red-teaming)) |
| 6.16 | Full Parameter Fine-tuning for Large Language Models with Limited Resources  ([:x:](https://arxiv.org/abs/2306.09782)), ([:paperclip:](https://arxiv.org/pdf/2306.09782.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09782)), ([:house:](https://huggingface.co/papers/2306.09782)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/full-parameter-fine-tuning-for-large-language)), ([:octocat:](https://github.com/openlmlab/lomo)![GitHub Repo stars](https://img.shields.io/github/stars/openlmlab/lomo?style=social)) |
| 6.16 | ClinicalGPT: Large Language Models Finetuned with Diverse Medical Data and Comprehensive Evaluation ([:x:](https://arxiv.org/abs/2306.09968)), ([:paperclip:](https://arxiv.org/pdf/2306.09968.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09968)), ([:house:](https://huggingface.co/papers/2306.09968)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/clinicalgpt-large-language-models-finetuned)) |
| 6.16 | CLIPSonic: Text-to-Audio Synthesis with Unlabeled Videos and Pretrained Language-Vision Models ([:x:](https://arxiv.org/abs/2306.09635)), ([:paperclip:](https://arxiv.org/pdf/2306.09635.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09635)), ([:house:](https://huggingface.co/papers/2306.09635)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/clipsonic-text-to-audio-synthesis-with)) |
| 6.16 | Language-Guided Music Recommendation for Video via Prompt Analogies ([:x:](https://arxiv.org/abs/2306.09327)), ([:paperclip:](https://arxiv.org/pdf/2306.09327.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09327)), ([:house:](https://huggingface.co/papers/2306.09327)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/language-guided-music-recommendation-for-1)) |
| 6.16 | QR Code AI Art Generator ([tweet](https://twitter.com/radamar/status/1669549592470499328)), ([Hugging face](https://huggingface.co/spaces/huggingface-projects/QR-code-AI-art-generator)), ([SD art](https://stable-diffusion-art.com/qr-code/)) |
| 6.16 | Standford CRFM - Transparency Index for Foundation Model Provider's Compliance measurement with the Draft EU AI Act ([tweet](https://twitter.com/RishiBommasani/status/1669463873869709313)), ([:octocat:](https://github.com/stanford-crfm/TransparencyIndex)![GitHub Repo stars](https://img.shields.io/github/stars/stanford-crfm/TransparencyIndex?style=social)) |
| 6.15 | Introducing the ElevenLabs AI Speech Classifier: Elevating Safety Standards for AI-generated Audio Content ([news](https://beta.elevenlabs.io/blog/ai-speech-classifier/)) |
| 6.15 | ChatGPT AI Shines in Challenging Medical Cases ([news](https://neurosciencenews.com/chatgpt-medical-ai-23480/)) |
| 6.15 | Accuracy of a Generative Artificial Intelligence Model in a Complex Diagnostic Challenge (JAMA [doi:10.1001/jama.2023.8288](https://jamanetwork.com/journals/jama/fullarticle/2806457)) |
| 6.15 | LOVM: Language-Only Vision Model Selection ([:x:](https://arxiv.org/abs/2306.08893)), ([:paperclip:](https://arxiv.org/pdf/2306.08893.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08893)), ([:house:](https://huggingface.co/papers/2306.08893)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/lovm-language-only-vision-model-selection)) |
| 6.15 | WizardCoder: Empowering Code Large Language Models with Evol-Instruct ([:x:](https://arxiv.org/abs/2306.08568)), ([:paperclip:](https://arxiv.org/pdf/2306.08568.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08568)), ([:house:](https://huggingface.co/papers/2306.08568)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/wizardcoder-empowering-code-large-language)), ([:octocat:](https://github.com/nlpxucan/wizardlm)![GitHub Repo stars](https://img.shields.io/github/stars/nlpxucan/wizardlm?style=social)) |
| 6.15 | Segment Any Point Cloud Sequences by Distilling Vision Foundation Models ([:x:](https://arxiv.org/abs/2306.09347)), ([:paperclip:](https://arxiv.org/pdf/2306.09347.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09347)), ([:house:](https://huggingface.co/papers/2306.09347)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/segment-any-point-cloud-sequences-by)), ([:octocat:](https://github.com/youquanl/segment-any-point-cloud)![GitHub Repo stars](https://img.shields.io/github/stars/youquanl/segment-any-point-cloud?style=social)) |
| 6.15 | Seeing the World through Your Eyes ([:x:](https://arxiv.org/abs/2306.09348)), ([:paperclip:](https://arxiv.org/pdf/2306.09348.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09348)), ([:house:](https://huggingface.co/papers/2306.09348)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/seeing-the-world-through-your-eyes)) |
| 6.15 | Exploring the MIT Mathematics and EECS Curriculum Using Large Language Models ([:x:](https://arxiv.org/abs/2306.08997)), ([:paperclip:](https://arxiv.org/pdf/2306.08997.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08997)), ([:house:](https://huggingface.co/papers/2306.08997)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/exploring-the-mit-mathematics-and-eecs)) |
| 6.15 | Can Language Models Teach Weaker Agents? Teacher Explanations Improve Students via Theory of Mind ([:x:](https://arxiv.org/abs/2306.09299)), ([:paperclip:](https://arxiv.org/pdf/2306.09299.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09299)), ([:house:](https://huggingface.co/papers/2306.09299)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/can-language-models-teach-weaker-agents)), ([:octocat:](https://github.com/swarnahub/explanationintervention)![GitHub Repo stars](https://img.shields.io/github/stars/swarnahub/explanationintervention?style=social)) |
| 6.15 | Segment Any Point Cloud Sequences by Distilling Vision Foundation Models ([:x:](https://arxiv.org/abs/2306.09347)), ([:paperclip:](https://arxiv.org/pdf/2306.09347.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09347)), ([:house:](https://huggingface.co/papers/2306.09347)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/segment-any-point-cloud-sequences-by)), ([:octocat:](https://github.com/youquanl/segment-any-point-cloud)![GitHub Repo stars](https://img.shields.io/github/stars/youquanl/segment-any-point-cloud?style=social)) |
| 6.15 | ChessGPT: Bridging Policy Learning and Language Modeling ([:x:](https://arxiv.org/abs/2306.09200)), ([:paperclip:](https://arxiv.org/pdf/2306.09200.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.09200)), ([:house:](https://huggingface.co/papers/2306.09200)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/chessgpt-bridging-policy-learning-and)), ([:octocat:](https://github.com/waterhorse1/chessgpt)![GitHub Repo stars](https://img.shields.io/github/stars/waterhorse1/chessgpt?style=social)) |
| 6.16 | The economic potential of generative AI: The next productivity frontier (McKinsey & Company. [report](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier)) |
| 6.14 | Radiology-GPT: A Large Language Model for Radiology ([demo](https://huggingface.co/spaces/allen-eric/radiology-gpt)), ([:x:](https://arxiv.org/abs/2306.08666)), ([:paperclip:](https://arxiv.org/pdf/2306.08666.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08666)), ([:house:](https://huggingface.co/papers/2306.08666)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/radiology-gpt-a-large-language-model-for)) |
| 6.15 | Top Use Cases and Cutting-Edge Solutions with Generative AI in Healthcare ([blog](https://emorphis.health/blogs/generative-ai-in-healthcare-top-use-cases-and-solutions/)) | 
| 6.15 | [SCIENCE] Art and the science of generative AI, Vol 380, Issue 6650, ([DOI: 10.1126/science.adh4451](https://www.science.org/doi/full/10.1126/science.adh4451)) |
| 6.14 | Unifying Large Language Models and Knowledge Graphs: A Roadmap ([:x:](https://arxiv.org/abs/2306.08302)), ([:paperclip:](https://arxiv.org/pdf/2306.08302.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08302)), ([:house:](https://huggingface.co/papers/2306.08302)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/unifying-large-language-models-and-knowledge)) |
| 6.14 | Knowledge Distillation of Large Language Models ([:x:](https://arxiv.org/abs/2306.08543)), ([:paperclip:](https://arxiv.org/pdf/2306.08543.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08543)), ([:house:](https://huggingface.co/papers/2306.08543)), ([:eight_spoked_asterisk:]()) |
| 6.14 | TAPIR: Tracking Any Point with per-frame Initialization and temporal Refinement ([:x:](https://arxiv.org/abs/2306.08637)), ([:paperclip:](https://arxiv.org/pdf/2306.08637.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08637)), ([:house:](https://huggingface.co/papers/2306.08637)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/tapir-tracking-any-point-with-per-frame)) |
| 6.14 | EU MEPs ready to negotiate first-ever rules for safe and transparent AI ([news](https://www.europarl.europa.eu/news/en/press-room/20230609IPR96212/meps-ready-to-negotiate-first-ever-rules-for-safe-and-transparent-ai)) |
| 6.14 | TryOnDiffusion: A Tale of Two UNets ([:x:](https://arxiv.org/abs/2306.08276)), ([:paperclip:](https://arxiv.org/pdf/2306.08276.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08276)), ([:house:](https://huggingface.co/papers/2306.08276)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/tryondiffusion-a-tale-of-two-unets)) |
| 6.14 | AssistGPT: A General Multi-modal Assistant that can Plan, Execute, Inspect, and Learn ([:x:](https://arxiv.org/abs/2306.08640)), ([:paperclip:](https://arxiv.org/pdf/2306.08640.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08640)), ([:house:](https://huggingface.co/papers/2306.08640)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/assistgpt-a-general-multi-modal-assistant)) |
| 6.14 | Stable Diffusion with Core ML on Apple Silicon  ([tweet](https://twitter.com/atiorh/status/1669009755191537664)), ([:octocat:](https://github.com/apple/ml-stable-diffusion)![GitHub Repo stars](https://img.shields.io/github/stars/apple/ml-stable-diffusion?style=social)) |
| 6.13 | How AI Responds to Common Lung Cancer Questions: ChatGPT vs Google Bard (RSNA Radiology, [https://doi.org/10.1148/radiol.230922](https://pubs.rsna.org/doi/full/10.1148/radiol.230922)) |
| 6.13 | Artificial Artificial Artificial Intelligence: Crowd Workers Widely Use Large Language Models for Text Production Tasks ([:x:](https://arxiv.org/abs/2306.07899)), ([:paperclip:](https://arxiv.org/pdf/2306.07899.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07899)), ([:house:](https://huggingface.co/papers/2306.07899)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/artificial-artificial-artificial-intelligence)), ([:octocat:](https://github.com/epfl-dlab/gpturk)![GitHub Repo stars](https://img.shields.io/github/stars/epfl-dlab/gpturk?style=social)) |
| 6.13 | Scalable 3D Captioning with Pretrained Models ([:x:](https://arxiv.org/abs/2306.07279)), ([:paperclip:](https://arxiv.org/pdf/2306.07279.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07279)), ([:house:](https://huggingface.co/papers/2306.07279)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/scalable-3d-captioning-with-pretrained-models)) |
| 6.13 | Rerender A Video: Zero-Shot Text-Guided Video-to-Video Translation ([:x:](https://arxiv.org/abs/2306.07954)), ([:paperclip:](https://arxiv.org/pdf/2306.07954.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07954)), ([:house:](https://huggingface.co/papers/2306.07954)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/rerender-a-video-zero-shot-text-guided-video)) |
| 6.13 | arXiVeri: Automatic table verification with GPT ([:x:](https://arxiv.org/abs/2306.07968)), ([:paperclip:](https://arxiv.org/pdf/2306.07968.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07968)), ([:house:](https://huggingface.co/papers/2306.07968)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/arxiveri-automatic-table-verification-with)) |
| 6.13 | AVIS: Autonomous Visual Information Seeking with Large Language Models ([:x:](https://arxiv.org/abs/2306.08129)), ([:paperclip:](https://arxiv.org/pdf/2306.08129.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08129)), ([:house:](https://huggingface.co/papers/2306.08129)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/avis-autonomous-visual-information-seeking)) |
| 6.13 | AniFaceDrawing: Anime Portrait Exploration during Your Sketching ([:x:](https://arxiv.org/abs/2306.07476)), ([:paperclip:](https://arxiv.org/pdf/2306.07476.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07476)), ([:house:](https://huggingface.co/papers/2306.07476)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/anifacedrawing-anime-portrait-exploration)) |
| 6.13 | h2oGPT: Democratizing Large Language Models ([:x:](https://arxiv.org/abs/2306.08161)), ([:paperclip:](https://arxiv.org/pdf/2306.08161.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.08161)), ([:house:](https://huggingface.co/papers/2306.08161)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/h2ogpt-democratizing-large-language-models)), [:octocat:](https://github.com/h2oai/h2ogpt)![GitHub Repo stars](https://img.shields.io/github/stars/h2oai/h2ogpt?style=social)) |
| 6.13 | 3D molecule generation by denoising voxel grids [:x:](https://arxiv.org/abs/2306.07473)), ([:paperclip:](https://arxiv.org/pdf/2306.07473.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07473)), ([:house:](https://huggingface.co/papers/2306.07473)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/3d-molecule-generation-by-denoising-voxel)) |
| 6.13 | GeneCIS: A Benchmark for General Conditional Image Similarity ([project page](https://sgvaze.github.io/genecis/)), ([:x:](https://arxiv.org/abs/2306.07969)), ([:paperclip:](https://arxiv.org/pdf/2306.07969.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07969)), ([:house:](https://huggingface.co/papers/2306.07969)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/genecis-a-benchmark-for-general-conditional-1)), ([:octocat:](https://github.com/facebookresearch/genecis)![GitHub Repo stars](https://img.shields.io/github/stars/facebookresearch/genecis?style=social)), (CVPR 2023) |
| 6.13 | Macaw-LLM: Multi-Modal Language Modeling with Image, Audio, Video, and Text Integration  ([:octocat:](https://github.com/lyuchenyang/Macaw-LLM)![GitHub Repo stars](https://img.shields.io/github/stars/lyuchenyang/Macaw-LLM?style=social)) |
| 6.13 | One-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning ([:x:](https://arxiv.org/abs/2306.07967)), ([:paperclip:](https://arxiv.org/pdf/2306.07967.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07967)), ([:house:](https://huggingface.co/papers/2306.07967)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/one-for-all-generalized-lora-for-parameter)), ([:octocat:](https://github.com/arnav0400/vit-slim)![GitHub Repo stars](https://img.shields.io/github/stars/arnav0400/vit-slim?style=social)) |
| 6.13 | GitHub survey result - 92% of U.S.-based developers are already using AI coding tools both in and outside of work ([blog](https://github.blog/2023-06-13-survey-reveals-ais-impact-on-the-developer-experience/)) |
| 6.13 | ChatGPT Workspaces - Upcoming ChatGPT features: file uploading, profiles, organizations and workspaces ([reddit](https://www.reddit.com/r/ChatGPT/comments/144cfzg/upcoming_chatgpt_features_file_uploading_profiles/?utm_source=share&utm_medium=web2x&context=3)) |
| 6.12 | Transformers learn through gradual rank increase ([:x:](https://arxiv.org/abs/2306.07042)), ([:paperclip:](https://arxiv.org/pdf/2306.07042.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07042)), ([:house:](https://huggingface.co/papers/2306.07042)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/transformers-learn-through-gradual-rank)) |
| 6.12 | Large Language Models as Tax Attorneys: A Case Study in Legal Capabilities Emergence ([:x:](https://arxiv.org/abs/2306.07075)), ([:paperclip:](https://arxiv.org/pdf/2306.07075.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07075)), ([:house:](https://huggingface.co/papers/2306.07075)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/large-language-models-as-tax-attorneys-a-case)) |
| 6.12 | Augmenting Language Models with Long-Term Memory ([:x:](https://arxiv.org/abs/2306.07174)), ([:paperclip:](https://arxiv.org/pdf/2306.07174.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07174)), ([:house:](https://huggingface.co/papers/2306.07174)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/augmenting-language-models-with-long-term)), ([:octocat:](https://github.com/Victorwz/LongMem)![GitHub Repo stars](https://img.shields.io/github/stars/Victorwz/LongMem?style=social)) |
| 6.12 | Yann LeCun and Geoffrrey Hinton's Consensus on a number of questions about AI and catastrophic risks ([tweet](https://twitter.com/ylecun/status/1667947166764023808)) |
| 6.12 | Conversation of Andrew Ng and Geoffrey Hinton about AI and catastrophic risks ([tweet](https://twitter.com/AndrewYNg/status/1667920020587020290)) |
| 6.12 | Benchmarking Neural Network Training Algorithms ([:x:](https://arxiv.org/abs/2306.07179)), ([:paperclip:](https://arxiv.org/pdf/2306.07179.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07179)), ([:house:](https://huggingface.co/papers/2306.07179)), ([:eight_spoked_asterisk:]()) |
| 6.12 | Lit-llama - Implementation of the LLaMA language model based on nanoGPT ([:octocat:](https://github.com/Lightning-AI/lit-llama)![GitHub Repo stars](https://img.shields.io/github/stars/Lightning-AI/lit-llama?style=social)) |
| 6.12 | OpenAI, DeepMind will open up models to UK government ([news](https://www.politico.eu/article/openai-deepmind-will-open-up-models-to-uk-government/)) |
| 6.12 | WizardLM: An Instruction-following LLM Using Evol-Instruct ([:octocat:](https://github.com/nlpxucan/WizardLM)![GitHub Repo stars](https://img.shields.io/github/stars/nlpxucan/WizardLM?style=social)) |
| 6.11 | Face0: Instantaneously Conditioning a Text-to-Image Model on a Face ([:x:](https://arxiv.org/abs/2306.06638)), ([:paperclip:](https://arxiv.org/pdf/2306.06638.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.06638)), ([:house:](https://huggingface.co/papers/2306.06638)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/face0-instantaneously-conditioning-a-text-to)) |
| 6.11 | A Comprehensive Survey on Applications of Transformers for Deep Learning Tasks ([:x:](https://arxiv.org/abs/2306.07303)), ([:paperclip:](https://arxiv.org/pdf/2306.07303.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07303)), ([:house:](https://huggingface.co/papers/2306.07303)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-comprehensive-survey-on-applications-of)) |
| 6.10 | Large Language Model Evaluation in 2023: 5 Methods ([blog](https://research.aimultiple.com/large-language-model-evaluation/)) | 
| 6.9 | Chat Generative Pretrained Transformer Fails the Multiple-Choice American College of Gastroenterology Self-Assessment Test (The American Journal of Gastroenterology, [DOI: 10.14309/ajg.0000000000002320](https://journals.lww.com/ajg/Abstract/9900/Chat_Generative_Pretrained_Transformer_Fails_the.751.aspx)) |
| 6.9 | Aladdin: Zero-Shot Hallucination of Stylized 3D Assets from Abstract Scene Descriptions ([:x:](https://arxiv.org/abs/2306.06212)), ([:paperclip:](https://arxiv.org/pdf/2306.06212.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.06212)), ([:house:](https://huggingface.co/papers/2306.06212)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/aladdin-zero-shot-hallucination-of-stylized)), ([:octocat:](https://github.com/ianhuang0630/aladdin)![GitHub Repo stars](https://img.shields.io/github/stars/ianhuang0630/aladdin?style=social)) |
| 6.9 | Judging LLM-as-a-judge with MT-Bench and Chatbot Arena ([:x:](https://arxiv.org/abs/2306.05685)), ([:paperclip:](https://arxiv.org/pdf/2306.05685.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.05685)), ([:house:](https://huggingface.co/papers/2306.05685)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/judging-llm-as-a-judge-with-mt-bench-and)), ([:octocat:](https://github.com/lm-sys/fastchat)![GitHub Repo stars](https://img.shields.io/github/stars/lm-sys/fastchat?style=social)) |
| 6.9 | Evaluating the Social Impact of Generative AI Systems in Systems and Society ([:x:](https://arxiv.org/abs/2306.05949)), ([:paperclip:](https://arxiv.org/pdf/2306.05949.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.05949)), ([:house:](https://huggingface.co/papers/2306.05949)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/evaluating-the-social-impact-of-generative-ai)) |
| 6.9 | Can Large Language Models Infer Causation from Correlation? ([:x:](https://arxiv.org/abs/2306.05836)), ([:paperclip:](https://arxiv.org/pdf/2306.05836.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.05836)), ([:house:](https://huggingface.co/papers/2306.05836)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/can-large-language-models-infer-causation)), ([:octocat:](https://github.com/causalNLP/corr2cause)![GitHub Repo stars](https://img.shields.io/github/stars/causalNLP/corr2cause?style=social)) |
| 6.9 | FinGPT: Open-Source Financial Large Language Models ([:x:](https://arxiv.org/abs/2306.06031)), ([:paperclip:](https://arxiv.org/pdf/2306.06031.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.06031)), ([:house:](https://huggingface.co/papers/2306.06031)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/fingpt-open-source-financial-large-language)), ([:octocat:](https://github.com/AI4Finance-Foundation/FinGPT)![GitHub Repo stars](https://img.shields.io/github/stars/AI4Finance-Foundation/FinGPT?style=social)) |
| 6.8 | On the Reliability of Watermarks for Large Language Models ([:x:](https://arxiv.org/abs/2306.04634)), ([:paperclip:](https://arxiv.org/pdf/2306.04634.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.04634)), ([:house:](https://huggingface.co/papers/2306.04634)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/on-the-reliability-of-watermarks-for-large)), ([:octocat:](https://github.com/jwkirchenbauer/lm-watermarking)![GitHub Repo stars](https://img.shields.io/github/stars/jwkirchenbauer/lm-watermarking?style=social)) |
| 6.8 | PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization ([:x:](https://arxiv.org/abs/2306.05087)), ([:paperclip:](https://arxiv.org/pdf/2306.05087.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.05087)), ([:house:](https://huggingface.co/papers/2306.05087)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/pandalm-an-automatic-evaluation-benchmark-for)), ([:octocat:](https://github.com/weopenml/pandalm)![GitHub Repo stars](https://img.shields.io/github/stars/weopenml/pandalm?style=social)) |
| 6.8 | How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources ([:x:](https://arxiv.org/abs/2306.04751)), ([:paperclip:](https://arxiv.org/pdf/2306.04751.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.04751)), ([:house:](https://huggingface.co/papers/2306.04751)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/how-far-can-camels-go-exploring-the-state-of)) |
| 6.8 | StableDiffusion - Clipdrop Launches Uncrop: The Ultimate Aspect Ratio Editor ([blog](https://stability.ai/blog/clipdrop-launches-uncrop-the-ultimate-aspect-ratio-editor)) |
| 6.8 | Video-ChatGPT: Towards Detailed Video Understanding via Large Vision and Language Models ([:x:](https://arxiv.org/abs/2306.05424)), ([:paperclip:](https://arxiv.org/pdf/2306.05424.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.05424)), ([:house:](https://huggingface.co/papers/2306.05424)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/video-chatgpt-towards-detailed-video)), ([:octocat:](https://github.com/mbzuai-oryx/video-chatgpt)![GitHub Repo stars](https://img.shields.io/github/stars/mbzuai-oryx/video-chatgpt?style=social)) |
| 6.8 | Simple and Controllable Music Generation ([:x:](https://arxiv.org/abs/2306.05284)), ([:paperclip:](https://arxiv.org/pdf/2306.05284.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.05284)), ([:house:](https://huggingface.co/papers/2306.05284)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/simple-and-controllable-music-generation)), ([:octocat:](https://github.com/facebookresearch/audiocraft)![GitHub Repo stars](https://img.shields.io/github/stars/facebookresearch/audiocraft?style=social)) |
| 6.8 | Tracking Everything Everywhere All at Once ([project page](https://omnimotion.github.io/)), ([:x:](https://arxiv.org/abs/2306.05422)), ([:paperclip:](https://arxiv.org/pdf/2306.05422.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.05422)), ([:house:](https://huggingface.co/papers/2306.05422)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/tracking-everything-everywhere-all-at-once)), ([:octocat:](https://github.com/qianqianwang68/omnimotion)![GitHub Repo stars](https://img.shields.io/github/stars/qianqianwang68/omnimotion?style=social) |
| 6.8 | Understanding GPT tokenizers ([blog](https://simonwillison.net/2023/Jun/8/gpt-tokenizers/)) |
| 6.7 | Health system-scale language models are all-purpose prediction engines (Nature [https://doi.org/10.1038/s41586-023-06160-y](https://www.nature.com/articles/s41586-023-06160-y#citeas)), ([:paperclip:](https://www.nature.com/articles/s41586-023-06160-y.pdf?pdf=button%20sticky)), ([:octocat:](https://github.com/nyuolab/NYUTron)![GitHub Repo stars](https://img.shields.io/github/stars/nyuolab/NYUTron?style=social) |
| 6.7 | Learning to Ground Instructional Articles in Videos through Narrations ([:x:](https://arxiv.org/abs/2306.03802)), ([:paperclip:](https://arxiv.org/pdf/2306.03802.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03802)), ([:house:](https://huggingface.co/papers/2306.03802)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/learning-to-ground-instructional-articles-in)) |
| 6.7 | Emergent Correspondence from Image Diffusion ([:x:](https://arxiv.org/abs/2306.03881)), ([:paperclip:](https://arxiv.org/pdf/2306.03881.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03881)), ([:house:](https://huggingface.co/papers/2306.03881)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/emergent-correspondence-from-image-diffusion)) |
| 6.7 | Certified Reasoning with Language Models ([:x:](https://arxiv.org/abs/2306.04031)), ([:paperclip:](https://arxiv.org/pdf/2306.04031.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.04031)), ([:house:](https://huggingface.co/papers/2306.04031)), ([:eight_spoked_asterisk:]()) |
| 6.7 | Increasing Diversity While Maintaining Accuracy: Text Data Generation with Large Language Models and Human Interventions  ([:x:](https://arxiv.org/abs/2306.04140)), ([:paperclip:](https://arxiv.org/pdf/2306.04140.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.04140)), ([:house:](https://huggingface.co/papers/2306.04140)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/increasing-diversity-while-maintaining)) |
| 6.7 | Youku-mPLUG: A 10 Million Large-scale Chinese Video-Language Dataset for Pre-training and Benchmarks ([:x:](https://arxiv.org/abs/2306.04362)), ([:paperclip:](https://arxiv.org/pdf/2306.04362.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.04362)), ([:house:](https://huggingface.co/papers/2306.04362)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/youku-mplug-a-10-million-large-scale-chinese)), ([:octocat:](https://github.com/x-plug/youku-mplug)![GitHub Repo stars](https://img.shields.io/github/stars/x-plug/youku-mplug?style=social) |
| 6.7 | M$^3$IT: A Large-Scale Dataset towards Multi-Modal Multilingual Instruction Tuning ([:x:](https://arxiv.org/abs/2306.04387)), ([:paperclip:](https://arxiv.org/pdf/2306.04387.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.04387)), ([:house:](https://huggingface.co/papers/2306.04387)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/m-3-it-a-large-scale-dataset-towards-multi)) |
| 6.7 | PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts ([:x:](https://arxiv.org/abs/2306.04528)), ([:paperclip:](https://arxiv.org/pdf/2306.04528.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.04528)), ([:house:](https://huggingface.co/papers/2306.04528)), ([:eight_spoked_asterisk:]()), ([:octocat:](https://github.com/microsoft/promptbench)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/promptbench?style=social) |
| 6.7 | INSTRUCTEVAL: Towards Holistic Evaluation of Instruction-Tuned Large Language Models ([:x:](https://arxiv.org/abs/2306.04757)), ([:paperclip:](https://arxiv.org/pdf/2306.04757.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.04757)), ([:house:](https://huggingface.co/papers/2306.04757)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/promptbench-towards-evaluating-the-robustness)), ([:octocat:](https://github.com/declare-lab/instruct-eval)![GitHub Repo stars](https://img.shields.io/github/stars/declare-lab/instruct-eval?style=social)) |
| 6.7 | ChatGPT is fun, but it is not funny! Humor is still challenging Large Language Models ([:x:](https://arxiv.org/abs/2306.04563)), ([:paperclip:](https://arxiv.org/pdf/2306.04563.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.04563)), ([:house:](https://huggingface.co/papers/2306.04563)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/chatgpt-is-fun-but-it-is-not-funny-humor-is)) |
| 6.7 | Deductive Verification of Chain-of-Thought Reasoning ([:x:](https://arxiv.org/abs/2306.03872)), ([:paperclip:](https://arxiv.org/pdf/2306.03872.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03872)), ([:house:](https://huggingface.co/papers/2306.03872)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/deductive-verification-of-chain-of-thought)), ([:octocat:](https://github.com/lz1oceani/verify_cot)![GitHub Repo stars](https://img.shields.io/github/stars/lz1oceani/verify_cot?style=social))  |
| 6.6 | ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory ([:x:](https://arxiv.org/abs/2306.03901)), ([:paperclip:](https://arxiv.org/pdf/2306.03901.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03901)), ([:house:](https://huggingface.co/papers/2306.03901)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/chatdb-augmenting-llms-with-databases-as)) |
| 6.6 | InstructZero: Efficient Instruction Optimization for Black-Box Large Language Models ([:x:](https://arxiv.org/abs/2306.03082)), ([:paperclip:](https://arxiv.org/pdf/2306.03082.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03082)), ([:house:](https://huggingface.co/papers/2306.03082)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/instructzero-efficient-instruction)), ([:octocat:](https://github.comlichang-chen/instructzero)![GitHub Repo stars](https://img.shields.io/github/stars/lichang-chen/instructzero?style=social)) |
| 6.6 | HeadSculpt: Crafting 3D Head Avatars with Text ([:x:](https://arxiv.org/abs/2306.03038)), ([:paperclip:](https://arxiv.org/pdf/2306.03038.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03038)), ([:house:](https://huggingface.co/papers/2306.03038)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/headsculpt-crafting-3d-head-avatars-with-text)) |
| 6.6 | MotionDiffuser: Controllable Multi-Agent Motion Prediction using Diffusion ([:x:](https://arxiv.org/abs/2306.03083)), ([:paperclip:](https://arxiv.org/pdf/2306.03083.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03083)), ([:house:](https://huggingface.co/papers/2306.03083)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/motiondiffuser-controllable-multi-agent-1)) |
| 6.6 | Neuralangelo: High-Fidelity Neural Surface Reconstruction ([:x:](https://arxiv.org/abs/2306.03092)), ([:paperclip:](https://arxiv.org/pdf/2306.03092.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03092)), ([:house:](https://huggingface.co/papers/2306.03092)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/neuralangelo-high-fidelity-neural-surface-1)) |
| 6.6 | PokemonChat: Auditing ChatGPT for Pokémon Universe Knowledge ([:x:](https://arxiv.org/abs/2306.03024)), ([:paperclip:](https://arxiv.org/pdf/2306.03024.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03024)), ([:house:](https://huggingface.co/papers/2306.03024)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/pokemonchat-auditing-chatgpt-for-pokemon)) |
| 6.6 | A Static Evaluation of Code Completion by Large Language Models ([:x:](https://arxiv.org/abs/2306.03203)), ([:paperclip:](https://arxiv.org/pdf/2306.03203.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03203)), ([:house:](https://huggingface.co/papers/2306.03203)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-static-evaluation-of-code-completion-by)) |
| 6.6 | Large Language Models of Code Fail at Completing Code with Potential Bugs  ([:x:](https://arxiv.org/abs/2306.03438)), ([:paperclip:](https://arxiv.org/pdf/2306.03438.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03438)), ([:house:](https://huggingface.co/papers/2306.03438)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/large-language-models-of-code-fail-at)) |
| 6.6 | Mega-TTS: Zero-Shot Text-to-Speech at Scale with Intrinsic Inductive Bias ([:x:](https://arxiv.org/abs/2306.03509)), ([:paperclip:](https://arxiv.org/pdf/2306.03509.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03509)), ([:house:](https://huggingface.co/papers/2306.03509)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/mega-tts-zero-shot-text-to-speech-at-scale)) |
| 6.6 | Ada-TTA: Towards Adaptive High-Quality Text-to-Talking Avatar Synthesis ([:x:](https://arxiv.org/abs/2306.03504)), ([:paperclip:](https://arxiv.org/pdf/2306.03504.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03504)), ([:house:](https://huggingface.co/papers/2306.03504)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/ada-tta-towards-adaptive-high-quality-text-to)) |
| 6.6 | Recognize Anything: A Strong Image Tagging Model ([:x:](https://arxiv.org/abs/2306.03514)), ([:paperclip:](https://arxiv.org/pdf/2306.03514.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.03514)), ([:house:](https://huggingface.co/papers/2306.03514)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/recognize-anything-a-strong-image-tagging)), ([:octocat:](https://github.com/xinyu1205/recognize-anything)![GitHub Repo stars](https://img.shields.io/github/stars/xinyu1205/recognize-anything?style=social)) |
| 6.6 | ATT3D: Amortized Text-to-3D Object Synthesis ([:x:](https://arxiv.org/abs/2306.07349)), ([:paperclip:](https://arxiv.org/pdf/2306.07349.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.07349)), ([:house:](https://huggingface.co/papers/2306.07349)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/att3d-amortized-text-to-3d-object-synthesis)) |
| 6.6 | Falcon-40B-Instruct is a 40B parameters causal decoder-only model built by TII based on Falcon-40B and finetuned on a mixture of Baize ([HF](https://huggingface.co/tiiuae/falcon-40b-instruct)) |
| 6.5 | A survey of Generative AI Applications ([:x:](https://arxiv.org/abs/2306.02781)), ([:paperclip:](https://arxiv.org/pdf/2306.02781.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.02781)), ([:house:](https://huggingface.co/papers/2306.02781)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-survey-of-generative-ai-applications)) |
| 6.5 | New Artificial Intelligence ChatGPT Performs Poorly on the 2022 Self-assessment Study Program for Urology (AUA Urology practice [https://doi.org/10.1097/UPJ.0000000000000406](https://www.auajournals.org/doi/10.1097/UPJ.0000000000000406)) |
| 6.5 | LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion ([:x:](https://arxiv.org/abs/2306.02561)), ([:paperclip:](https://arxiv.org/pdf/2306.02561.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.02561)), ([:house:](https://huggingface.co/papers/2306.02561)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/llm-blender-ensembling-large-language-models)) |
| 6.5 | Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding ([:x:](https://arxiv.org/abs/2306.02858)), ([:paperclip:](https://arxiv.org/pdf/2306.02858.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.02858)), ([:house:](https://huggingface.co/papers/2306.02858)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/video-llama-an-instruction-tuned-audio-visual)), ([:octocat:](https://github.com/damo-nlp-sg/video-llama)![GitHub Repo stars](https://img.shields.io/github/stars/damo-nlp-sg/video-llama?style=social)) |
| 6.5 | PLANNER: Generating Diversified Paragraph via Latent Language Diffusion Mode ([:x:](https://arxiv.org/abs/2306.02531)), ([:paperclip:](https://arxiv.org/pdf/2306.02531.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.02531)), ([:house:](https://huggingface.co/papers/2306.02531)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/planner-generating-diversified-paragraph-via)) |
| 6.5 | Orca: Progressive Learning from Complex Explanation Traces of GPT-4 ([:x:](https://arxiv.org/abs/2306.02707)), ([:paperclip:](https://arxiv.org/pdf/2306.02707.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.02707)), ([:house:](https://huggingface.co/papers/2306.02707)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/orca-progressive-learning-from-complex)) |
| 6.4 | SAM3D: Zero-Shot 3D Object Detection via Segment Anything Model  ([:x:](https://arxiv.org/abs/2306.02245)), ([:paperclip:](https://arxiv.org/pdf/2306.02245.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.02245)), ([:house:](https://huggingface.co/papers/2306.02245)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/sam3d-zero-shot-3d-object-detection-via)), ([:octocat:](https://github.com/dyzhang09/sam3d)![GitHub Repo stars](https://img.shields.io/github/stars/dyzhang09/sam3d?style=social))  |
| 6.4 | A Technical Report for Polyglot-Ko: Open-Source Large-Scale Korean Language Models ([:x:](https://arxiv.org/abs/2306.02254)), ([:paperclip:](https://arxiv.org/pdf/2306.02254.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.02254)), ([:house:](https://huggingface.co/papers/2306.02254)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-technical-report-for-polyglot-ko-open)) |
| 6.3 | The Role of ChatGPT, Generative Language Models, and Artificial Intelligence in Medical Education: A Conversation With ChatGPT and a Call for Papers (JMIR, [doi: 10.2196/46885](https://mededu.jmir.org/2023/1/e46885)), ([PDF](https://mededu.jmir.org/2023/1/e46885/PDF)) |
| 6.3 | VisualGPTScore: Visio-Linguistic Reasoning with Multimodal Generative Pre-Training Scores ([:x:](https://arxiv.org/abs/2306.01879)), ([:paperclip:](https://arxiv.org/pdf/2306.01879.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.01879)), ([:house:](https://huggingface.co/papers/2306.01879)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/visualgptscore-visio-linguistic-reasoning)) |
| 6.2 | Segment Anything in High Quality ([:x:](https://arxiv.org/abs/2306.01567)), ([:paperclip:](https://arxiv.org/pdf/2306.01567.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.01567)), ([:house:](https://huggingface.co/papers/2306.01567)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/segment-anything-in-high-quality)), ([:octocat:](https://github.com/syscv/sam-hq)![GitHub Repo stars](https://img.shields.io/github/stars/syscv/sam-hq?style=social)) |
| 6.2 | The RefinedWeb Dataset for Falcon LLM: Outperforming Curated Corpora with Web Data, and Web Data Only ([:x:](https://arxiv.org/abs/2306.01116)), ([:paperclip:](https://arxiv.org/pdf/2306.01116.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.01116)), ([:house:](https://huggingface.co/papers/2306.01116)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/the-refinedweb-dataset-for-falcon-llm)) |
| 6.2 | StyleDrop: Text-To-Image Generation in Any Style ([project page](https://styledrop.github.io/)), ([:x:](https://arxiv.org/abs/2306.00983)), ([:paperclip:](https://arxiv.org/pdf/2306.00983.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00983)), ([:house:](https://huggingface.co/papers/2306.00983)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/styledrop-text-to-image-generation-in-any)) |
| 6.1 | StableRep: Synthetic Images from Text-to-Image Models Make Strong Visual Representation Learners ([:x:](https://arxiv.org/abs/2306.00984)), ([:paperclip:](https://arxiv.org/pdf/2306.00984.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00984)), ([:house:](https://huggingface.co/papers/2306.00984)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/stablerep-synthetic-images-from-text-to-image)) |
| 6.1 | The TIME - "The End of Humanity" cover ([tweet](https://twitter.com/TIME/status/1663939590908985348)), (["AI Is Not an Arms Race"](https://time.com/6283609/artificial-intelligence-race-existential-threat/)) | 
| 6.1 | AutoGPTQ - An easy-to-use LLMs quantization package with user-friendly apis, based on GPTQ algorithm ([:octocat:](https://github.com/PanQiWei/AutoGPTQ)![GitHub Repo stars](https://img.shields.io/github/stars/PanQiWei/AutoGPTQ?style=social)) |
| 6.1 | Wuerstchen: Efficient Pretraining of Text-to-Image Models ([:x:](https://arxiv.org/abs/2306.00637)), ([:paperclip:](https://arxiv.org/pdf/2306.00637.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00637)), ([:house:](https://huggingface.co/papers/2306.00637)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/wuerstchen-efficient-pretraining-of-text-to)) |
| 6.1 | StyleGAN knows Normal, Depth, Albedo, and More ([:x:](https://arxiv.org/abs/2306.00987)), ([:paperclip:](https://arxiv.org/pdf/2306.00987.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00987)), ([:house:](https://huggingface.co/papers/2306.00987)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/stylegan-knows-normal-depth-albedo-and-more)) |
| 6.1 | Diffusion Self-Guidance for Controllable Image Generation ([:x:](https://arxiv.org/abs/2306.00986)), ([:paperclip:](https://arxiv.org/pdf/2306.00986.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00986)), ([:house:](https://huggingface.co/papers/2306.00986)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/diffusion-self-guidance-for-controllable)) |
| 6.1 | Thought Cloning: Learning to Think while Acting by Imitating Human Thinking ([:x:](https://arxiv.org/abs/2306.00323)), ([:paperclip:](https://arxiv.org/pdf/2306.00323.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00323)), ([:house:](https://huggingface.co/papers/2306.00323)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/thought-cloning-learning-to-think-while)), ([:octocat:](https://github.com/ShengranHu/Thought-Cloning)![GitHub Repo stars](https://img.shields.io/github/stars/ShengranHu/Thought-Cloning?style=social)) |
| 6.1 | Hiera: A Hierarchical Vision Transformer without the Bells-and-Whistles ([:x:](https://arxiv.org/abs/2306.00989)), ([:paperclip:](https://arxiv.org/pdf/2306.00989.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00989)), ([:house:](https://huggingface.co/papers/2306.00989)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/hiera-a-hierarchical-vision-transformer)) |
| 6.1 | The Hidden Language of Diffusion Models ([:x:](https://arxiv.org/abs/2306.00966)), ([:paperclip:](https://arxiv.org/pdf/2306.00966.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00966)), ([:house:](https://huggingface.co/papers/2306.00966)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/the-hidden-language-of-diffusion-models)) |
| 6.1 | Inserting Anybody in Diffusion Models via Celeb Basis ([:x:](https://arxiv.org/abs/2306.00926)), ([:paperclip:](https://arxiv.org/pdf/2306.00926.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00926)), ([:house:](https://huggingface.co/papers/2306.00926)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/inserting-anybody-in-diffusion-models-via)), ([project page](https://celeb-basis.github.io/)), ([:octocat:](https://github.com/ygtxr1997/celebbasis)![GitHub Repo stars](https://img.shields.io/github/stars/ygtxr1997/celebbasis?style=social)) |
| 6.1 | LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day ([:x:](https://arxiv.org/abs/2306.00890)), ([:paperclip:](https://arxiv.org/pdf/2306.00890.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00890)), ([:house:](https://huggingface.co/papers/2306.00890)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/llava-med-training-a-large-language-and)), ([:octocat:](https://github.com/microsoft/LLaVA-Med)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/LLaVA-Med?style=social)) |
| 6.1 | Birth of a Transformer: A Memory Viewpoint  ([:x:](https://arxiv.org/abs/2306.00802)), ([:paperclip:](https://arxiv.org/pdf/2306.00802.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00802)), ([:house:](https://huggingface.co/papers/2306.00802)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/birth-of-a-transformer-a-memory-viewpoint)) |
| 6.1 | SnapFusion: Text-to-Image Diffusion Model on Mobile Devices within Two Seconds ([:x:](https://arxiv.org/abs/2306.00980)), ([:paperclip:](https://arxiv.org/pdf/2306.00980.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00980)), ([:house:](https://huggingface.co/papers/2306.00980)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/snapfusion-text-to-image-diffusion-model-on)) |
| 6.1 | Make-Your-Video: Customized Video Generation Using Textual and Structural Guidance ([:x:](https://arxiv.org/abs/2306.00943)), ([:paperclip:](https://arxiv.org/pdf/2306.00943.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00943)), ([:house:](https://huggingface.co/papers/2306.00943)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/make-your-video-customized-video-generation)) |
| 6.1 | ReviewerGPT? An Exploratory Study on Using Large Language Models for Paper Reviewing ([:x:](https://arxiv.org/abs/2306.00622)), ([:paperclip:](https://arxiv.org/pdf/2306.00622.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00622)), ([:house:](https://huggingface.co/papers/2306.00622)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/reviewergpt-an-exploratory-study-on-using)) |
| 5.31 | The Impact of Positional Encoding on Length Generalization in Transformers ([:x:](https://arxiv.org/abs/2305.19466)), ([:paperclip:](https://arxiv.org/pdf/2305.19466.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.19466)), ([:house:](https://huggingface.co/papers/2305.19466)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/the-impact-of-positional-encoding-on-length)), ([:octocat:](https://github.com/mcgill-nlp/length-generalization)![GitHub Repo stars](https://img.shields.io/github/stars/mcgill-nlp/length-generalization?style=social)) |
| 5.31 | Tree-Ring Watermarks: Fingerprints for Diffusion Images that are Invisible and Robust ([:x:](https://arxiv.org/abs/2305.20030)), ([:paperclip:](https://arxiv.org/pdf/2305.20030.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.20030)), ([:house:](https://huggingface.co/papers/2305.20030)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/tree-ring-watermarks-fingerprints-for)), ([:octocat:](https://github.com/YuxinWenRick/tree-ring-watermark)![GitHub Repo stars](https://img.shields.io/github/stars/YuxinWenRick/tree-ring-watermark?style=social)) |
| 5.31 | Discovering New Interpretable Conservation Laws as Sparse Invariants ([:x:](https://arxiv.org/abs/2305.19525)), ([:paperclip:](https://arxiv.org/pdf/2305.19525.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.19525)), ([:house:](https://huggingface.co/papers/2305.19525)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/discovering-new-interpretable-conservation)) |
| 5.31 | Control4D: Dynamic Portrait Editing by Learning 4D GAN from 2D Diffusion-based Editor ([:x:](https://arxiv.org/abs/2305.20082)), ([:paperclip:](https://arxiv.org/pdf/2305.20082.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.20082)), ([:house:](https://huggingface.co/papers/2305.20082)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/control4d-dynamic-portrait-editing-by)) |
| 5.31 | Understanding and Mitigating Copying in Diffusion Models ([:x:](https://arxiv.org/abs/2305.20086)), ([:paperclip:](https://arxiv.org/pdf/2305.20086.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.20086)), ([:house:](https://huggingface.co/papers/2305.20086)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/understanding-and-mitigating-copying-in)) |
| 5.31 | PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning ([:x:](https://arxiv.org/abs/2305.19472)), ([:paperclip:](https://arxiv.org/pdf/2305.19472.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.19472)), ([:house:](https://huggingface.co/papers/2305.19472)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/plasma-making-small-language-models-better)) |
| 5.31 | Human or Not? A Gamified Approach to the Turing Test ([:x:](https://arxiv.org/abs/2305.20010)), ([:paperclip:](https://arxiv.org/pdf/2305.20010.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.20010)), ([:house:](https://huggingface.co/papers/2305.20010)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/human-or-not-a-gamified-approach-to-the)) |
| 5.31 | OpenAI - Let’s Verify Step by Step ([paper](https://cdn.openai.com/improving-mathematical-reasoning-with-process-supervision/Lets_Verify_Step_by_Step.pdf)), ([:x:](https://arxiv.org/abs/2305.20050)), ([:paperclip:](https://arxiv.org/pdf/2305.20050.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.20050)), ([:house:](https://huggingface.co/papers/2305.20050)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/let-s-verify-step-by-step-1)), ([blog](https://openai.com/research/improving-mathematical-reasoning-with-process-supervision)), ([GitHub dataset](https://github.com/openai/prm800k)![GitHub Repo stars](https://img.shields.io/github/stars/openai/prm800k?style=social)) | 
| 5.31 | Humans in 4D: Reconstructing and Tracking Humans with Transformers ([:x:](https://arxiv.org/abs/2306.20091)), ([:paperclip:](https://arxiv.org/pdf/2306.20091.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.20091)), ([:house:](https://huggingface.co/papers/2306.20091)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/humans-in-4d-reconstructing-and-tracking)), ([:octocat:](https://github.com/shubham-goel/4D-Humans)![GitHub Repo stars](https://img.shields.io/github/stars/shubham-goel/4D-Humans?style=social)) |
| 5.31 | Improving CLIP Training with Language Rewrites ([:x:](https://arxiv.org/abs/2306.20088)), ([:paperclip:](https://arxiv.org/pdf/2306.20088.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.20088)), ([:house:](https://huggingface.co/papers/2306.20088)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/improving-clip-training-with-language)) |
| 5.31 | MuseCoco: Generating Symbolic Music from Text ([:x:](https://arxiv.org/abs/2306.00110)), ([:paperclip:](https://arxiv.org/pdf/2306.00110.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00110)), ([:house:](https://huggingface.co/papers/2306.00110)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/musecoco-generating-symbolic-music-from-text)) |
| 5.31 | MERT: Acoustic Music Understanding Model with Large-Scale Self-supervised Training ([:x:](https://arxiv.org/abs/2306.00107)), ([:paperclip:](https://arxiv.org/pdf/2306.00107.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00107)), ([:house:](https://huggingface.co/papers/2306.00107)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/mert-acoustic-music-understanding-model-with)), ([:octocat:](https://github.com/yizhilll/mert)![GitHub Repo stars](https://img.shields.io/github/stars/yizhilll/mert?style=social)) |
| 5.31 | CodeTF: One-stop Transformer Library for State-of-the-art Code LLM ([:x:](https://arxiv.org/abs/2306.00029)), ([:paperclip:](https://arxiv.org/pdf/2306.00029.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00029)), ([:house:](https://huggingface.co/papers/2306.00029)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/codetf-one-stop-transformer-library-for-state)), ([:octocat:](https://github.com/salesforce/codetf)![GitHub Repo stars](https://img.shields.io/github/stars/salesforce/codetf?style=social)) |
| 5.30 | Prompt Engineering for Effective Use of Large Language Models in Radiology ([RSNA](https://pubs.rsna.org/page/ai/blog/2023/05/ryai_editorsblog053023)) |
| 5.30 | Re-evaluating Word Mover's Distance ([:x:](https://arxiv.org/abs/2305.14403)), ([:paperclip:](https://arxiv.org/pdf/2305.14403.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14403)), ([:house:](https://huggingface.co/papers/2305.14403)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/re-evaluating-word-mover-s-distance)), ([:octocat:](https://github.com/joisino/reeval-wmd)![GitHub Repo stars](https://img.shields.io/github/stars/joisino/reeval-wmd?style=social)) |
| 5.30 | Bigger, Better, Faster: Human-level Atari with human-level efficiency ([:x:](https://arxiv.org/abs/2305.19452)), ([:paperclip:](https://arxiv.org/pdf/2305.19452.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.19452)), ([:house:](https://huggingface.co/papers/2305.19452)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/bigger-better-faster-human-level-atari-with)), ([:octocat:](https://github.com/google-research/google-research)![GitHub Repo stars](https://img.shields.io/github/stars/google-research/google-research?style=social)) |
| 5.30 | Japan Goes All In: Copyright Doesn’t Apply To AI Training ([news](https://technomancers.ai/japan-goes-all-in-copyright-doesnt-apply-to-ai-training/)) |
| 5.30 | A.I. Poses ‘Risk of Extinction,’ Industry Leaders Warn - ([NYT news](https://www.nytimes.com/2023/05/30/technology/ai-threat-warning.html)) |
| 5.30 | Statement on AI Risk - AI experts and public figures express their concern about AI risk ([statement](https://www.safe.ai/statement-on-ai-risk)) | 
| 5.30 | GPT4Tools: Teaching Large Language Model to Use Tools via Self-instruction ([:x:](https://arxiv.org/abs/2305.18752)), ([:paperclip:](https://arxiv.org/pdf/2305.18752.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18752)), ([:house:](https://huggingface.co/papers/2305.18752)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/gpt4tools-teaching-large-language-model-to)), ([:octocat:](https://github.com/stevengrove/gpt4tools)![GitHub Repo stars](https://img.shields.io/github/stars/stevengrove/gpt4tools?style=social)) |
| 5.30 | Nested Diffusion Processes for Anytime Image Generation ([:x:](https://arxiv.org/abs/2305.19066)), ([:paperclip:](https://arxiv.org/pdf/2305.19066.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.19066)), ([:house:](https://huggingface.co/papers/2305.19066)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/nested-diffusion-processes-for-anytime-image)) |
| 5.30 | StyleAvatar3D: Leveraging Image-Text Diffusion Models for High-Fidelity 3D Avatar Generation ([:x:](https://arxiv.org/abs/2305.19012)), ([:paperclip:](https://arxiv.org/pdf/2305.19012.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.19012)), ([:house:](https://huggingface.co/papers/2305.19012)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/styleavatar3d-leveraging-image-text-diffusion)), ([GitHub dataset](https://github.com/icoz69/styleavatar3d)![GitHub Repo stars](https://img.shields.io/github/stars/icoz69/styleavatar3d?style=social))  |
| 5.30 | HiFA: High-fidelity Text-to-3D with Advanced Diffusion Guidance ([:x:](https://arxiv.org/abs/2305.18766)), ([:paperclip:](https://arxiv.org/pdf/2305.18766.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18766)), ([:house:](https://huggingface.co/papers/2305.18766)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/hifa-high-fidelity-text-to-3d-with-advanced)) |
| 5.30 | Grammar Prompting for Domain-Specific Language Generation with Large Language Models ([:x:](https://arxiv.org/abs/2305.19234)), ([:paperclip:](https://arxiv.org/pdf/2305.19234.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.19234)), ([:house:](https://huggingface.co/papers/2305.19234)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/grammar-prompting-for-domain-specific)) |
| 5.30 | AlteredAvatar: Stylizing Dynamic 3D Avatars with Fast Style Adaptation  ([:x:](https://arxiv.org/abs/2305.19245)), ([:paperclip:](https://arxiv.org/pdf/2305.19245.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.19245)), ([:house:](https://huggingface.co/papers/2305.19245)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/alteredavatar-stylizing-dynamic-3d-avatars)) |
| 5.30 | Ambient Diffusion: Learning Clean Distributions from Corrupted Data  ([:x:](https://arxiv.org/abs/2305.19256)), ([:paperclip:](https://arxiv.org/pdf/2305.19256.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.19256)), ([:house:](https://huggingface.co/papers/2305.19256)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/ambient-diffusion-learning-clean)), ([:octocat:](https://github.com/giannisdaras/ambient-diffusion)![GitHub Repo stars](https://img.shields.io/github/stars/giannisdaras/ambient-diffusion?style=social)) |
| 5.30 | ChatGPT and large language models in gastroenterology, ([Nature Reviews Gastroenterology & Hepatology](https://www.nature.com/articles/s41575-023-00799-8)) |
| 5.30 | Blockwise Parallel Transformer for Long Context Large Models ([:x:](https://arxiv.org/abs/2305.19370)), ([:paperclip:](https://arxiv.org/pdf/2305.19370.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.19370)), ([:house:](https://huggingface.co/papers/2305.19370)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/blockwise-parallel-transformer-for-long)) |
| 5.29 | A lawyer used ChatGPT to prepare a court filing. It went horribly awry. ([CBS news](https://www.cbsnews.com/news/lawyer-chatgpt-court-filing-avianca/)) |
| 5.29 | Reconstructing the Mind's Eye: fMRI-to-Image with Contrastive Learning and Diffusion Priors ([:x:](https://arxiv.org/abs/2305.18274)), ([:paperclip:](https://arxiv.org/pdf/2305.18274.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18274)), ([:house:](https://huggingface.co/papers/2305.18274)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/reconstructing-the-mind-s-eye-fmri-to-image)), ([:octocat:](https://github.com/medarc-ai/fmri-reconstruction-nsd)![GitHub Repo stars](https://img.shields.io/github/stars/medarc-ai/fmri-reconstruction-nsd?style=social)) |
| 5.29 | RAPHAEL: Text-to-Image Generation via Large Mixture of Diffusion Paths ([:x:](https://arxiv.org/abs/2305.18295)), ([:paperclip:](https://arxiv.org/pdf/2305.18295.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18295)), ([:house:](https://huggingface.co/papers/2305.18295)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/raphael-text-to-image-generation-via-large)) |
| 5.29 | Photoswap: Personalized Subject Swapping in Images ([:x:](https://arxiv.org/abs/2305.18286)), ([:paperclip:](https://arxiv.org/pdf/2305.18286.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18286)), ([:house:](https://huggingface.co/papers/2305.18286)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/photoswap-personalized-subject-swapping-in)) |
| 5.29 | TaleCrafter: Interactive Story Visualization with Multiple Characters ([:x:](https://arxiv.org/abs/2305.18247)), ([:paperclip:](https://arxiv.org/pdf/2305.18247.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18247)), ([:house:](https://huggingface.co/papers/2305.18247)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/talecrafter-interactive-story-visualization)), ([:octocat:](https://github.com/videocrafter/talecrafter)![GitHub Repo stars](https://img.shields.io/github/stars/videocrafter/talecrafter?style=social)) |
| 5.29 | GlyphControl: Glyph Conditional Control for Visual Text Generation ([:x:](https://arxiv.org/abs/2305.18259)), ([:paperclip:](https://arxiv.org/pdf/2305.18259.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18259)), ([:house:](https://huggingface.co/papers/2305.18259)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/glyphcontrol-glyph-conditional-control-for)) |
| 5.29 | Make-An-Audio 2: Temporal-Enhanced Text-to-Audio Generation ([:x:](https://arxiv.org/abs/2305.18474)), ([:paperclip:](https://arxiv.org/pdf/2305.18474.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18474)), ([:house:](https://huggingface.co/papers/2305.18474)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/make-an-audio-2-temporal-enhanced-text-to)) |
| 5.29 | Faith and Fate: Limits of Transformers on Compositionality  ([:x:](https://arxiv.org/abs/2305.18654)), ([:paperclip:](https://arxiv.org/pdf/2305.18654.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18654)), ([:house:](https://huggingface.co/papers/2305.18654)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/faith-and-fate-limits-of-transformers-on)) |
| 5.29 | PaLI-X: On Scaling up a Multilingual Vision and Language Model ([:x:](https://arxiv.org/abs/2305.18565)), ([:paperclip:](https://arxiv.org/pdf/2305.18565.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18565)), ([:house:](https://huggingface.co/papers/2305.18565)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/pali-x-on-scaling-up-a-multilingual-vision)) |
| 5.29 | Controllable Text-to-Image Generation with GPT-4  ([:x:](https://arxiv.org/abs/2305.18583)), ([:paperclip:](https://arxiv.org/pdf/2305.18583.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18583)), ([:house:](https://huggingface.co/papers/2305.18583)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/controllable-text-to-image-generation-with)) |
| 5.29 | Brainformers: Trading Simplicity for Efficiency ([:x:](https://arxiv.org/abs/2306.00008)), ([:paperclip:](https://arxiv.org/pdf/2306.00008.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.00008)), ([:house:](https://huggingface.co/papers/2306.00008)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/brainformers-trading-simplicity-for)) |
| 5.28 | Geometric Algebra Transformers ([:x:](https://arxiv.org/abs/2305.18415)), ([:paperclip:](https://arxiv.org/pdf/2305.18415.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18415)), ([:house:](https://huggingface.co/papers/2305.18415)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/geometric-algebra-transformers)) |
| 5.28 | Tab-CoT: Zero-shot Tabular Chain of Thought ([:x:](https://arxiv.org/abs/2305.17812)), ([:paperclip:](https://arxiv.org/pdf/2305.17812.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17812)), ([:house:](https://huggingface.co/papers/2305.17812)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/tab-cot-zero-shot-tabular-chain-of-thought)) |
| 5.28 | Tab-CoT: Zero-shot Tabular Chain of Thought ([:x:](https://arxiv.org/abs/2305.17812)), ([:paperclip:](https://arxiv.org/pdf/2305.17812.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17812)), ([:house:](https://huggingface.co/papers/2305.17812)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/tab-cot-zero-shot-tabular-chain-of-thought)) |
| 5.28 | FuseCap: Leveraging Large Language Models to Fuse Visual Data into Enriched Image Captions ([:x:](https://arxiv.org/abs/2305.17718)), ([:paperclip:](https://arxiv.org/pdf/2305.17718.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17718)), ([:house:](https://huggingface.co/papers/2305.17718)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/fusecap-leveraging-large-language-models-to)), ([demo](https://huggingface.co/spaces/Xalphinions/tab-cot)) |
| 5.28 | Introducing NVIDIA ACE For Games - Spark Life Into Virtual Characters With Generative AI ([blog](https://www.nvidia.com/en-us/geforce/news/nvidia-ace-for-games-generative-ai-npcs/)) |
| 5.27 | SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks ([:x:](https://arxiv.org/abs/2305.17390)), ([:paperclip:](https://arxiv.org/pdf/2305.17390.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17390)), ([:house:](https://huggingface.co/papers/2305.17390)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/swiftsage-a-generative-agent-with-fast-and)) |
| 5.27 | The Curse of Recursion: Training on Generated Data Makes Models Forget ([:x:](https://arxiv.org/abs/2305.17493)), ([:paperclip:](https://arxiv.org/pdf/2305.17493.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17493)), ([:house:](https://huggingface.co/papers/2305.17493)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/model-dementia-generated-data-makes-models)) |
| 5.27 | DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of GPT-Generated Text ([:x:](https://arxiv.org/abs/2305.17359)), ([:paperclip:](https://arxiv.org/pdf/2305.17359.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17359)), ([:house:](https://huggingface.co/papers/2305.17359)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/dna-gpt-divergent-n-gram-analysis-for)) |
| 5.27 | What indeed can GPT models do in chemistry? A comprehensive benchmark on eight tasks ([:x:](https://arxiv.org/abs/2305.18365)), ([:paperclip:](https://arxiv.org/pdf/2305.18365.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18365)), ([:house:](https://huggingface.co/papers/2305.18365)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/what-indeed-can-gpt-models-do-in-chemistry-a)) |
| 5.27 | WingmanAI - real-time transcription of audio, integrated with ChatGPT for interactive use ([:octocat:](https://github.com/e-johnstonn/wingmanAI)![GitHub Repo stars](https://img.shields.io/github/stars/e-johnstonn/wingmanAI?style=social)) |
| 5.27 | ToolBench - Large-scale instruction tuning SFT data to equip LLMs with general tool-use capability ([:octocat:](https://github.com/OpenBMB/ToolBench)![GitHub Repo stars](https://img.shields.io/github/stars/OpenBMB/ToolBench?style=social)) |
| 5.27 | G7 officials to hold first meeting on AI regulation next week ([news](https://www.reuters.com/world/g7-officials-hold-first-meeting-ai-regulation-next-week-2023-05-26/)) |
| 5.26 | ChatGPT Fails American College of Gastroenterology Assessment Tests ([news](https://healthitanalytics.com/news/chatgpt-fails-american-college-of-gastroenterology-assessment-tests)) |
| 5.26 | Chain-of-Thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance ([:x:](https://arxiv.org/abs/2305.17306)), ([:paperclip:](https://arxiv.org/pdf/2305.17306.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17306)), ([:house:](https://huggingface.co/papers/2305.17306)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/chain-of-thought-hub-a-continuous-effort-to)), ([:octocat:](https://github.com/franxyao/chain-of-thought-hub)![GitHub Repo stars](https://img.shields.io/github/stars/franxyao/chain-of-thought-hub?style=social)) |
| 5.26 | A new antibiotic, discovered with artificial intelligence, may defeat a dangerous superbug ([CNN news](https://edition.cnn.com/2023/05/25/health/antibiotic-artificial-intelligence-superbug/index.html)) |
| 5.26 | Generating Images with Multimodal Language Models ([:x:](https://arxiv.org/abs/2305.17216)), ([:paperclip:](https://arxiv.org/pdf/2305.17216.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17216)), ([:house:](https://huggingface.co/papers/2305.17216)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/generating-images-with-multimodal-language)), ([:octocat:](https://github.com/kohjingyu/gill)![GitHub Repo stars](https://img.shields.io/github/stars/kohjingyu/gill?style=social)) |
| 5.26 | Backpack Language Models ([:x:](https://arxiv.org/abs/2305.16765)), ([:paperclip:](https://arxiv.org/pdf/2305.16765.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16765)), ([:house:](https://huggingface.co/papers/2305.16765)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/backpack-language-models)) |
| 5.26 | Impossible Distillation: from Low-Quality Model to High-Quality Dataset & Model for Summarization and Paraphrasing ([:x:](https://arxiv.org/abs/2305.16635)), ([:paperclip:](https://arxiv.org/pdf/2305.16635.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16635)), ([:house:](https://huggingface.co/papers/2305.16635)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/impossible-distillation-from-low-quality)) |
| 5.26 | Playing repeated games with Large Language Models ([:x:](https://arxiv.org/abs/2305.16867)), ([:paperclip:](https://arxiv.org/pdf/2305.16867.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16867)), ([:house:](https://huggingface.co/papers/2305.16867)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/playing-repeated-games-with-large-language)) |
| 5.26 | Training Socially Aligned Language Models in Simulated Human Society ([:x:](https://arxiv.org/abs/2305.16960)), ([:paperclip:](https://arxiv.org/pdf/2305.16960.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16960)), ([:house:](https://huggingface.co/papers/2305.16960)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/training-socially-aligned-language-models-in)) |
| 5.26 | BiomedGPT: A Unified and Generalist Biomedical Generative Pre-trained Transformer for Vision, Language, and Multimodal Tasks ([:x:](https://arxiv.org/abs/2305.17100)), ([:paperclip:](https://arxiv.org/pdf/2305.17100.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17100)), ([:house:](https://huggingface.co/papers/2305.17100)) |
| 5.26 | Large Language Models as Tool Makers ([:x:](https://arxiv.org/abs/2305.17126)), ([:paperclip:](https://arxiv.org/pdf/2305.17126.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17126)), ([:house:](https://huggingface.co/papers/2305.17126)) |
| 5.26 | ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation  ([:x:](https://arxiv.org/abs/2305.16213)), ([:paperclip:](https://arxiv.org/pdf/2305.16213.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16213)), ([:house:](https://huggingface.co/papers/2305.16213)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/prolificdreamer-high-fidelity-and-diverse)), ([project page](https://ml.cs.tsinghua.edu.cn/prolificdreamer/)) |
| 5.25 | The Current and Future State of AI Interpretation of Medical Images (NEJM, [DOI: 10.1056/NEJMra2301725](https://www.nejm.org/doi/full/10.1056/NEJMra2301725)) |
| 5.25 | Deep learning-guided discovery of an antibiotic targeting Acinetobacter baumannii, (nature chemical biology [https://doi.org/10.1038/s41589-023-01349-8](https://www.nature.com/articles/s41589-023-01349-8)), ([:octocat:](https://github.com/chemprop/chemprop)![GitHub Repo stars](https://img.shields.io/github/stars/chemprop/chemprop?style=social)), ([Cloned snapshot](https://github.com/GaryLiu152/chemprop_abaucin)) |
| 5.25 | Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory ([:x:](https://arxiv.org/abs/2305.17144)), ([:paperclip:](https://arxiv.org/pdf/2305.17144.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.17144)), ([:house:](https://huggingface.co/papers/2305.17144)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/ghost-in-the-minecraft-generally-capable)), ([:octocat:](https://github.com/opengvlab/gitm)![GitHub Repo stars](https://img.shields.io/github/stars/opengvlab/gitm?style=social)) |
| 5.25 | Role-Play with Large Language Models ([:x:](https://arxiv.org/abs/2305.16367)), ([:paperclip:](https://arxiv.org/pdf/2305.16367.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16367)), ([:house:](https://huggingface.co/papers/2305.16367)) |
| 5.25 | Break-A-Scene: Extracting Multiple Concepts from a Single Image ([:x:](https://arxiv.org/abs/2305.16311)), ([:paperclip:](https://arxiv.org/pdf/2305.16311.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16311)), ([:house:](https://huggingface.co/papers/2305.16311)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/break-a-scene-extracting-multiple-concepts)) |
| 5.25 | Voyager: An Open-Ended Embodied Agent with Large Language Models ([Project page](https://voyager.minedojo.org/)), ([:x:](https://arxiv.org/abs/2305.16291)), ([:paperclip:](https://arxiv.org/pdf/2305.16291.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16291)), ([:house:](https://huggingface.co/papers/2305.16291)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/voyager-an-open-ended-embodied-agent-with)), ([:octocat:](https://github.com/MineDojo/Voyager)![GitHub Repo stars](https://img.shields.io/github/stars/MineDojo/Voyager?style=social)), ([MindDojo](https://minedojo.org/)) |
| 5.25 | Efficient Neural Music Generation ([:x:](https://arxiv.org/abs/2305.15719)), ([:paperclip:](https://arxiv.org/pdf/2305.15719.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15719)), ([:house:](https://huggingface.co/papers/2305.15719)) |
| 5.25 | Custom-Edit: Text-Guided Image Editing with Customized Diffusion Models ([:x:](https://arxiv.org/abs/2305.15779)), ([:paperclip:](https://arxiv.org/pdf/2305.15779.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15779)), ([:house:](https://huggingface.co/papers/2305.15779)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/custom-edit-text-guided-image-editing-with)) |
| 5.25 | On Architectural Compression of Text-to-Image Diffusion Models ([:x:](https://arxiv.org/abs/2305.15798)), ([:paperclip:](https://arxiv.org/pdf/2305.15798.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15798)), ([:house:](https://huggingface.co/papers/2305.15798)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/on-architectural-compression-of-text-to-image)) |
| 5.25 | Prompt-Free Diffusion: Taking "Text" out of Text-to-Image Diffusion Models ([:x:](https://arxiv.org/abs/2305.16223)), ([:paperclip:](https://arxiv.org/pdf/2305.16223.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16223)), ([:house:](https://huggingface.co/papers/2305.16223)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/prompt-free-diffusion-taking-text-out-of-text)), ([:octocat:](https://github.com/SHI-Labs/Prompt-Free-Diffusion)![GitHub Repo stars](https://img.shields.io/github/stars/SHI-Labs/Prompt-Free-Diffusion?style=social)) |
| 5.25 | The False Promise of Imitating Proprietary LLMs ([:x:](https://arxiv.org/abs/2305.15717)), ([:paperclip:](https://arxiv.org/pdf/2305.15717.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15717)), ([:house:](https://huggingface.co/papers/2305.15717)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/the-false-promise-of-imitating-proprietary)) |
| 5.25 | the new Stable Diffusion “Reimagine XL” model on @ClipdropApp x @StabilityAI ([tweet](https://twitter.com/hardmaru/status/1661739577395286022)), ([Clipdrop](https://clipdrop.co/stable-diffusion-reimagine)) |
| 5.25 | Gorilla: Large Language Model Connected with Massive APIs ([tweet](https://twitter.com/shishirpatil_/status/1661780076277678082)), ([project page](https://gorilla.cs.berkeley.edu/)), ([:x:](https://arxiv.org/abs/2305.15334)), ([:paperclip:](https://arxiv.org/pdf/2305.15334.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15334)), ([:house:](https://huggingface.co/papers/2305.15334)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/gorilla-large-language-model-connected-with)), ([:octocat:](https://github.com/ShishirPatil/gorilla)![GitHub Repo stars](https://img.shields.io/github/stars/ShishirPatil/gorilla?style=social)), ([demo video](https://drive.google.com/file/d/1E0k5mG1mTiaz0kukyK1PdeohJipTFh6j/view)), ([discord](https://discord.com/invite/3apqwwME)) |
| 5.25 | OpenAI - Democratic Inputs to AI ([Tweet](https://twitter.com/OpenAI/status/1661811329957781504)), ([Blog](https://openai.com/blog/democratic-inputs-to-ai)) |
| 5.24 | HuatuoGPT, towards Taming Language Model to Be a Doctor ([:x:](https://arxiv.org/abs/2305.15075)), ([:paperclip:](https://arxiv.org/pdf/2305.15075.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15075)), ([:house:](https://huggingface.co/papers/2305.15075)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/huatuogpt-towards-taming-language-model-to-be)), ([:octocat:](https://github.com/freedomintelligence/huatuogpt)![GitHub Repo stars](https://img.shields.io/github/stars/freedomintelligence/huatuogpt?style=social)) |
| 5.24 | Instructions as Backdoors: Backdoor Vulnerabilities of Instruction Tuning for Large Language Models ([:x:](https://arxiv.org/abs/2305.14710)), ([:paperclip:](https://arxiv.org/pdf/2305.14710.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14710)), ([:house:](https://huggingface.co/papers/2305.14710)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/instructions-as-backdoors-backdoor)) |
| 5.24 | Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For Large Language Models ([:x:](https://arxiv.org/abs/2305.15074)), ([:paperclip:](https://arxiv.org/pdf/2305.15074.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15074)), ([:house:](https://huggingface.co/papers/2305.15074)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/have-llms-advanced-enough-a-challenging)) |
| 5.24 | Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models ([:x:](https://arxiv.org/abs/2305.14763)), ([:paperclip:](https://arxiv.org/pdf/2305.14763.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14763)), ([:house:](https://huggingface.co/papers/2305.14763)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/clever-hans-or-neural-theory-of-mind-stress)) |
| 5.24 | A majority of Americans have heard of ChatGPT, but few have tried it themselves ([Pew Research Center news](https://www.pewresearch.org/short-reads/2023/05/24/a-majority-of-americans-have-heard-of-chatgpt-but-few-have-tried-it-themselves/)) |
| 5.24 | Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective ([:x:](https://arxiv.org/abs/2305.16338)), ([:paperclip:](https://arxiv.org/pdf/2305.16338.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16338)), ([:house:](https://huggingface.co/papers/2305.16338)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/towards-revealing-the-mystery-behind-chain-of)) |
| 5.24 | Think Before You Act: Decision Transformers with Internal Working Memory ([:x:](https://arxiv.org/abs/2305.15408)), ([:paperclip:](https://arxiv.org/pdf/2305.15408.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15408)), ([:house:](https://huggingface.co/papers/2305.15408)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/think-before-you-act-decision-transformers)) |
| 5.24 | PandaGPT: One Model to Instruction-Follow Them All ([project page](https://panda-gpt.github.io/)), ([:paperclip:](https://github.com/yxuansu/PandaGPT/blob/main/PandaGPT.pdf)), ([demo](https://huggingface.co/spaces/GMFTBY/PandaGPT)), ([video](https://www.youtube.com/watch?v=96XgdQle7EY)), ([dataset](https://huggingface.co/datasets/openllmplayground/pandagpt_visual_instruction_dataset)), ([model](https://huggingface.co/openllmplayground/pandagpt_13b_max_len_400)), ([:octocat:](https://github.com/yxuansu/PandaGPT)![GitHub Repo stars](https://img.shields.io/github/stars/yxuansu/PandaGPT?style=social)), ([tweet](https://twitter.com/yixuan_su/status/1661064018868551691)) |
| 5.24 | SPRING: GPT-4 Out-performs RL Algorithms by Studying Papers and Reasoning ([:x:](https://arxiv.org/abs/2305.15486)), ([:paperclip:](https://arxiv.org/pdf/2305.15486.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15486)), ([:house:](https://huggingface.co/papers/2305.15486)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/spring-gpt-4-out-performs-rl-algorithms-by)) |
| 5.24 | Manifold Diffusion Fields ([:x:](https://arxiv.org/abs/2305.15586)), ([:paperclip:](https://arxiv.org/pdf/2305.15586.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15586)), ([:house:](https://huggingface.co/papers/2305.15586)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/manifold-diffusion-fields)) |
| 5.24 | A Neural Space-Time Representation for Text-to-Image Personalization ([:x:](https://arxiv.org/abs/2305.15391)), ([:paperclip:](https://arxiv.org/pdf/2305.15391.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15391)), ([:house:](https://huggingface.co/papers/2305.15391)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-neural-space-time-representation-for-text)), ([:octocat:](https://github.com/NeuralTextualInversion/NeTI)![GitHub Repo stars](https://img.shields.io/github/stars/NeuralTextualInversion/NeTI?style=social)) |
| 5.24 | Can Transformers Learn to Solve Problems Recursively? ([:x:](https://arxiv.org/abs/2305.14699)), ([:paperclip:](https://arxiv.org/pdf/2305.14699.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14699)), ([:house:](https://huggingface.co/papers/2305.14699)) |
| 5.24 | This Land is {Your, My} Land: Evaluating Geopolitical Biases in Language Models ([:x:](https://arxiv.org/abs/2305.14610)), ([:paperclip:](https://arxiv.org/pdf/2305.14610.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14610)), ([:house:](https://huggingface.co/papers/2305.14610)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/this-land-is-your-my-land-evaluating)) |
| 5.24 | Model evaluation for extreme risks ([:x:](https://arxiv.org/abs/2305.15324)), ([:paperclip:](https://arxiv.org/pdf/2305.15324.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15324)), ([:house:](https://huggingface.co/papers/2305.15324)) |
| 5.24 | State of GPT and RLHF LLMs - Andrej Karpathy, OpenAI ([session](https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2)), ([video](https://mediusdownload.event.microsoft.com/video-51378/ea11c3c20e/BRK216HFS_v1.mp4?sv=2018-03-28&sr=c&sig=tlIPwp2z6q8TNAEig%2BOQGh4lL8o8hAHcdw33msvikXY%3D&se=2028-05-24T06%3A23%3A01Z&sp=r)) |
| 5.24 | LMs with a Voice: Spoken Language Modeling beyond Speech Tokens ([:x:](https://arxiv.org/abs/2305.15255)), ([:paperclip:](https://arxiv.org/pdf/2305.15255.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.15255)), ([:house:](https://huggingface.co/papers/2305.15255)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/blip-diffusion-pre-trained-subject)), ([:octocat:](https://paperswithcode.com/paper/lms-with-a-voice-spoken-language-modeling)) |
| 5.24 | BLIP-Diffusion: Pre-trained Subject Representation for Controllable Text-to-Image Generation and Editing ([:x:](https://arxiv.org/abs/2305.14720)), ([:paperclip:](https://arxiv.org/pdf/2305.14720.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14720)), ([:house:](https://huggingface.co/papers/2305.14720)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/blip-diffusion-pre-trained-subject)), ([:octocat:](https://github.com/salesforce/LAVIS/tree/main/projects/blip-diffusion)), ([Project page](https://dxli94.github.io/BLIP-Diffusion-website/)) |
| 5.23 | Transformer-based Vulnerability Detection in Code at EditTime: Zero-shot, Few-shot, or Fine-tuning? [:x:](https://arxiv.org/abs/2306.01754)), ([:paperclip:](https://arxiv.org/pdf/2306.01754.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.01754)), ([:house:](https://huggingface.co/papers/2306.01754)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/transformer-based-vulnerability-detection-in)) |
| 5.23 | Unity’s Project Barracuda Injects Generative AI Into Games To Kickstart Exponential Growth ([Forbes news](https://www.forbes.com/sites/johnkoetsier/2023/05/23/unitys-project-barracuda-injects-generative-ai-into-games-to-kickstart-exponential-growth/?sh=5b2154b3703a)) |
| 5.23 | VisorGPT: Learning Visual Prior via Generative Pre-Training ([:x:](https://arxiv.org/abs/2305.13777)), ([:paperclip:](https://arxiv.org/pdf/2305.13777.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13777)), ([:house:](https://huggingface.co/papers/2305.13777)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/visorgpt-learning-visual-prior-via-generative)), ([:octocat:](https://github.com/sierkinhane/visorgpt)![GitHub Repo stars](https://img.shields.io/github/stars/sierkinhane/visorgpt?style=social)) |
| 5.23 | ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models ([:x:](https://arxiv.org/abs/2305.18323)), ([:paperclip:](https://arxiv.org/pdf/2305.18323.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.18323)), ([:house:](https://huggingface.co/papers/2305.18323)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/rewoo-decoupling-reasoning-from-observations)) |
| 5.23 | OlaGPT: Empowering LLMs With Human-like Problem-Solving Abilities ([:x:](https://arxiv.org/abs/2305.16334)), ([:paperclip:](https://arxiv.org/pdf/2305.16334.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.16334)), ([:house:](https://huggingface.co/papers/2305.16334)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/olagpt-empowering-llms-with-human-like)) |
| 5.23 | Goat: Fine-tuned LLaMA Outperforms GPT-4 on Arithmetic Tasks ([:x:](https://arxiv.org/abs/2305.14201)), ([:paperclip:](https://arxiv.org/pdf/2305.14201.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14201)), ([:house:](https://huggingface.co/papers/2305.14201)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/goat-fine-tuned-llama-outperforms-gpt-4-on)) |
| 5.23 | Enhancing Detail Preservation for Customized Text-to-Image Generation: A Regularization-Free Approach ([:x:](https://arxiv.org/abs/2305.13579)), ([:paperclip:](https://arxiv.org/pdf/2305.13579.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13579)), ([:house:](https://huggingface.co/papers/2305.13579)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/enhancing-detail-preservation-for-customized)) |
| 5.23 | Control-A-Video: Controllable Text-to-Video Generation with Diffusion Models ([:x:](https://arxiv.org/abs/2305.13840)), ([:paperclip:](https://arxiv.org/pdf/2305.13840.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13840)), ([:house:](https://huggingface.co/papers/2305.13840)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/control-a-video-controllable-text-to-video)) |
| 5.23 | Aligning Large Language Models through Synthetic Feedback ([:x:](https://arxiv.org/abs/2305.13735)), ([:paperclip:](https://arxiv.org/pdf/2305.13735.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13735)), ([:house:](https://huggingface.co/papers/2305.13735)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/aligning-large-language-models-through)) |
| 5.23 | LLMs as Factual Reasoners: Insights from Existing Benchmarks and Beyond ([:x:](https://arxiv.org/abs/2305.14540)), ([:paperclip:](https://arxiv.org/pdf/2305.14540.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14540)), ([:house:](https://huggingface.co/papers/2305.14540)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/llms-as-factual-reasoners-insights-from)), ([:octocat:](https://github.com/salesforce/factualnlg)![GitHub Repo stars](https://img.shields.io/github/stars/salesforce/factualnlg?style=social)) |
| 5.23 | Lost in Translation: Large Language Models in Non-English Content Analysis ([news](https://cdt.org/insights/lost-in-translation-large-language-models-in-non-english-content-analysis)) |
| 5.23 | Anchor Prediction: Automatic Refinement of Internet Links ([:x:](https://arxiv.org/abs/2305.14337)), ([:paperclip:](https://arxiv.org/pdf/2305.14337.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14337)), ([:house:](https://huggingface.co/papers/2305.14337)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/anchor-prediction-automatic-refinement-of)) |
| 5.23 | Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for Improved Vision-Language Compositionality ([:x:](https://arxiv.org/abs/2305.13812)), ([:paperclip:](https://arxiv.org/pdf/2305.13812.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13812)), ([:house:](https://huggingface.co/papers/2305.13812)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/coarse-to-fine-contrastive-learning-in-image)) |
| 5.23 | Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training ([:x:](https://arxiv.org/abs/2305.14342)), ([:paperclip:](https://arxiv.org/pdf/2305.14342.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14342)), ([:house:](https://huggingface.co/papers/2305.14342)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/sophia-a-scalable-stochastic-second-order)) |
| 5.23 | PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents ([:x:](https://arxiv.org/abs/2305.14564)), ([:paperclip:](https://arxiv.org/pdf/2305.14564.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14564)), ([:house:](https://huggingface.co/papers/2305.14564)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/pearl-prompting-large-language-models-to-plan)) |
| 5.23 | Bing at Microsoft Build 2023: Continuing the Transformation of Search ([blog](https://blogs.bing.com/search/may_2023/Bing-at-Microsoft-Build-2023)) |
| 5.23 | Bringing the power of AI to Windows 11 – unlocking a new era of productivity for customers and developers with Windows Copilot and Dev Home ([blog](https://blogs.windows.com/windowsdeveloper/2023/05/23/bringing-the-power-of-ai-to-windows-11-unlocking-a-new-era-of-productivity-for-customers-and-developers-with-windows-copilot-and-dev-home/)) |
| 5.23 | Adobe Unveils Future of Creative Cloud With Generative AI as a Creative Co-Pilot in Photoshop ([news](https://news.adobe.com/news/news-details/2023/Adobe-Unveils-Future-of-Creative-Cloud-with-Generative-AI-as-a-Creative-Co-Pilot-in-Photoshop-default.aspx/default.aspx)), ([blog](https://blog.adobe.com/en/publish/2023/05/23/photoshop-new-features-ai-contextual-presets)) |
| 5.23 | QLoRA: Efficient Finetuning of Quantized LLMs ([:x:](https://arxiv.org/abs/2305.14314)), ([:paperclip:](https://arxiv.org/pdf/2305.14314.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.14314)), ([:house:](https://huggingface.co/papers/2305.14314)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/qlora-efficient-finetuning-of-quantized-llms)), ([:octocat:](https://github.com/artidoro/qlora)![GitHub Repo stars](https://img.shields.io/github/stars/artidoro/qlora?style=social)) |
| 5.22 | SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization Evaluation ([:x:](https://arxiv.org/abs/2305.13194)), ([:paperclip:](https://arxiv.org/pdf/2305.13194.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13194)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/seahorse-a-multilingual-multifaceted-dataset)) |
| 5.22 | Meta-in-context learning in large language models  ([:x:](https://arxiv.org/abs/2305.12907)), ([:paperclip:](https://arxiv.org/pdf/2305.12907.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.12907)), ([:house:](https://huggingface.co/papers/2305.12647)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/meta-in-context-learning-in-large-language)) |
| 5.22 | AudioToken: Adaptation of Text-Conditioned Diffusion Models for Audio-to-Image Generation ([:x:](https://arxiv.org/abs/2305.13050)), ([:paperclip:](https://arxiv.org/pdf/2305.13050.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13050)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/audiotoken-adaptation-of-text-conditioned-1)), ([:octocat:](https://github.com/guyyariv/AudioToken)![GitHub Repo stars](https://img.shields.io/github/stars/guyyariv/AudioToken?style=social)) |
| 5.22 | Iterative Forward Tuning Boosts In-context Learning in Language Models  ([:x:](https://arxiv.org/abs/2305.13016)), ([:paperclip:](https://arxiv.org/pdf/2305.13016.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13016)), ([:house:](https://huggingface.co/papers/2305.13016)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/iterative-forward-tuning-boosts-in-context)) |
| 5.22 | How Language Model Hallucinations Can Snowball  ([:x:](https://arxiv.org/abs/2305.13534)), ([:paperclip:](https://arxiv.org/pdf/2305.13534.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13534)), ([:house:](https://huggingface.co/papers/2305.13534)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/how-language-model-hallucinations-can)), ([demo](https://huggingface.co/spaces/huybery/deep-thinking)) |
| 5.22 | Intel Announces Aurora genAI, Generative AI Model With 1 Trillion Parameters ([news](https://wccftech.com/intel-aurora-genai-chatgpt-competitor-generative-ai-model-with-1-trillion-parameters/)), ([Intel newsroom](https://www.intel.com/content/www/us/en/newsroom/news/intel-delivers-ai-accelerated-hpc-performance.html#gs.ymzdf9)) |
| 5.22 | Introducing Mind-Video ([Tweet](https://twitter.com/ZijiaoC/status/1660470518569639937)), ([demo](https://mind-video.com/)), ([data](https://drive.google.com/drive/folders/1swYQD-69phlJUz4_HmdM0RFk_7okLK4v)) |
| 5.22 | Reflective Linguistic Programming (RLP): A Stepping Stone in Socially-Aware AGI (SocialAGI) ([:x:](https://arxiv.org/abs/2305.12647)), ([:paperclip:](https://arxiv.org/pdf/2305.12647.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.12647)), ([:house:](https://huggingface.co/papers/2305.12647)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/reflective-linguistic-programming-rlp-a)) |
| 5.22 | GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints ([:x:](https://arxiv.org/abs/2305.13245)), ([:paperclip:](https://arxiv.org/pdf/2305.13245.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13245)), ([:house:](https://huggingface.co/papers/2305.13245)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/gqa-training-generalized-multi-query)) |
| 5.22 | LM vs LM: Detecting Factual Errors via Cross Examination ([:x:](https://arxiv.org/abs/2305.13281)), ([:paperclip:](https://arxiv.org/pdf/2305.13281.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13281)), ([:house:](https://huggingface.co/papers/2305.13281)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/lm-vs-lm-detecting-factual-errors-via-cross)) |
| 5.22 | XTREME-UP: A User-Centric Scarce-Data Benchmark for Under-Represented Languages ([:paperclip:](https://storage.googleapis.com/xtreme-up/xtreme-up.pdf)), ([:octocat:](https://github.com/google-research/xtreme-up)![GitHub Repo stars](https://img.shields.io/github/stars/google-research/xtreme-up?style=social)) |
| 5.22 | VideoLLM: Modeling Video Sequence with Large Language Models ([:x:](https://arxiv.org/abs/2305.13292)), ([:paperclip:](https://arxiv.org/pdf/2305.13292.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13292)), ([:house:](https://huggingface.co/papers/2305.13292)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/videollm-modeling-video-sequence-with-large)) |
| 5.22 | RecurrentGPT: Interactive Generation of (Arbitrarily) Long Text ([:x:](https://arxiv.org/abs/2305.13304)), ([:paperclip:](https://arxiv.org/pdf/2305.13304.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13304)), ([:house:](https://huggingface.co/papers/2305.13304)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/recurrentgpt-interactive-generation-of)) |
| 5.22 | RWKV: Reinventing RNNs for the Transformer Era  ([:x:](https://arxiv.org/abs/2305.13048)), ([:paperclip:](https://arxiv.org/pdf/2305.13048.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.13048)), ([:house:](https://huggingface.co/papers/2305.13048)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/rwkv-reinventing-rnns-for-the-transformer-era)) |
| 5.22 | Introducing speech-to-text, text-to-speech, and more for 1,100+ languages ([Blog](https://ai.facebook.com/blog/multilingual-model-speech-recognition/)), ([:paperclip:](https://scontent-nrt1-1.xx.fbcdn.net/v/t39.8562-6/348836647_265923086001014_6878005808275791319_n.pdf?_nc_cat=104&ccb=1-7&_nc_sid=ae5e01&_nc_ohc=5exJiCqt0Y4AX-_7kQa&_nc_ht=scontent-nrt1-1.xx&oh=00_AfApkDyQVBqv7V82fFveVwLv3AC7KxmOR1FegeXQkrsPiQ&oe=6471ACCF)), ([:octocat:](https://github.com/facebookresearch/fairseq/tree/main/examples/mms)) | 
| 5.21 | Augmenting Autotelic Agents with Large Language Models ([:x:](https://arxiv.org/abs/2305.12487)), ([:paperclip:](https://arxiv.org/pdf/2305.12487.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.12487)), ([:house:](https://huggingface.co/papers/2305.12487)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/augmenting-autotelic-agents-with-large)) |
| 5.21 | XrayGPT: Chest Radiographs Summarization using Medical Vision-Language Models ([:octocat:](https://github.com/mbzuai-oryx/XrayGPT)![GitHub Repo stars](https://img.shields.io/github/stars/mbzuai-oryx/XrayGPT?style=social)), ([Video](https://www.youtube.com/watch?v=-zzq7bzbUuY&t=31s)) | 
| 5.20 | G7 Hiroshima Leaders’ Communiqué ([statement](https://www.mofa.go.jp/files/100506878.pdf)), ([html](https://www.whitehouse.gov/briefing-room/statements-releases/2023/05/20/g7-hiroshima-leaders-communique/)) |
| 5.20 | G7 calls for developing global technical standards for AI ([news](https://www.reuters.com/world/g7-calls-developing-global-technical-standards-ai-2023-05-20/)) |
| 5.20 | Labour should pledge £11bn to build ‘BritGPT’ AI, thinktank says ([news](https://www.theguardian.com/technology/2023/may/20/labour-should-pledge-11bn-to-build-britgpt-ai-thinktank-says)) |
| 5.20 | CodeCompose: A Large-Scale Industrial Deployment of AI-assisted Code Authoring ([:x:](https://arxiv.org/abs/2305.12050)), ([:paperclip:](https://arxiv.org/pdf/2305.12050.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.12050)), ([:house:](https://huggingface.co/papers/2305.12050)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/codecompose-a-large-scale-industrial)) |
| 5.19 | OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models ([:x:](https://arxiv.org/abs/2305.12001)), ([:paperclip:](https://arxiv.org/pdf/2305.12001.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.12001)), ([:house:](https://huggingface.co/papers/2305.12001)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/opt-r-exploring-the-role-of-explanations-in)) |
| 5.19 | Neural Foundations of Mental Simulation: Future Prediction of Latent Representations on Dynamic Scenes ([:x:](https://arxiv.org/abs/2305.11772)), ([:paperclip:](https://arxiv.org/pdf/2305.11772.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11772)), ([:house:](https://huggingface.co/papers/2305.11772)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/neural-foundations-of-mental-simulation)) |
| 5.19 | Clinical Camel: An Open-Source Expert-Level Medical Language Model with Dialogue-Based Knowledge Encoding ([:x:](https://arxiv.org/abs/2305.12031)), ([:paperclip:](https://arxiv.org/pdf/2305.12031.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.12050)), ([:house:](https://huggingface.co/papers/2305.12050)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/codecompose-a-large-scale-industrial)), ([huggingface](https://huggingface.co/wanglab/clinical-camel)), ([:octocat:](https://github.com/bowang-lab/clinical-camel)![GitHub Repo stars](https://img.shields.io/github/stars/bowang-lab/clinical-camel?style=social)) |
| 5.19 | New York City public schools remove ChatGPT ban ([news](https://www.nbcnews.com/tech/chatgpt-ban-dropped-new-york-city-public-schools-rcna85089)) |
| 5.19 | Graphologue: Exploring Large Language Model Responses with Interactive Diagrams ([:x:](https://arxiv.org/abs/2305.11473)), ([:paperclip:](https://arxiv.org/pdf/2305.11473.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11473)), ([:house:](https://huggingface.co/papers/2305.11473)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/graphologue-exploring-large-language-model)) |
| 5.19 | The Inside Story: Towards Better Understanding of Machine Translation Neural Evaluation Metrics ([:x:](https://arxiv.org/abs/2305.11806)), ([:paperclip:](https://arxiv.org/pdf/2305.11806.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11806)), ([:house:](https://huggingface.co/papers/2305.11806)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/the-inside-story-towards-better-understanding)), ([:octocat:](https://github.com/Unbabel/COMET)![GitHub Repo stars](https://img.shields.io/github/stars/Unbabel/COMET?style=social)) |
| 5.19 | HalOmi: A Manually Annotated Benchmark for Multilingual Hallucination and Omission Detection in Machine Translation ([:x:](https://arxiv.org/abs/2305.11746)), ([:paperclip:](https://arxiv.org/pdf/2305.11746.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11746)), ([:house:](https://huggingface.co/papers/2305.11746)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/halomi-a-manually-annotated-benchmark-for)) |
| 5.19 | Characterizing tradeoffs between teaching via language and demonstrations in multi-agent systems ([:x:](https://arxiv.org/abs/2305.11374)), ([:paperclip:](https://arxiv.org/pdf/2305.11374.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11374)), ([:house:](https://huggingface.co/papers/2305.11374)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/characterizing-tradeoffs-between-teaching-via)) |
| 5.19 | TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks ([:x:](https://arxiv.org/abs/2305.11430)), ([:paperclip:](https://arxiv.org/pdf/2305.11430.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11430)), ([:house:](https://huggingface.co/papers/2305.11430)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/teler-a-general-taxonomy-of-llm-prompts-for)) |
| 5.19 | Text2NeRF: Text-Driven 3D Scene Generation with Neural Radiance Fields ([:x:](https://arxiv.org/abs/2305.11588)), ([:paperclip:](https://arxiv.org/pdf/2305.11588.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11588)), ([:house:](https://huggingface.co/papers/2305.11588)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/text2nerf-text-driven-3d-scene-generation)) |
| 5.19 | Chupa: Carving 3D Clothed Humans from Skinned Shape Priors using 2D Diffusion Probabilistic Models ([:x:](https://arxiv.org/abs/2305.11870)), ([:paperclip:](https://arxiv.org/pdf/2305.11870.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11870)), ([:house:](https://huggingface.co/papers/2305.11870)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/chupa-carving-3d-clothed-humans-from-skinned)) |
| 5.19 | Comparing Software Developers with ChatGPT: An Empirical Investigation ([:x:](https://arxiv.org/abs/2305.11837)), ([:paperclip:](https://arxiv.org/pdf/2305.11837.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11837)), ([:house:](https://huggingface.co/papers/2305.11837)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/comparing-software-developers-with-chatgpt-an)) |
| 5.19 | CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing ([:x:](https://arxiv.org/abs/2305.11738)), ([:paperclip:](https://arxiv.org/pdf/2305.11738.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11738)), ([:house:](https://huggingface.co/papers/2305.11738)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/critic-large-language-models-can-self-correct)), ([:octocat:](https://github.com/microsoft/ProphetNet)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/ProphetNet?style=social)) |
| 5.19 | Multimodal Web Navigation with Instruction-Finetuned Foundation Models ([:x:](https://arxiv.org/abs/2305.11854)), ([:paperclip:](https://arxiv.org/pdf/2305.11854.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11854)), ([:house:](https://huggingface.co/papers/2305.11854)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/multimodal-web-navigation-with-instruction)) |
| 5.19 | Cinematic Mindscapes: High-quality Video Reconstruction from Brain Activity ([:x:](https://arxiv.org/abs/2305.11675)), ([:paperclip:](https://arxiv.org/pdf/2305.11675.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11675)), ([:house:](https://huggingface.co/papers/2305.11675)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/cinematic-mindscapes-high-quality-video)) | 
| 5.19 | Scaling laws for language encoding models in fMRI ([:x:](https://arxiv.org/abs/2305.11863)), ([:paperclip:](https://arxiv.org/pdf/2305.11863.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11863)), ([:house:](https://huggingface.co/papers/2305.11863)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/scaling-laws-for-language-encoding-models-in)) | 
| 5.19 | Any-to-Any Generation via Composable Diffusion ([:x:](https://arxiv.org/abs/2305.11846)), ([:paperclip:](https://arxiv.org/pdf/2305.11846.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11846)), ([:house:](https://huggingface.co/papers/2305.11846)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/any-to-any-generation-via-composable)), ([:octocat:](https://github.com/microsoft/i-Code/tree/main/i-Code-V3)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/i-Code?style=social)) |
| 5.19 | ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings ([:x:](https://arxiv.org/abs/2305.11554)), ([:paperclip:](https://arxiv.org/pdf/2305.11554.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11554)), ([:house:](https://huggingface.co/papers/2305.11554)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/toolkengpt-augmenting-frozen-language-models)) |
| 5.19 | Apple Bans Employees From Using ChatGPT Amid Its Own AI Efforts ([news](https://www.macrumors.com/2023/05/19/apple-bans-employees-from-using-chatgpt/)) |
| 5.18 | A Framework for Critically Assessing ChatGPT and Other Large Language Artificial Intelligence Model Applications in Health Care ([https://doi.org/10.1016/j.mcpdig.2023.03.006](https://www.mcpdigitalhealth.org/article/S2949-7612(23)00022-6/fulltext)) |
| 5.18 | Brain-inspired learning in artificial neural networks: a review ([:x:](https://arxiv.org/abs/2305.11252)), ([:paperclip:](https://arxiv.org/pdf/2305.11252.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11252)), ([:house:](https://huggingface.co/papers/2305.11252)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/brain-inspired-learning-in-artificial-neural)) |
| 5.18 | ONE-PEACE: Exploring One General Representation Model Toward Unlimited Modalities ([:x:](https://arxiv.org/abs/2305.11172)), ([:paperclip:](https://arxiv.org/pdf/2305.11172.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11172)), ([:house:](https://huggingface.co/papers/2305.11337)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/one-peace-exploring-one-general)) |
| 5.18 | RoomDreamer: Text-Driven 3D Indoor Scene Synthesis with Coherent Geometry and Texture  ([:x:](https://arxiv.org/abs/2305.11337)), ([:paperclip:](https://arxiv.org/pdf/2305.11337.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11337)), ([:house:](https://huggingface.co/papers/2305.11337)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/roomdreamer-text-driven-3d-indoor-scene)) |
| 5.18 | LIMA: Less Is More for Alignment ([:x:](https://arxiv.org/abs/2305.11206)), ([:paperclip:](https://arxiv.org/pdf/2305.11206.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11206)), ([:house:](https://huggingface.co/papers/2305.11206)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/lima-less-is-more-for-alignment)) |
| 5.18 | GETMusic: Generating Any Music Tracks with a Unified Representation and Diffusion Framework ([:x:](https://arxiv.org/abs/2305.10841)), ([:paperclip:](https://arxiv.org/pdf/2305.10841.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10841)), ([:house:](https://huggingface.co/papers/2305.10841)), ([project page](https://ai-muzic.github.io/getmusic/)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/getmusic-generating-any-music-tracks-with-a)), ([:octocat:](https://github.com/microsoft/muzic)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/muzic?style=social)), ([Star history](https://star-history.com/#microsoft/muzic&Date)) |
| 5.18 | SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities ([:x:](https://arxiv.org/abs/2305.11000)), ([:paperclip:](https://arxiv.org/pdf/2305.11000.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11000)), ([:house:](https://huggingface.co/papers/2305.11000)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/speechgpt-empowering-large-language-models)) |
| 5.18 | mLongT5: A Multilingual and Efficient Text-To-Text Transformer for Longer Sequences ([:x:](https://arxiv.org/abs/2305.11129)), ([:paperclip:](https://arxiv.org/pdf/2305.11129.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11129)), ([:house:](https://huggingface.co/papers/2305.11129)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/mlongt5-a-multilingual-and-efficient-text-to)) |
| 5.18 | Language Models Meet World Models: Embodied Experiences Enhance Language Models  ([:x:](https://arxiv.org/abs/2305.10626)), ([:paperclip:](https://arxiv.org/pdf/2305.10626.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10626)), ([:house:](https://huggingface.co/papers/2305.10626)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/language-models-meet-world-models-embodied)) |
| 5.18 | Roundhill Investments Launches Generative AI & Technology ETF (NYSE Arca: CHAT) ([news](https://www.prnewswire.com/news-releases/roundhill-investments-launches-generative-ai--technology-etf-nyse-arca-chat-301828049.html)), ([CHAT ETF](https://www.marketwatch.com/investing/fund/chat)) |
| 5.18 | VisionLLM: Large Language Model is also an Open-Ended Decoder for Vision-Centric Tasks ([:x:](https://arxiv.org/abs/2305.11175)), ([:paperclip:](https://arxiv.org/pdf/2305.11175.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11175)), ([:house:](https://huggingface.co/papers/2305.11175)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/visionllm-large-language-model-is-also-an)) |
| 5.18 | Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold ([:x:](https://arxiv.org/abs/2305.10973)), ([:paperclip:](https://arxiv.org/pdf/2305.10973.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10973)), ([:house:](https://huggingface.co/papers/2305.10973)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/drag-your-gan-interactive-point-based)), ([Huggingfae](https://huggingface.co/spaces/radames/UserControllableLT-Latent-Transformer)), ([Unofficial](https://github.com/Zeqiang-Lai/DragGAN)![GitHub Repo stars](https://img.shields.io/github/stars/Zeqiang-Lai/DragGAN?style=social)), ([colab](https://colab.research.google.com/github/Zeqiang-Lai/DragGAN/blob/master/colab.ipynb)), ([Official](https://github.com/XingangPan/DragGAN)![GitHub Repo stars](https://img.shields.io/github/stars/XingangPan/DragGAN?style=social)) |
| 5.18 | PyLLMs - a minimal Python library to connect to LLMs (OpenAI, Anthropic, Google, AI21, Cohere, Aleph Alpha, HuggingfaceHub) ([:octocat:](https://github.com/kagisearch/pyllms)![GitHub Repo stars](https://img.shields.io/github/stars/kagisearch/pyllms?style=social))
| 5.18 | Evidence of Meaning in Language Models Trained on Programs ([:x:](https://arxiv.org/abs/2305.11169)), ([:paperclip:](https://arxiv.org/pdf/2305.11169.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.11169)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/evidence-of-meaning-in-language-models)) |
| 5.18 | Introducing the ChatGPT app for iOS ([blog](https://openai.com/blog/introducing-the-chatgpt-app-for-ios)), ([Download on the App Stor](https://apps.apple.com/app/openai-chatgpt/id6448311069)) |
| 5.18 | MTIA v1: Meta’s first-generation AI inference accelerator ([blog](https://ai.facebook.com/blog/meta-training-inference-accelerator-AI-MTIA/)) |
| 5.18 | Pursuing groundbreaking scale and accelerating research using Meta’s Research SuperCluster ([blog](https://ai.facebook.com/blog/supercomputer-meta-research-supercluster-2023/)) |
| 5.18 | Reimagining Meta’s infrastructure for the AI age ([blog](https://ai.facebook.com/blog/meta-ai-infrastructure-overview/)) |
| 5.17 | Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models ([:x:](https://arxiv.org/abs/2305.10276)), ([:paperclip:](https://arxiv.org/pdf/2305.10276.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10276)), ([:house:](https://huggingface.co/papers/2305.10276)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/chain-of-symbol-prompting-elicits-planning-in)) |
| 5.17 | DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining ([:x:](https://arxiv.org/abs/2305.10429)), ([:paperclip:](https://arxiv.org/pdf/2305.10429.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10429)), ([:house:](https://huggingface.co/papers/2305.10429)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/doremi-optimizing-data-mixtures-speeds-up)) |
| 5.17 | Explaining black box text modules in natural language with language models ([:x:](https://arxiv.org/abs/2305.09863)), ([:paperclip:](https://arxiv.org/pdf/2305.09863.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.09863)), ([:house:](https://huggingface.co/papers/2305.09863)), ([project page](https://ai-muzic.github.io/getmusic/)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/explaining-black-box-text-modules-in-natural) |
| 5.17 | Tree of Thoughts: Deliberate Problem Solving with Large Language Models ([:x:](https://arxiv.org/abs/2305.10601)), ([:paperclip:](https://arxiv.org/pdf/2305.10601.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10601)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/tree-of-thoughts-deliberate-problem-solving)) |
| 5.17 | Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback  ([:x:](https://arxiv.org/abs/2305.10142)), ([:paperclip:](https://arxiv.org/pdf/2305.10142.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10142)), ([:eight_spoked_asterisk:](https://paperswithcode.com/search?q_meta=&q_type=&q=%09Improving%20Language%20Model%20Negotiation%20with%20Self-Play%20and%20In-Context%20Learning%20from%20AI%20Feedback)) |
| 5.17 | PMC-VQA: Visual Instruction Tuning for Medical Visual Question Answering ([:x:](https://arxiv.org/abs/2305.10415)), ([:paperclip:](https://arxiv.org/pdf/2305.10415.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10415)), ([:trophy:papers with code](https://paperswithcode.com/paper/pmc-vqa-visual-instruction-tuning-for-medical)) |
| 5.17 | What You See is What You Read? Improving Text-Image Alignment Evaluation ([:x:](https://arxiv.org/abs/2305.10400)), ([:paperclip:](https://arxiv.org/pdf/2305.10400.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10400)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/what-you-see-is-what-you-read-improving-text)) |
| 5.17 | PaLM 2 Technical Report  ([:x:](https://arxiv.org/abs/2305.10403)), ([:paperclip:](https://arxiv.org/pdf/2305.10403.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10403)), ([:trophy:papers with code](https://paperswithcode.com/paper/palm-2-technical-report)) |
| 5.17 | Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback ([:x:](https://arxiv.org/abs/2305.10142)), ([:paperclip:](https://arxiv.org/pdf/2305.10142.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.10142)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/improving-language-model-negotiation-with)) |
| 5.17 | SoundStorm: Efficient Parallel Audio Generation ([:x:](https://arxiv.org/abs/2305.09636)), ([:paperclip:](https://arxiv.org/pdf/2305.09636.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.09636)), ([Project page](https://google-research.github.io/seanet/soundstorm/examples/)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/soundstorm-efficient-parallel-audio)) | 
| 5.16 | GPT-4 in Radiology: Improvements in Advanced Reasoning (RSNA Radiology, [https://doi.org/10.1148/radiol.230987](https://pubs.rsna.org/doi/10.1148/radiol.230987)) |
| 5.16 | Performance of ChatGPT on a Radiology Board-style Examination: Insights into Current Strengths and Limitations (RSNA Radiology, [https://doi.org/10.1148/radiol.230582](https://pubs.rsna.org/doi/10.1148/radiol.230582)) |
| 5.16 | AR-Diffusion: Auto-Regressive Diffusion Model for Text Generation ([:x:](https://arxiv.org/abs/2305.09515)), ([:paperclip:](https://arxiv.org/pdf/2305.09515.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.09515)) |
| 5.16 | Make-An-Animation: Large-Scale Text-conditional 3D Human Motion Generation ([:x:](https://arxiv.org/abs/2305.09662)), ([:paperclip:](https://arxiv.org/pdf/2305.09662.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.09662)) |
| 5.16 | ChatGPT versus human in generating medical graduate exam questions – An international prospective study ([medRxiv](https://www.medrxiv.org/content/10.1101/2023.05.13.23289943v1)), ([:paperclip:](https://www.medrxiv.org/content/10.1101/2023.05.13.23289943v1.full.pdf)) |
| 5.16 | Understanding 3D Object Interaction from a Single Image ([:x:](https://arxiv.org/abs/2305.09664)), ([:paperclip:](https://arxiv.org/pdf/2305.09664.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.09664)), ([project page](https://jasonqsy.github.io/3DOI/)), ([demo](https://huggingface.co/spaces/shengyi-qian/3DOI)), ([video](https://www.youtube.com/watch?v=YDIL93XxHyk)), ([:octocat:](https://github.com/JasonQSY/3DOI)) |
| 5.16 | StructGPT: A General Framework for Large Language Model to Reason over Structured Data ([:x:](https://arxiv.org/abs/2305.09645)), ([:paperclip:](https://arxiv.org/pdf/2305.09645.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.09645)), ([:eight_spoked_asterisk:](https://paperswithcode.com/search?q_meta=&q_type=&q=%09StructGPT%3A%20A%20General%20Framework%20for%20Large%20Language%20Model%20to%20Reason%20over%20Structured%20Data)) |
| 5.16 | FitMe: Deep Photorealistic 3D Morphable Model Avatars ([:x:](https://arxiv.org/abs/2305.09641)), ([:paperclip:](https://arxiv.org/pdf/2305.09641.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.09641)), ([project page](https://alexlattas.com/fitme)) |
| 5.16 | Pre-Training to Learn in Context ([:x:](https://arxiv.org/abs/2305.09137)), ([:paperclip:](https://arxiv.org/pdf/2305.09137.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.09137)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/pre-training-to-learn-in-context)) |
| 5.16 | Towards Expert-Level Medical Question Answering with Large Language Models ([:x:](https://arxiv.org/abs/2305.09617)), ([:paperclip:](https://arxiv.org/pdf/2305.09617.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.09617)), ([:trophy:papers with code](https://paperswithcode.com/paper/towards-expert-level-medical-question)) |
| 5.16 | GPTeam: Collaborative AI Agents  ([:octocat:](https://github.com/101dotxyz/GPTeam)![GitHub Repo stars](https://img.shields.io/github/stars/101dotxyz/GPTeam?style=social)) |
| 5.16 | WATCH LIVE: OpenAI CEO Sam Altman testifies on artificial intelligence before Senate committee ([Youtube](https://www.youtube.com/watch?v=P_ACcQxJIsg)) |
| 5.16 | NYT - [Microsoft Says New A.I. Shows Signs of Human Reasoning](https://www.nytimes.com/2023/05/16/technology/microsoft-ai-human-reasoning.html) | 
| 5.15 | Common Diffusion Noise Schedules and Sample Steps are Flawed ([:x:](https://arxiv.org/abs/2305.08891)), ([:paperclip:](https://arxiv.org/pdf/2305.08891.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.08891)) |
| 5.15 | Symbol tuning improves in-context learning in language models ([:x:](https://arxiv.org/abs/2305.08298)), ([:paperclip:](https://arxiv.org/pdf/2305.08298.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.08298)) |
| 5.15 | Interpretability at Scale: Identifying Causal Mechanisms in Alpaca ([:x:](https://arxiv.org/abs/2305.08809)), ([:paperclip:](https://arxiv.org/pdf/2305.08809.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.08809)) |
| 5.15 | DarkBERT: A Language Model for the Dark Side of the Internet ([:x:](https://arxiv.org/abs/2305.08596)), ([:paperclip:](https://arxiv.org/pdf/2305.08596.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.08596)) | 
| 5.15 | AutoRecon: Automated 3D Object Discovery and Reconstruction ([:x:](https://arxiv.org/abs/2305.08810)), ([:paperclip:](https://arxiv.org/pdf/2305.08810.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.08810)), ([Project page](https://zju3dv.github.io/autorecon/)) | 
| 5.15 | RL4F: Generating Natural Language Feedback with Reinforcement Learning for Repairing Model Outputs ([:x:](https://arxiv.org/abs/2305.08844)), ([:paperclip:](https://arxiv.org/pdf/2305.08844.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.08844)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/rl4f-generating-natural-language-feedback)) | 
| 5.15 | Small Models are Valuable Plug-ins for Large Language Models ([:x:](https://arxiv.org/abs/2305.08848)), ([:paperclip:](https://arxiv.org/pdf/2305.08848.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.08848)) | 
| 5.15 | "ChatGPT can pick stocks better then top fund managers" - The ChatGPT Fund - ([tweet](https://twitter.com/chatgpttrader/status/1658193474708213760)), ([website](https://www.thechatgptfund.com/)) |
| 5.15 | officially launching the Poe API - ([Tweet](https://twitter.com/adamdangelo/status/1658121701077516291), ([:octocat:](https://github.com/poe-platform)): ([poe-protocol](https://github.com/poe-platform/poe-protocol)![GitHub Repo stars](https://img.shields.io/github/stars/poe-platform/poe-protocol?style=social)), ([api-bot-tutorial](https://github.com/poe-platform/api-bot-tutorial)![GitHub Repo stars](https://img.shields.io/github/stars/poe-platform/api-bot-tutorial?style=social)) | |
| 5.15 | Guidance - A guidance language for controlling large language models ([:octocat:](https://github.com/microsoft/guidance)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/guidance?style=social)) |
| 5.15 | BriefGPT - Locally hosted tool that connects documents to LLMs for summarization and querying, with a simple GUI ([:octocat:](https://github.com/e-johnstonn/BriefGPT)![GitHub Repo stars](https://img.shields.io/github/stars/e-johnstonn/BriefGPT?style=social)) |
| 5.15 | I’m an ER doctor. Here’s how I’m already using ChatGPT to help treat patients ([blog](https://www.fastcompany.com/90895618/how-a-doctor-uses-chat-gpt-to-treat-patients)) |
| 5.14 | A Comprehensive Survey on Segment Anything Model for Vision and Beyond ([:x:](https://arxiv.org/abs/2305.08196)), ([:paperclip:](https://arxiv.org/pdf/2305.08196.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.08196)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-comprehensive-survey-on-segment-anything)), ([:octocat:](https://github.com/liliu-avril/Awesome-Segment-Anything)![GitHub Repo stars](https://img.shields.io/github/stars/liliu-avril/Awesome-Segment-Anything?style=social)) |
| 5.14 | How to run Llama 13B with a 6GB graphics card ([Gist](https://gist.github.com/rain-1/8cc12b4b334052a21af8029aa9c4fafc)) |
| 5.13 | Leaked Copilot Chat's confidential rules ([tweet](https://twitter.com/marvinvonhagen/status/1657060506371346432)) |
| 5.13 | GPT-Sentinel: Distinguishing Human and ChatGPT Generated Content (arXiv](https://arxiv.org/abs/2305.07969)), ([:paperclip:](https://arxiv.org/pdf/2305.07969.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07969)) |
| 5.13 | Everything-LLMs-And-Robotics - The world's largest GitHub Repository for LLMs + Robotics ([:octocat:](https://github.com/jrin771/Everything-LLMs-And-Robotics)![GitHub Repo stars](https://img.shields.io/github/stars/jrin771/Everything-LLMs-And-Robotics?style=social)) | 
| 5.13 | CodeT5+: Open Code Large Language Models for Code Understanding and Generation ([:x:](https://arxiv.org/abs/2305.07922)), ([:paperclip:](https://arxiv.org/pdf/2305.07922.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07922)), ([:octocat:](https://github.com/salesforce/CodeT5/tree/main/CodeT5%2B)![GitHub Repo stars](https://img.shields.io/github/stars/salesforce/CodeT5?style=social)), ([:trophy:papers with code](https://paperswithcode.com/paper/codet5-open-code-large-language-models-for)) |
| 5.13 | EU AI Act To Target US Open Source Software ([Blog](https://technomancers.ai/eu-ai-act-to-target-us-open-source-software/#more-561)) |
| 5.13 | PCAST Working Group on Generative AI Invites Public Input ([Blog](https://terrytao.wordpress.com/2023/05/13/pcast-working-group-on-generative-ai-invites-public-input/)) | 
| 5.12 | A Survey on Segment Anything Model (SAM): Vision Foundation Model Meets Prompt Engineering ([:x:](https://arxiv.org/abs/2305.06211)), ([:paperclip:](https://arxiv.org/pdf/2305.06211.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06211)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-survey-on-segment-anything-model-sam-vision)) |
| 5.12 | spacy-llm, an extension for integrating LLMs into structured NLP pipelines! ([:octocat:](https://github.com/explosion/spacy-llm)![GitHub Repo stars](https://img.shields.io/github/stars/explosion/spacy-llm?style=social)), ([tweet](https://twitter.com/spacy_io/status/1656734286425255937)) |
| 5.12 | TinyStories: How Small Can Language Models Be and Still Speak Coherent English? ([:x:](https://arxiv.org/abs/2305.07759)), ([:paperclip:](https://arxiv.org/pdf/2305.07759.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07759)) | 
| 5.12 | Dr. LLaMA: Improving Small Language Models in Domain-Specific QA via Generative Data Augmentation  ([:x:](https://arxiv.org/abs/2305.07804)), ([:paperclip:](https://arxiv.org/pdf/2305.07804.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07804)), ([model](https://huggingface.co/Tyrannosaurus/ArtGPT-4)), ([:octocat:](https://github.com/zguo0525/Dr.llama)![GitHub Repo stars](https://img.shields.io/github/stars/zguo0525/Dr.llama?style=social))  |
| 5.12 | ArtGPT-4: Artistic Vision-Language Understanding with Adapter-enhanced MiniGPT-4 ([:x:](https://arxiv.org/abs/2305.07490)), ([:paperclip:](https://arxiv.org/pdf/2305.07490.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07490)), ([model](https://huggingface.co/Tyrannosaurus/ArtGPT-4)) |
| 5.12 | MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers ([:x:](https://arxiv.org/abs/2305.07185)), ([:paperclip:](https://arxiv.org/pdf/2305.07185.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07185)) |
| 5.12 | AI FILM -The Carnival of the Ages - Runway gen2 ([Youtube](https://www.youtube.com/watch?v=q0EDV1HGbrc)), ([Reddit](https://www.reddit.com/r/aivideo/comments/13eh1rq/carnival_of_ages_text_to_video_runway_gen2/)) | 
| 5.11 | Large Language Models Can Be Used To Effectively Scale Spear Phishing Campaigns ([:x:](https://arxiv.org/abs/2305.06972)), ([:paperclip:](https://arxiv.org/pdf/2305.06972.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06972)) |
| 5.11 | Towards best practices in AGI safety and governance: A survey of expert opinion ([:x:](https://arxiv.org/abs/2305.07153)), ([:paperclip:](https://arxiv.org/pdf/2305.07153.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07153)) |
| 5.11 | Optimizing Memory Mapping Using Deep Reinforcement Learning ([:x:](https://arxiv.org/abs/2305.07440)), ([:paperclip:](https://arxiv.org/pdf/2305.07440.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07440)) |
| 5.11 | Universal Source Separation with Weakly Labelled Data ([:x:](https://arxiv.org/abs/2305.07447)), ([:paperclip:](https://arxiv.org/pdf/2305.07447.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07447)), ([:octocat:](https://github.com/bytedance/uss)![GitHub Repo stars](https://img.shields.io/github/stars/bytedance/uss?style=social)) |
| 5.11 | Active Retrieval Augmented Generation  ([:x:](https://arxiv.org/abs/2305.06983)), ([:paperclip:](https://arxiv.org/pdf/2305.06983.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06983)), ([:octocat:](https://github.com/jzbjyb/FLARE)![GitHub Repo stars](https://img.shields.io/github/stars/jzbjyb/FLARE?style=social)) |
| 5.11 | Anthropic - Introducing 100K Context Windows ([Blog](https://www.anthropic.com/index/100k-context-windows)) |
| 5.11 | CoMoSpeech: One-Step Speech and Singing Voice Synthesis via Consistency Model ([:x:](https://arxiv.org/abs/2305.06908)), ([:paperclip:](https://arxiv.org/pdf/2305.06908.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06908)) |
| 5.11 | Exploiting Diffusion Prior for Real-World Image Super-Resolution ([:x:](https://arxiv.org/abs/2305.07015)), ([:paperclip:](https://arxiv.org/pdf/2305.07015.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07015)), ([Project page](https://iceclear.github.io/projects/stablesr/)) |
| 5.11 | Domain Incremental Lifelong Learning in an Open World ([:x:](https://arxiv.org/abs/2305.06555)), ([:paperclip:](https://arxiv.org/pdf/2305.06555.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06555)) |
| 5.11 | Not All Languages Are Created Equal in LLMs: Improving Multilingual Capability by Cross-Lingual-Thought Prompting ([:x:](https://arxiv.org/abs/2305.07004)), ([:paperclip:](https://arxiv.org/pdf/2305.07004.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07004)) |
| 5.11 | Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers ([:x:](https://arxiv.org/abs/2305.07011)), ([:paperclip:](https://arxiv.org/pdf/2305.07011.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07011)) |
| 5.11 | EfficientViT: Memory Efficient Vision Transformer with Cascaded Group Attention ([:x:](https://arxiv.org/abs/2305.07027)), ([:paperclip:](https://arxiv.org/pdf/2305.07027.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.07027)), ([:octocat:](https://github.com/microsoft/Cream/tree/main/EfficientViT)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/Cream?style=social)) |
| 5.11 | InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning ([:x:](https://arxiv.org/abs/2305.06500)), ([:paperclip:](https://arxiv.org/pdf/2305.06500.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06500)), ([:octocat:](https://github.com/salesforce/LAVIS/tree/main/projects/instructblip)![GitHub Repo stars](https://img.shields.io/github/stars/salesforce/LAVIS?style=social)) |
| 5.11 | Huggingface Transformers Agent ([API](https://huggingface.co/docs/transformers/transformers_agents)) |
| 5.11 | Google PaLM 2 Technical Report ([:paperclip:](https://ai.google/static/documents/palm2techreport.pdf)), ([Blog](https://ai.google/discover/palm2)) |
| 5.11 | Google MusicLM ([Demo](https://aitestkitchen.withgoogle.com/experiments/music-lm)), ([news](https://techcrunch.com/2023/05/10/google-makes-its-text-to-music-ai-public/)) |
| 5.10 | LMFlow Benchmark: An Automatic Evaluation Framework for Open-Source LLMs ([blog](https://blog.gopenai.com/lmflow-benchmark-an-automatic-evaluation-framework-for-open-source-llms-ef5c6f142418)) | 
| 5.10 | Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text Analytics? An Examination on Several Typical Tasks ([:x:](https://arxiv.org/abs/2305.05862)), ([:paperclip:](https://arxiv.org/pdf/2305.05862.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.05862)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/are-chatgpt-and-gpt-4-general-purpose-solvers)) |
| 5.10 | HumanRF: High-Fidelity Neural Radiance Fields for Humans in Motion ([:x:](https://arxiv.org/abs/2305.06356)), ([:paperclip:](https://arxiv.org/pdf/2305.06356.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06356)) |
| 5.10 | VideoChat: Chat-Centric Video Understanding ([:x:](https://arxiv.org/abs/2305.06355)), ([:paperclip:](https://arxiv.org/pdf/2305.06355.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06355)) |
| 5.10 | Bot or Human? Detecting ChatGPT Imposters with A Single Question ([:x:](https://arxiv.org/abs/2305.06424)), ([:paperclip:](https://arxiv.org/pdf/2305.06424.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06424)) |
| 5.10 | Do LLMs Understand User Preferences? Evaluating LLMs On User Rating Prediction ([:x:](https://arxiv.org/abs/2305.06474)), ([:paperclip:](https://arxiv.org/pdf/2305.06474.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06474)) |
| 5.10 | Relightify: Relightable 3D Faces from a Single Image via Diffusion Models ([:x:](https://arxiv.org/abs/2305.06077)), ([:paperclip:](https://arxiv.org/pdf/2305.06077.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06077)) |
| 5.10 | Similarity of Neural Network Models: A Survey of Functional and Representational Measures ([:x:](https://arxiv.org/abs/2305.06329)), ([:paperclip:](https://arxiv.org/pdf/2305.06329.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06329)) |
| 5.10 | Generative AI meets 3D: A Survey on Text-to-3D in AIGC Era  ([:x:](https://arxiv.org/abs/2305.06131)), ([:paperclip:](https://arxiv.org/pdf/2305.06131.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06131)) |
| 5.10 | MPT-7B StoryWriter- new open-source language model that can handle really long inputs ([Replicate](https://replicate.com/replicate/mpt-7b-storywriter)) |
| 5.10 | [Humata.ai](https://www.humata.ai/) - Ask AI anything about your files ([Tweet](https://twitter.com/hasantoxr/status/1655963736149045249)) |
| 5.10 | IMAGEBIND: One Embedding Space To Bind Them All ([:paperclip:](https://dl.fbaipublicfiles.com/imagebind/imagebind_final.pdf)), ([Blog](https://ai.facebook.com/blog/imagebind-six-modalities-binding-ai/)), ([:octocat:](https://github.com/facebookresearch/ImageBind)![GitHub Repo stars](https://img.shields.io/github/stars/facebookresearch/ImageBind?style=social)), ([:trophy:papers with code](https://paperswithcode.com/paper/imagebind-one-embedding-space-to-bind-them)), ([star history](https://star-history.com/#facebookresearch/ImageBind&Date)) |
| 5.9 | StarCoder: may the source be with you! ([:x:](https://arxiv.org/abs/2305.06161)), ([:paperclip:](https://arxiv.org/pdf/2305.06161.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.06161)), ([:house:](https://huggingface.co/papers/2305.06161)) |
| 5.9 | Towards Building the Federated GPT: Federated Instruction Tuning ([:x:](https://arxiv.org/abs/2305.05644)), ([:paperclip:](https://arxiv.org/pdf/2305.05644.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.05644)), ([:octocat:](https://github.com/JayZhang42/FederatedGPT-Shepherd)![GitHub Repo stars](https://img.shields.io/github/stars/JayZhang42/FederatedGPT-Shepherd?style=social)) |
| 5.9 | Large Language Model Programs ([:x:](https://arxiv.org/abs/2305.05364)), ([:paperclip:](https://arxiv.org/pdf/2305.05364.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.05364)) |
| 5.9 | FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance ([:x:](https://arxiv.org/abs/2305.05176)), ([:paperclip:](https://arxiv.org/pdf/2305.05176.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.05176)) |
| 5.9 | OpenAI - Language models can explain neurons in language models ([Blog](https://openai.com/research/language-models-can-explain-neurons-in-language-models)), ([Paper](https://openaipublic.blob.core.windows.net/neuron-explainer/paper/index.html)), ([:octocat:](https://github.com/openai/automated-interpretability)![GitHub Repo stars](https://img.shields.io/github/stars/openai/automated-interpretability?style=social)), ([Tweet](https://twitter.com/OpenAI/status/1655982364273831936)) |
| 5.9 | AvatarReX: Real-time Expressive Full-body Avatars ([:x:](https://arxiv.org/abs/2305.04789)), ([:paperclip:](https://arxiv.org/pdf/2305.04789.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.04789)) | 
| 5.8 | Augmented Large Language Models with Parametric Knowledge Guiding ([:x:](https://arxiv.org/abs/2305.04789)), ([:paperclip:](https://arxiv.org/pdf/2305.04789.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.04789)) | 
| 5.8 | We had ChatGPT take the CPA exam — and it failed ([news](https://www.accountingtoday.com/news/we-ran-the-cpa-exam-through-chatgpt-and-it-failed-miserably)) |
| 5.8 | Comparison of GPT-3.5, GPT-4, and human user performance on a practice ophthalmology written examination ([Nature](https://www.nature.com/articles/s41433-023-02564-2)) |
| 5.8 | MultiModal-GPT: A Vision and Language Model for Dialogue with Humans  ([:x:](https://arxiv.org/abs/2305.04790)), ([:paperclip:](https://arxiv.org/pdf/2305.04790.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.04790)), ([:octocat:](https://github.com/open-mmlab/Multimodal-GPT)![GitHub Repo stars](https://img.shields.io/github/stars/open-mmlab/Multimodal-GPT?style=social)), ([:house:](https://huggingface.co/papers/2305.04790)), ([Star history](https://star-history.com/#open-mmlab/Multimodal-GPT&Date)) |
| 5.7 | SuperAgent - Deploy LLM Agents to production ([:octocat:](https://github.com/homanp/superagent)![GitHub Repo stars](https://img.shields.io/github/stars/homanp/superagent?style=social)) |
| 5.7 | Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models ([:x:](https://arxiv.org/abs/2305.04091)), ([:paperclip:](https://arxiv.org/pdf/2305.04091.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.04091)), ([:octocat:](https://github.com/AGI-Edgerunners/Plan-and-Solve-Prompting)![GitHub Repo stars](https://img.shields.io/github/stars/AGI-Edgerunners/Plan-and-Solve-Prompting?style=social)) |
| 5.7 | X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages ([:x:](https://arxiv.org/abs/2305.04160)), ([:paperclip:](https://arxiv.org/pdf/2305.04160.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.04160)) |
| 5.7 | Multi-Space Neural Radiance Fields ([:x:](https://arxiv.org/abs/2305.04268)), ([:paperclip:](https://arxiv.org/pdf/2305.04268.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.04268)), ([Project page](https://zx-yin.github.io/msnerf/)), ([Dataset](https://drive.google.com/drive/folders/1gqmonTlR8LbJkljtT28S47N_o_YoExFz)) |
| 5.7 | Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting ([:x:](https://arxiv.org/abs/2305.04388)), ([:paperclip:](https://arxiv.org/pdf/2305.04388.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.04388)) |
| 5.7 | Yoshua Bengio - AI Scientists: Safe and Useful AI? ([Blog](https://yoshuabengio.org/2023/05/07/ai-scientists-safe-and-useful-ai/)) |
| 5.5 | privateGPT - Interact privately with your documents using the power of GPT, 100% privately, no data leaks ([:octocat:](https://github.com/imartinez/privateGPT)![GitHub Repo stars](https://img.shields.io/github/stars/imartinez/privateGPT?style=social)), ([star history](https://star-history.com/#imartinez/privateGPT&Date)) |
| 5.5 | Open LLMs : A list of open LLMs available for commercial use - ([:octocat:](https://github.com/eugeneyan/open-llms)![GitHub Repo stars](https://img.shields.io/github/stars/eugeneyan/open-llms?style=social)) |
| 5.5 | A Suite of Generative Tasks for Multi-Level Multimodal Webpage Understanding ([:x:](https://arxiv.org/abs/2305.03668)), ([:paperclip:](https://arxiv.org/pdf/2305.03668.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.03668)), ([:house:](https://huggingface.co/papers/2305.03668)) |
| 5.5 | Otter: A Multi-Modal Model with In-Context Instruction Tuning  ([:x:](https://arxiv.org/abs/2305.03726)), ([:paperclip:](https://arxiv.org/pdf/2305.03726.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.03726)), ([:octocat:](https://github.com/Luodian/Otter)![GitHub Repo stars](https://img.shields.io/github/stars/Luodian/Otter?style=social)), ([:house:](https://huggingface.co/papers/2305.03726)) |
| 5.5 | Composite Motion Learning with Task Control ([:x:](https://arxiv.org/abs/2305.03286)), ([:paperclip:](https://arxiv.org/pdf/2305.03286.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.03286)), ([:octocat:](https://github.com/xupei0610/CompositeMotion)![GitHub Repo stars](https://img.shields.io/github/stars/xupei0610/CompositeMotion?style=social)), ([Papper page](https://huggingface.co/papers/2305.03286)) |
| 5.5 | StarCoderBase: trained on 1T tokens in 80+ programming languages ([Huggingface](https://huggingface.co/bigcode/starcoderbase)) |
| 5.5 | Dolphin: General video interaction platform based on LLMs ([Demo](https://da2c48f45ee053ef87.gradio.live/)), ([:octocat:](https://github.com/kaleido-lab/dolphin)![GitHub Repo stars](https://img.shields.io/github/stars/kaleido-lab/dolphin?style=social)), ([Tweet](https://twitter.com/_akhaliq)) | 
| 5.5 | MPT-7B: A New Standard for Open-Source, Commercially Usable LLMs ([Blog](https://www.mosaicml.com/blog/mpt-7b)), Commercially usable: ([MPT-7B](https://huggingface.co/mosaicml/mpt-7b))  ([MPT-7B-Instruct](https://huggingface.co/mosaicml/mpt-7b-instruct)), ([MPT-7B-StoryWriter](https://huggingface.co/mosaicml/mpt-7b-storywriter)), For non-commerical use: ([MPT-7B-Chat](https://huggingface.co/mosaicml/mpt-7b-chat)) |
| 5.5 | StarCoder: A State-of-the-Art LLM for Code ([Blog](https://huggingface.co/blog/starcoder)), ([:octocat:](https://github.com/bigcode-project/starcoder/)![GitHub Repo stars](https://img.shields.io/github/stars/bigcode-project/starcoder?style=social)), ([HuggingFace](https://huggingface.co/bigcode/starcoder)), ([Tweet](https://twitter.com/BigCodeProject/status/1654174941976068119)) |
| 5.5 | OpenAlpaca, an instruction-following model based on OpenLLaMA ([:octocat:](https://github.com/openlm-research/open_llama)![GitHub Repo stars](https://img.shields.io/github/stars/openlm-research/open_llama?style=social)), ([Huggingface](https://huggingface.co/openlm-research/open_llama_7b_preview_200bt)), ([Tweet](https://twitter.com/yixuan_su/status/1654234602003636226)) |
| 5.4 | Seeing is Believing: Brain-Inspired Modular Training for Mechanistic Interpretability  ([:x:](https://arxiv.org/abs/2305.08746)), ([:paperclip:](https://arxiv.org/pdf/2305.08746.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.08746)), ([:octocat:](https://github.com/KindXiaoming/BIMT)(https://img.shields.io/github/stars/KindXiaoming/BIMT?style=social)), ([demo](https://colab.research.google.com/drive/1hggc5Tae97BORVNdesLcwp9og3SmPtM7?usp=sharing)), ([Papper page](https://huggingface.co/papers/2305.08746)) |
| 5.4 | Evaluating the Performance of ChatGPT in Ophthalmology: An Analysis of its Successes and Shortcomings ([Ophthalmology Science](https://www.ophthalmologyscience.org/article/S2666-9145(23)00056-8/fulltext)) | 
| 5.4 | Cognitive Reframing of Negative Thoughts through Human-Language Model Interaction ([:x:](https://arxiv.org/abs/2305.02466)), ([:paperclip:](https://arxiv.org/pdf/2305.02466.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.02466)) |
| 5.4 | Governance of the AI, by the AI, and for the AI ([:x:](https://arxiv.org/abs/2305.03719)), ([:paperclip:](https://arxiv.org/pdf/2305.03719.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.03719)), ([Papper page](https://huggingface.co/papers/2305.03719)) |
| 5.4 | Can LLM Already Serve as A Database Interface? A BIg Bench for Large-Scale Database Grounded Text-to-SQLs  ([:x:](https://arxiv.org/abs/2305.03111)), ([:paperclip:](https://arxiv.org/pdf/2305.03111.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.03111)) |
| 5.4 | Diffusion Explainer: Visual Explanation for Text-to-image Stable Diffusion ([:x:](https://arxiv.org/abs/2305.03509)), ([:paperclip:](https://arxiv.org/pdf/2305.03509.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.03509)), ([Papper page](https://huggingface.co/papers/2305.03509)) |
| 5.4 | AttentionViz: A Global View of Transformer Attention ([:x:](https://arxiv.org/abs/2305.03210)), ([:paperclip:](https://arxiv.org/pdf/2305.03210.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.03210)), ([Papper page](https://huggingface.co/papers/2305.03210)) |
| 5.4 | Reddit - [OpenAI lost $540M in 2022, will need $100B more to develop AGI, says Altman. My breakdown on why this matters and what it means for other AI startups](https://www.reddit.com/r/ChatGPT/comments/1383obf/openai_lost_540m_in_2022_will_need_100b_more_to/) |
| 5.4 | FACT SHEET: Biden-⁠Harris Administration Announces New Actions to Promote Responsible AI Innovation that Protects Americans’ Rights and Safety - ([White house](https://www.whitehouse.gov/briefing-room/statements-releases/2023/05/04/fact-sheet-biden-harris-administration-announces-new-actions-to-promote-responsible-ai-innovation-that-protects-americans-rights-and-safety/)) |
| 5.4 | Google "We Have No Moat, And Neither Does OpenAI" - ([Blog](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither)) |
| 5.4 | CNBC - [Britain launches probe into ChatGPT-style A.I. as regulators grow concerned by risks](https://www.cnbc.com/2023/05/04/chatgpt-britain-launches-competition-probe-into-ai-consumer-risks.html?utm_content=Main&utm_medium=Social&utm_source=Twitter) |
| 5.4 | Personalize Segment Anything Model with One Shot ([:x:](https://arxiv.org/abs/2305.03048)), ([:paperclip:](https://arxiv.org/pdf/2305.03048.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.03048)), ([:octocat:](https://github.com/ZrrSkywalker/Personalize-SAM)![GitHub Repo stars](https://img.shields.io/github/stars/ZrrSkywalker/Personalize-SAM?style=social)), ([:house:](https://huggingface.co/papers/2305.03048)) |
| 5.4 | AutoML-GPT: Automatic Machine Learning with GPT ([:x:](https://arxiv.org/abs/2305.02499)), ([:paperclip:](https://arxiv.org/pdf/2305.02499.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.02499)), ([:house:](https://huggingface.co/papers/2305.02499)) |
| 5.4 | NeRSemble: Multi-view Radiance Field Reconstruction of Human Heads ([:x:](https://arxiv.org/abs/2305.03027)), ([:paperclip:](https://arxiv.org/pdf/2305.03027.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.03027), ([Project page](https://tobias-kirschstein.github.io/nersemble/)), ([:house:](https://huggingface.co/papers/2305.03027)) |
| 5.4 | An automatically discovered chain-of-thought prompt generalizes to novel models and datasets ([:x:](https://arxiv.org/abs/2305.02897)), ([:paperclip:](https://arxiv.org/pdf/2305.02897.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.02897))
| 5.4 | NYT - [White House Pushes Tech C.E.O.s to Limit Risks of A.I.](https://www.nytimes.com/2023/05/04/technology/us-ai-research-regulation.html) |
| 5.4 | Microsoft Bing AI chatbot and Edge browser get massive AI upgrades. See the list. ([Blog](https://mashable.com/article/microsoft-bing-ai-chatbot-edge-browser-new-updates-features)) |
| 5.4 | Introducing Slack GPT ([Blog](https://slack.com/intl/ko-kr/blog/news/introducing-slack-gpt)) |
| 5.3 | Distinguishing GPT-4-generated Radiology Abstracts from Original Abstracts: Performance of Blinded Human Observers and AI Content Detector ([medRxiv](https://www.medrxiv.org/content/10.1101/2023.04.28.23289283v1)), ([:paperclip:](https://www.medrxiv.org/content/10.1101/2023.04.28.23289283v1.full.pdf)) |
| 5.3 | Chatbot Arena: Benchmarking LLMs in the Wild with Elo Ratings - ([Blog](https://lmsys.org/blog/2023-05-03-arena/)) |
| 5.3 | CodeGen2: Lessons for Training LLMs on Programming and Natural Languages ([:x:](https://arxiv.org/abs/2305.02309)), ([:paperclip:](https://arxiv.org/pdf/2305.02309.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.02309)), ([:octocat:](https://github.com/salesforce/CodeGen2)![GitHub Repo stars](https://img.shields.io/github/stars/salesforce/CodeGen2?style=social)) |
| 5.3 | Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes ([:x:](https://arxiv.org/abs/2305.02301)), ([:paperclip:](https://arxiv.org/pdf/2305.02301.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.02301)) |
| 5.3 | Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings ([:x:](https://arxiv.org/abs/2305.02317)), ([:paperclip:](https://arxiv.org/pdf/2305.02317.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.02317)) |
| 5.3 | AG3D: Learning to Generate 3D Avatars from 2D Image Collections ([:x:](https://arxiv.org/abs/2305.02312)), ([:paperclip:](https://arxiv.org/pdf/2305.02312.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.02312)), ([Project page](https://zj-dong.github.io/AG3D/)) |
| 5.3 | Shap-E: Generating Conditional 3D Implicit Functions ([:x:](https://arxiv.org/abs/2305.02463)), ([:paperclip:](https://arxiv.org/pdf/2305.02463.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.02463)), ([:octocat:](https://github.com/openai/shap-e)![GitHub Repo stars](https://img.shields.io/github/stars/openai/shap-e?style=social)), ([:house:](https://huggingface.co/papers/2305.02463)) |
| 5.3 | 100 Practical Applications and Use Cases of Generative AI - ([:paperclip:](https://ai.gov.ae/wp-content/uploads/2023/04/406.-Generative-AI-Guide_ver1-EN.pdf)), ([News](https://gulfnews.com/uae/uae-government-launches-guide-on-generative-ai-applications-such-as-chatgpt-1.95449467)) |  
| 5.3 | Comprehensive LLM model zoo - Ecosystem Graphs to track the foundation model ecosystem assets (datasets, models, and applications) and their relationship ([Table](https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=table)), ([Graph](https://crfm.stanford.edu/ecosystem-graphs/index.html?mode=graph)), ([:octocat:](https://github.com/stanford-crfm/ecosystem-graphs)![GitHub Repo stars](https://img.shields.io/github/stars/stanford-crfm/ecosystem-graphs?style=social)) |
| 5.3 | GPTutor: a ChatGPT-powered programming tool for code explanation ([:x:](https://arxiv.org/abs/2305.01863)), ([:paperclip:](https://arxiv.org/pdf/2305.01863.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.01863)) |
| 5.3 | Midjourney 5.1 Arrives - And It’s Another Leap Forward For AI Art - ([Forbes](https://www.forbes.com/sites/barrycollins/2023/05/03/midjourney-51-arrivesand-its-another-leap-forward-for-ai-art/)) |
| 5.3 | Mojo 🔥 — a new programming language for all AI developers ([Web](https://www.modular.com/mojo)), ([tweet](https://twitter.com/Modular_AI/status/1653436642248781825)), ([:octocat:](https://github.com/modularml/mojo)![GitHub Repo stars](https://img.shields.io/github/stars/modularml/mojo?style=social)) |
| 5.3 | #NeurIPS2023 Creative AI Track ([Blog](https://blog.neurips.cc/2023/05/02/call-for-neurips-creative-ai-track/)), ([Call for proposal](https://neurips.cc/Conferences/2023/CallForCreativeAI)) |
| 5.3 | [HeyPi](https://heypi.com/) - Personal AI |
| 5.2 | RadAdapt: Radiology Report Summarization via Lightweight Domain Adaptation of Large Language Models ([:x:](https://arxiv.org/abs/2305.01146)), ([:paperclip:](https://arxiv.org/pdf/2305.01146.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.01146)), ([:house:](https://huggingface.co/papers/2305.01146)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/radadapt-radiology-report-summarization-via)) |
| 5.2 | Interpretable Machine Learning for Science with PySR and SymbolicRegression.jl ([:x:](https://arxiv.org/abs/2305.01582)), ([:paperclip:](https://arxiv.org/pdf/2305.01582.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.01582)) |
| 5.2 | Andrew Ng - ChatGPT Prompt Engineering for Developers - ([online course](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)), ([Tweet](https://twitter.com/AndrewYNg/status/1653141408386260992)) |
| 5.2 | DreamPaint: Few-Shot Inpainting of E-Commerce Items for Virtual Try-On without 3D Modeling ([:x:](https://arxiv.org/abs/2305.01649)), ([:paperclip:](https://arxiv.org/pdf/2305.01649.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.01649)) |
| 5.2 | Generalizing Dataset Distillation via Deep Generative Prior ([:x:](https://arxiv.org/abs/2305.01257)), ([:paperclip:](https://arxiv.org/pdf/2305.01257.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.01257)) |
| 5.2 | Multimodal Procedural Planning via Dual Text-Image Prompting ([:x:](https://arxiv.org/abs/2305.01795)), ([:paperclip:](https://arxiv.org/pdf/2305.01795.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.01795)), ([:octocat:](https://github.com/YujieLu10/TIP)![GitHub Repo stars](https://img.shields.io/github/stars/YujieLu10/TIP?style=social)) |
| 5.2 | WSJ - [Google DeepMind CEO Says Some Form of AGI Possible in a Few Years](https://www.wsj.com/articles/google-deepmind-ceo-says-some-form-of-agi-possible-in-a-few-years-2705f452) |
| 5.2 | Latest NVIDIA Graphics Research Advances Generative AI’s Next Frontier ([Blog](https://blogs.nvidia.com/blog/2023/05/02/graphics-research-advances-generative-ai-next-frontier/)) |
| 5.2 | Pick-a-Pic: An Open Dataset of User Preferences for Text-to-Image Generation ([:x:](https://arxiv.org/abs/2305.01569)), ([:paperclip:](https://arxiv.org/pdf/2305.01569.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.01569)), ([:octocat:](https://github.com/yuvalkirstain/pickscore)![GitHub Repo stars](https://img.shields.io/github/stars/yuvalkirstain/pickscore?style=social)) |
| 5.2 | TMR: Text-to-Motion Retrieval Using Contrastive 3D Human Motion Synthesis ([:x:](https://arxiv.org/abs/2305.00976)), ([:paperclip:](https://arxiv.org/pdf/2305.00976.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.00976)), ([Project page](https://t.co/KH4w0442YP)), ([Demo](https://huggingface.co/spaces/Mathux/TMR)) |
| 5.2 | Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation ([:x:](https://arxiv.org/abs/2305.01210)), ([:paperclip:](https://arxiv.org/pdf/2305.01210.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.01210)), ([:octocat:](https://github.com/evalplus/evalplus)![GitHub Repo stars](https://img.shields.io/github/stars/evalplus/evalplus?style=social)) |
| 5.2 | Unlimiformer: Long-Range Transformers with Unlimited Length Input ([:x:](https://arxiv.org/abs/2305.01625)), ([:paperclip:](https://arxiv.org/pdf/2305.01625.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.01625)) |
| 5.2 | Bark - Text-Prompted Generative Audio Model ([:octocat:](https://github.com/suno-ai/bark)![GitHub Repo stars](https://img.shields.io/github/stars/suno-ai/bark?style=social)) |
| 5.2 | Jsonformer: A Bulletproof Way to Generate Structured JSON from Language Models ([:octocat:](https://github.com/1rgs/jsonformer)![GitHub Repo stars](https://img.shields.io/github/stars/1rgs/jsonformer?style=social)) |
| 5.1 | scGPT: Towards Building a Foundation Model for Single-Cell Multi-omics Using Generative AI ([bioXiv](https://www.biorxiv.org/content/10.1101/2023.04.30.538439v1)), ([:paperclip:](https://www.biorxiv.org/content/10.1101/2023.04.30.538439v1.full.pdf)) |
| 5.1 | The Guardian - [AI makes non-invasive mind-reading possible by turning thoughts into text](https://www.theguardian.com/technology/2023/may/01/ai-makes-non-invasive-mind-reading-possible-by-turning-thoughts-into-text) |
| 5.1 | Learning to Reason and Memorize with Self-Notes ([:x:](https://arxiv.org/abs/2305.00833)), ([:paperclip:](https://arxiv.org/pdf/2305.00833.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.00833)) |
| 5.1 | Poisoning Language Models During Instruction Tuning ([:x:](https://arxiv.org/abs/2305.00944)), ([:paperclip:](https://arxiv.org/pdf/2305.00944.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.00944)) |
| 5.1 | What Do Self-Supervised Vision Transformers Learn? ([:x:](https://arxiv.org/abs/2305.00729)), ([:paperclip:](https://arxiv.org/pdf/2305.00729.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.00729)) |
| 5.1 | [NYT](https://www.nytimes.com/2023/05/01/technology/ai-google-chatbot-engineer-quits-hinton.html) - ‘The Godfather of A.I.’ Leaves Google and Warns of Danger Ahead ([Archive](https://archive.is/TgPyC#selection-331.0-331.63)) |
| 4.30 | ChatGPT: Is this version good for healthcare and research? - ([ScienceDirect](https://www.sciencedirect.com/science/article/abs/pii/S1871402123000401)) |
| 4.30 | Understanding Parameter-Efficient LLM Finetuning: Prompt Tuning And Prefix Tuning ([Blog](https://magazine.sebastianraschka.com/p/understanding-parameter-efficient)) |
| 4.30 | A brief history of LLaMA models ([Blog](https://agi-sphere.com/llama-models/)) |
| 4.30 | BabyBeeAGI: Task Management and Functionality Expansion on top of BabyAGI ([blog](https://yoheinakajima.com/babybeeagi-task-management-and-functionality-expansion-on-top-of-babyagi/)), ([Replit](https://replit.com/@YoheiNakajima/BabyBeeAGI?v=1)), ([:octocat:](https://github.com/yoheinakajima/babyagi)![GitHub Repo stars](https://img.shields.io/github/stars/yoheinakajima/babyagi?style=social)), ([OG BaybyAGI](https://replit.com/@YoheiNakajima/babyagi)) |
| 4.30 | Results of G7 Digital and Tech Ministers’ Meeting in Takasaki, Gunma - ([Summary](https://g7digital-tech-2023.go.jp/en/topics/topics_20230430.html)), ([Declaration](https://g7digital-tech-2023.go.jp/topics/pdf/pdf_20230430/ministerial_declaration_dtmm.pdf)), ([Annex1](https://g7digital-tech-2023.go.jp/topics/pdf/pdf_20230430/annex1.pdf)), ([Annex2](https://g7digital-tech-2023.go.jp/topics/pdf/pdf_20230430/annex2.pdf)), ([Annex3](https://g7digital-tech-2023.go.jp/topics/pdf/pdf_20230430/annex3.pdf)), ([Annex4](https://g7digital-tech-2023.go.jp/topics/pdf/pdf_20230430/annex4.pdf)), ([Annex5](https://g7digital-tech-2023.go.jp/topics/pdf/pdf_20230430/annex5.pdf)) |
| 4.30 | PandaLM: Reproducible and Automated Language Model Assessment ([:octocat:](https://github.com/WeOpenML/PandaLM)![GitHub Repo stars](https://img.shields.io/github/stars/WeOpenML/PandaLM?style=social)) |
| 4.29 | Can ChatGPT Pass An Introductory Level Functional Language Programming Course? ([:x:](https://arxiv.org/abs/2305.02230)), ([:paperclip:](https://arxiv.org/pdf/2305.02230.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.02230)) |
| 4.29 | A Review of ChatGPT Applications in Education, Marketing, Software Engineering, and Healthcare: Benefits, Drawbacks, and Research Directions ([:x:](https://arxiv.org/abs/2305.00237)), ([:paperclip:](https://arxiv.org/pdf/2305.00237.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.00237)) |
| 4.29 | ChatGPT-2D, which can generate mind maps with AI - ([Tweet](https://twitter.com/eyishazyer/status/1652215468005146626)), ([ChatGPT-2D](https://superusapp.com/chatgpt2d/)) |
| 4.29 | MLC LLM - an open framework that brings language models (LLMs) directly into a broad class of platforms (CUDA, Vulkan, Metal) with GPU acceleration ([Tweet](https://twitter.com/bohanhou1998/status/1652151502012837890)), ([Demo](https://mlc.ai/mlc-llm/)), ([:octocat:](https://github.com/mlc-ai/mlc-llm)![GitHub Repo stars](https://img.shields.io/github/stars/mlc-ai/mlc-llm?style=social)) |
| 4.29 | GenOs Index - The April (aka the Frenetic Pace) Edition - ([blog](https://www.decibel.vc/articles/genos-index-the-april-aka-the-frenetic-pace-edition)) |
| 4.29 | StableVicuna, the AI World’s First Open Source RLHF LLM Chatbot! - ([Blog](https://stability.ai/blog/stablevicuna-open-source-rlhf-chatbot)), ([Tweet](https://twitter.com/StabilityAI/status/1652026192193785856)) |
| 4.29 | DeepFloyd - a state-of-the-art text-to-image model ([Web](https://deepfloyd.ai/deepfloyd-if)), ([:octocat:](https://github.com/deep-floyd/IF)![GitHub Repo stars](https://img.shields.io/github/stars/deep-floyd/IF?style=social)), ([HuggingFace demo](https://huggingface.co/spaces/DeepFloyd/IF)), ([Tweet](https://twitter.com/deepfloydai/status/1651983493717532673)) |
| 4.29 | When Patient Questions Are Answered With Higher Quality and Empathy by ChatGPT than Physicians - ([Blog](https://erictopol.substack.com/p/when-patient-questions-are-answered)) |
| 4.29 | BMTools - Tool Learning for Big Models, Open-Source Solutions of ChatGPT-Plugins ([:octocat:](https://github.com/openbmb/bmtools)) |
| 4.29 | FastChat-T5 ([:octocat:](https://github.com/lm-sys/FastChat#FastChat-T5)![GitHub Repo stars](https://img.shields.io/github/stars/lm-sys/FastChat#FastChat-T5?style=social)), ([Tweet](https://twitter.com/lmsysorg/status/1652037026705985537)) |
| 4.29 | Lamini, the LLM Engine for Rapidly Customizing Models - ([Blog](https://lamini.ai/blog/introducing-lamini)) |
| 4.28 | SAM on Medical Images: A Comprehensive Study on Three Prompt Modes ([:x:](https://arxiv.org/abs/2305.00035)), ([:paperclip:](https://arxiv.org/pdf/2305.00035.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.00035)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/sam-on-medical-images-a-comprehensive-study)) |
| 4.28 | EU proposes new copyright rules for generative AI - ([Reuter](https://www.reuters.com/technology/eu-lawmakers-committee-reaches-deal-artificial-intelligence-act-2023-04-27/)), ([Economic times](https://www.reuters.com/technology/eu-lawmakers-committee-reaches-deal-artificial-intelligence-act-2023-04-27/)) | 
| 4.28 | PROMPTENGINEERING FORCHATGPTA QUICKGUIDE TOTECHNIQUES, TIPS,ANDBESTPRACTICES - ([:paperclip:](https://www.techrxiv.org/articles/preprint/Prompt_Engineering_For_ChatGPT_A_Quick_Guide_To_Techniques_Tips_And_Best_Practices/22683919)) |
| 4.28 | ResiDual: Transformer with Dual Residual Connections ([:x:](https://arxiv.org/abs/2304.14802)), ([:paperclip:](https://arxiv.org/pdf/2304.14802.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.14802)), ([:octocat:](https://github.com/microsoft/ResiDual)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/ResiDual?style=social)) |
| 4.28 | Causal Reasoning and Large Language Models: Opening a New Frontier for Causality ([:x:](https://arxiv.org/abs/2305.00050)), ([:paperclip:](https://arxiv.org/pdf/2305.00050.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.00050)) |
| 4.28 | We Interviewed the Engineer Google Fired for Saying Its AI Had Come to Life ([Futurism](https://futurism.com/blake-lemoine-google-interview)) |
| 4.28 | LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model ([:x:](https://arxiv.org/abs/2304.15010)), ([:paperclip:](https://arxiv.org/pdf/2304.15010.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.15010)), ([:octocat:](https://github.com/ZrrSkywalker/LLaMA-Adapter)![GitHub Repo stars](https://img.shields.io/github/stars/ZrrSkywalker/LLaMA-Adapter?style=social)) |
| 4.28 | MLCopilot: Unleashing the Power of Large Language Models in Solving Machine Learning Tasks ([:x:](https://arxiv.org/abs/2304.14979)), ([:paperclip:](https://arxiv.org/pdf/2304.14979.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.14979)) |
| 4.28 | Are Emergent Abilities of Large Language Models a Mirage? ([:x:](https://arxiv.org/abs/2304.15004)), ([:paperclip:](https://arxiv.org/pdf/2304.15004.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.15004)) |
| 4.28 | The Ultimate Battle of Language Models: Lit-LLaMA vs GPT3.5 vs Bloom vs …. ([Blog](https://lightning.ai/pages/community/community-discussions/the-ultimate-battle-of-language-models-lit-llama-vs-gpt3.5-vs-bloom-vs/)) |
| 4.28 | Otter, a multi-modal in-context learning model with instruction tuning - ([:octocat:](https://github.com/Luodian/otter)![GitHub Repo stars](https://img.shields.io/github/stars/Luodian/otter?style=social)), ([Demo](https://otter.cliangyu.com/)), ([Youtube](https://www.youtube.com/watch?v=r-YM4DGGAdE)) |
| 4.28 | [Economist](https://www.economist.com/by-invitation/2023/04/28/yuval-noah-harari-argues-that-ai-has-hacked-the-operating-system-of-human-civilisation) - Yuval Noah Harari argues that AI has hacked the operating system of human civilisation ([Archive](https://archive.is/HGRsq#selection-1039.0-1039.86)) |
| 4.28 | Assessing the Potential of USMLE-Like Exam Questions Generated by GPT-4 ([medRxiv](https://www.medrxiv.org/content/10.1101/2023.04.25.23288588v1)), ([:paperclip:](https://www.medrxiv.org/content/10.1101/2023.04.25.23288588v1.full.pdf)) |
| 4.28 | JAMA - Comparing Physician and Artificial Intelligence Chatbot Responses to Patient Questions Posted to a Public Social Media Forum - ([paper](https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2804309?guestAccessKey=6d6e7fbf-54c1-49fc-8f5e-ae7ad3e02231&utm_source=For_The_Media&utm_medium=referral&utm_campaign=ftm_links&utm_content=tfl&utm_term=042823)) |
| 4.27 | Ethics of large language models in medicine and medical research (The Lancet, [https://doi.org/10.1016/S2589-7500(23)00083-3](https://www.thelancet.com/journals/landig/article/PIIS2589-7500(23)00083-3/fulltext)), ([PDF](https://www.thelancet.com/action/showPdf?pii=S2589-7500%2823%2900083-3)) |
| 4.27 | ChatGPT as an Attack Tool: Stealthy Textual Backdoor Attack via Blackbox Generative Model Trigger ([:x:](https://arxiv.org/abs/2304.14475)), ([:paperclip:](https://arxiv.org/pdf/2304.14475.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.14475)) |
| 4.27 | PMC-LLaMA: Further Finetuning LLaMA on Medical Papers ([:x:](https://arxiv.org/abs/2304.14454)), ([:paperclip:](https://arxiv.org/pdf/2304.14454.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.14454)), ([:octocat:](https://github.com/chaoyi-wu/PMC-LLaMA)![GitHub Repo stars](https://img.shields.io/github/stars/chaoyi-wu/PMC-LLaMA?style=social)) |
| 4.27 | "Can ChatGPT Diagnose Me?" How Large Language Models will Transform Clinical Care - ([Youtube](https://www.youtube.com/playlist?list=PLe6zdIMe5B7JWokb0Vvket4M3h-0KvBNn)) |
| 4.27 | Large Language Models Are State-of-the-Art Evaluators of Code Generation ([:x:](https://arxiv.org/abs/2304.14317)), ([:paperclip:](https://arxiv.org/pdf/2304.14317.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.14317)) |
| 4.27 | Controlled Text Generation with Natural Language Instructions  ([:x:](https://arxiv.org/abs/2303.14293)), ([:paperclip:](https://arxiv.org/pdf/2303.14293.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.14293)) |
| 4.27 | A Survey of Large Language Models - version 8 ([:x:](https://arxiv.org/abs/2303.18223)), ([:paperclip:](https://arxiv.org/pdf/2303.18223.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.18223)) |
| 4.27 | LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions ([:x:](https://arxiv.org/abs/2304.14402)), ([:paperclip:](https://arxiv.org/pdf/2304.14402.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.14402)), ([:octocat:]([https://github.com/m](https://github.com/mbzuai-nlp/LaMini-LM)![GitHub Repo stars](https://img.shields.io/github/stars/mbzuai-nlp/LaMini-LM?style=social)) |
| 4.27 | DataComp: In search of the next generation of multimodal datasets ([:x:](https://arxiv.org/abs/2304.14108)), ([:paperclip:](https://arxiv.org/pdf/2304.14108.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.14108)), ([:octocat:](https://github.com/mlfoundations/datacomp)![GitHub Repo stars](https://img.shields.io/github/stars/mlfoundations/datacomp?style=social)), ([Project page](https://www.datacomp.ai/)) |
| 4.27 | We're Afraid Language Models Aren't Modeling Ambiguity ([:x:](https://arxiv.org/abs/2304.14399)), ([:paperclip:](https://arxiv.org/pdf/2304.14399.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.14399)) |
| 4.27 | Boston Dynamics robot dog can answer your questions now, thanks to ChatGPT - ([ZDNet](https://www.zdnet.com/article/boston-dynamics-robot-dog-can-answer-your-questions-now-thanks-to-chatgpt/)), ([YouTube](https://www.youtube.com/watch?v=Y1-s37zrm1M)) |
| 4.27 | LlamaIndex & Deep Lake for Financial Statement Analysis ([Blog](https://medium.com/@jerryjliu98/llamaindex-deep-lake-for-financial-statement-analysis-954f2b789c8e)) |
| 4.26 | Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement Learning ([:x:](https://arxiv.org/abs/2304.13653)), ([:paperclip:](https://arxiv.org/pdf/2304.13653.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13653)) |
| 4.26 | Multidimensional Evaluation for Text Style Transfer Using ChatGPT ([:x:](https://arxiv.org/abs/2304.13462)), ([:paperclip:](https://arxiv.org/pdf/2304.13462.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13462)) |
| 4.26 | NPJ - Comparing scientific abstracts generated by ChatGPT to real abstracts with detectors and blinded human reviewers ([Paper](https://www.nature.com/articles/s41746-023-00819-6)), ([:paperclip:](https://www.nature.com/articles/s41746-023-00819-6.pdf)) |
| 4.26 | [TopGPT](https://www.topgpt.io/) — the world’s first Andrew Tate large language model |
| 4.26 | Multi-Party Chat: Conversational Agents in Group Settings with Humans and Models ([:x:](https://arxiv.org/abs/2304.13835)), ([:paperclip:](https://arxiv.org/pdf/2304.13835.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13835)) |
| 4.26 | MOSS, a 16B tool-augmented conversational language model ([Tweet](https://twitter.com/tianxiangsun/status/1650895260493705216)), ([:octocat:](https://github.com/OpenLMLab/MOSS)![GitHub Repo stars](https://img.shields.io/github/stars/OpenLMLab/MOSS?style=social)) |
| 4.26 | Exploring the Curious Case of Code Prompts ([:x:](https://arxiv.org/abs/2304.13250)), ([:paperclip:](https://arxiv.org/pdf/2304.13250.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13250)) |
| 4.26 | Controllable Image Generation via Collage Representations ([:x:](https://arxiv.org/abs/2304.13722)), ([:paperclip:](https://arxiv.org/pdf/2304.13722.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13722)) |
| 4.26 | Unleashing Infinite-Length Input Capacity for Large-scale Language Models with Self-Controlled Memory System ([:x:](https://arxiv.org/abs/2304.13343)), ([:paperclip:](https://arxiv.org/pdf/2304.13343.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13343)) |
| 4.26 | TextDeformer: Geometry Manipulation using Text Guidance ([:x:](https://arxiv.org/abs/2304.13348)), ([:paperclip:](https://arxiv.org/pdf/2304.13348.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13348)) |
| 4.26 | Evaluation of GPT-3.5 and GPT-4 for supporting real-world information needs in healthcare delivery ([:x:](https://arxiv.org/abs/2304.13714)), ([:paperclip:](https://arxiv.org/pdf/2304.13714.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13714)) |
| 4.26 | Ray Conditioning: Trading Photo-consistency for Photo-realism in Multi-view Image Generation ([:x:](https://arxiv.org/abs/2304.13681)), ([:paperclip:](https://arxiv.org/pdf/2304.13681.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13681)), ([Project page](https://ray-cond.github.io/)) |
| 4.26 | Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond ([:x:](https://arxiv.org/abs/2304.13712)), ([:paperclip:](https://arxiv.org/pdf/2304.13712.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13712)), ([:octocat:](https://github.com/Mooler0410/LLMsPracticalGuide)![GitHub Repo stars](https://img.shields.io/github/stars/Mooler0410/LLMsPracticalGuide?style=social)) |
| 4.26 | [HuggingChat](https://huggingface.co/chat/) - the first open source alternative to ChatGPT |
| 4.25 | [Time](https://time.com/6273743/thinking-that-could-doom-us-with-ai/) - The 'Don't Look Up' Thinking That Could Doom Us With AI ([Archive](https://archive.is/gMi8q)) |
| 4.25 | AI-assisted coding: Experiments with GPT-4 ([:x:](https://arxiv.org/abs/2304.13187)), ([:paperclip:](https://arxiv.org/pdf/2304.13187.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13187)) |
| 4.25 | NVIDIA NeMo Guardrails helps enterprises keep applications built on large language models aligned with their safety and security requirements ([Blog](https://blogs.nvidia.com/blog/2023/04/25/ai-chatbot-guardrails-nemo/)), ([:octocat:](https://github.com/NVIDIA/NeMo-Guardrails)![GitHub Repo stars](https://img.shields.io/github/stars/NVIDIA/NeMo-Guardrails?style=social)) |
| 4.25 | Stable and low-precision training for large-scale vision-language models ([:x:](https://arxiv.org/abs/2304.13013)), ([:paperclip:](https://arxiv.org/pdf/2304.13013.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13013)) |
| 4.25 | AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head ([:x:](https://arxiv.org/abs/2304.12995)), ([:paperclip:](https://arxiv.org/pdf/2304.12995.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12995)) |
| 4.25 | Answering Questions by Meta-Reasoning over Multiple Chains of Thought ([:x:](https://arxiv.org/abs/2304.13007)), ([:paperclip:](https://arxiv.org/pdf/2304.13007.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13007)) |
| 4.25 | Patch-based 3D Natural Scene Generation from a Single Example ([:x:](https://arxiv.org/abs/2304.12670)), ([:paperclip:](https://arxiv.org/pdf/2304.12670.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12670)), ([Project page](http://weiyuli.xyz/Sin3DGen/))  |
| 4.25 | Generative AI at Work - ([NBER](https://www.nber.org/papers/w31161)), ([:paperclip:](https://www.nber.org/system/files/working_papers/w31161/w31161.pdf)) | 
| 4.25 | [Chatbot Arena](https://chat.lmsys.org/?arena) |
| 4.24 | Text-to-Audio Generation using Instruction-Tuned LLM and Latent Diffusion Model ([:x:](https://arxiv.org/abs/2304.13731)), ([:paperclip:](https://arxiv.org/pdf/2304.13731.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.13731)),([Project page](https://tango-web.github.io/)), ([:octocat:](https://github.com/declare-lab/tango)![GitHub Repo stars](https://img.shields.io/github/stars/declare-lab/tango?style=social)) |
| 4.24 | AI, write an essay for me: A large-scale comparison of human-written versus ChatGPT-generated essays ([:x:](https://arxiv.org/abs/2304.14276)), ([:paperclip:](https://arxiv.org/pdf/2304.14276.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.14276)) |
| 4.24 | Pointersect: Neural Rendering with Cloud-Ray Intersection ([:x:](https://arxiv.org/abs/2304.12390)), ([:paperclip:](https://arxiv.org/pdf/2304.12390.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12390)), ([web](https://machinelearning.apple.com/research/pointersect)) |
| 4.24 | A Cookbook of Self-Supervised Learning  ([:x:](https://arxiv.org/abs/2304.12210)), ([:paperclip:](https://arxiv.org/pdf/2304.12210.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12210)) |
| 4.24 | On the Challenges of Using Black-Box APIs for Toxicity Evaluation in Research ([:x:](https://arxiv.org/abs/2304.12397)), ([:paperclip:](https://arxiv.org/pdf/2304.12397.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12397)), ([:octocat:](https://github.com/for-ai/black-box-api-challenges)![GitHub Repo stars](https://img.shields.io/github/stars/for-ai/black-box-api-challenges?style=social)) |
| 4.24 | Towards Realistic Generative 3D Face Models ([:x:](https://arxiv.org/abs/2304.12483)), ([:paperclip:](https://arxiv.org/pdf/2304.12483.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12483)) |
| 4.24 | TextMesh: Generation of Realistic 3D Meshes From Text Prompts ([:x:](https://arxiv.org/abs/2304.12439)), ([:paperclip:](https://arxiv.org/pdf/2304.12439.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12439)) |
| 4.24 | Benchmarking ChatGPT-4 on ACR Radiation Oncology In-Training Exam (TXIT): Potentials and Challenges for AI-Assisted Medical Education and Decision Making in Radiation Oncology ([:x:](https://arxiv.org/abs/2304.11957)), ([:paperclip:](https://arxiv.org/pdf/2304.11957.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11957)), ([:octocat:](https://github.com/yixinghuang/chatgpt-benchmark-on-radiation-oncology)![GitHub Repo stars](https://img.shields.io/github/stars/yixinghuang/chatgpt-benchmark-on-radiation-oncology?style=social)) |
| 4.24 | Social AGI - SAMANTHA (Self-Reflective Artificial Mind Attuned to Naturalistic Thought and Human Adaptability) ([:octocat:](https://github.com/Methexis-Inc/SocialAGI)![GitHub Repo stars](https://img.shields.io/github/stars/Methexis-Inc/SocialAGI?style=social)) |
| 4.24 | Segment Anything in Medical Images ([:x:](https://arxiv.org/abs/2304.12306)), ([:paperclip:](https://arxiv.org/pdf/2304.12306.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12306)), ([:octocat:](https://github.com/bowang-lab/MedSAM)![GitHub Repo stars](https://img.shields.io/github/stars/bowang-lab/MedSAM?style=social)) |
| 4.24 | Segment Anything in 3D with NeRFs  ([:x:](https://arxiv.org/abs/2304.12308)), ([:paperclip:](https://arxiv.org/pdf/2304.12308.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12308)), ([project page](https://jumpat.github.io/SA3D/)) |
| 4.24 | WizardLM: Empowering Large Language Models to Follow Complex Instructions ([:x:](https://arxiv.org/abs/2304.12244)), ([:paperclip:](https://arxiv.org/pdf/2304.12244.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12244)) |
| 4.24 | Track Anything: Segment Anything Meets Videos ([:x:](https://arxiv.org/abs/2304.11968)), ([:paperclip:](https://arxiv.org/pdf/2304.11968.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11968)) |
| 4.24 | OpenAI Brand guidelines - ([blog](https://openai.com/brand)) |
| 4.24 | GPT4Tools: Teaching LLM to Use Tools via Self-instruction - ([Project page](https://gpt4tools.github.io/)), ([:octocat:](https://github.com/StevenGrove/GPT4Tools)), ([Video](https://www.youtube.com/watch?v=Qrj94ibQIT8)),  |
| 4.24 | RAM: Relate-Anything-Model ([:octocat:](https://github.com/Luodian/RelateAnything)![GitHub Repo stars](https://img.shields.io/github/stars/Luodian/RelateAnything?style=social)), ([Demo](https://huggingface.co/spaces/mmlab-ntu/relate-anything-model)) |
| 4.24 | [Chart-GPT 1.0](https://www.chartgpt.dev/) |
| 4.23 | Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models ([:x:](https://arxiv.org/abs/2304.11657)), ([:paperclip:](https://arxiv.org/pdf/2304.11657.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11657)), ([:octocat:](https://github.com/GasolSun36/Iter-CoT)![GitHub Repo stars](https://img.shields.io/github/stars/GasolSun36/Iter-CoT?style=social)) |
| 4.23 | Evaluating ChatGPT's Information Extraction Capabilities: An Assessment of Performance, Explainability, Calibration, and Faithfulness ([:x:](https://arxiv.org/abs/2304.11633)), ([:paperclip:](https://arxiv.org/pdf/2304.11633.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11633)) |
| 4.22 | Boosting Theory-of-Mind Performance in Large Language Models via Prompting  ([:x:](https://arxiv.org/abs/2304.11490)), ([:paperclip:](https://arxiv.org/pdf/2304.11490.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11490)) |
| 4.22 | LaMP: When Large Language Models Meet Personalization ([:x:](https://arxiv.org/abs/2304.11406)), ([:paperclip:](https://arxiv.org/pdf/2304.11406.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11406)), ([Project page](https://lamp-benchmark.github.io/index.html)), ([Download](https://lamp-benchmark.github.io/download)), ([Leaderboard](https://lamp-benchmark.github.io/leaderboard)), ([:octocat:](https://github.com/LaMP-Benchmark/LaMP)![GitHub Repo stars](https://img.shields.io/github/stars/LaMP-Benchmark/LaMP?style=social)) |
| 4.22 | Finetuning Large Language Models ([Blog](https://magazine.sebastianraschka.com/p/finetuning-large-language-models)) |
| 4.21 | Can GPT-4 Perform Neural Architecture Search? ([:x:](https://arxiv.org/abs/2304.10970)), ([:paperclip:](https://arxiv.org/pdf/2304.10970.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.10970)) |
| 4.21 | Evaluating Transformer Language Models on Arithmetic Operations Using Number Decomposition ([:x:](https://arxiv.org/abs/2304.10977)), ([:paperclip:](https://arxiv.org/pdf/2304.10977.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.10977)) |
| 4.21 | Emergent and Predictable Memorization in Large Language Models  ([:x:](https://arxiv.org/abs/2304.11158)), ([:paperclip:](https://arxiv.org/pdf/2304.11158.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11158)) |
| 4.21 | CLaMP: Contrastive Language-Music Pre-training for Cross-Modal Symbolic Music Information Retrieval  ([:x:](https://arxiv.org/abs/2304.11029)), ([:paperclip:](https://arxiv.org/pdf/2304.11029.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11029)) |
| 4.21 | Bard now helps you code with support for 20+ langs (Python, C++, JS, Go, etc.). ([Blog](https://blog.google/technology/ai/code-with-bard/)) |
| 4.21 | Inducing anxiety in large language models increases exploration and bias ([:x:](https://arxiv.org/abs/2304.11111)), ([:paperclip:](https://arxiv.org/pdf/2304.11111.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11111)) |
| 4.20 | Is ChatGPT a Good Recommender? A Preliminary Study ([:x:](https://arxiv.org/abs/2304.10149)), ([:paperclip:](https://arxiv.org/pdf/2304.10149.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.10149)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/is-chatgpt-a-good-recommender-a-preliminary)) |
| 4.20 | Why Does ChatGPT Fall Short in Answering Questions Faithfully? ([:x:](https://arxiv.org/abs/2304.10513)), ([:paperclip:](https://arxiv.org/pdf/2304.10513.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.10513)) |
| 4.20 | [FinChat.io](https://finchat.io/chats/) - The Chat GPT for Finance |
| 4.20 | LlamaAcademy: Teaching Llamas How to Code ([:octocat:](https://github.com/danielgross/LlamaAcademy)![GitHub Repo stars](https://img.shields.io/github/stars/danielgross/LlamaAcademy?style=social)) |
| 4.20 | Announcing Google DeepMind: DeepMind + Brain = Google DeepMind ([Blog](https://www.deepmind.com/blog/announcing-google-deepmind)) |
| 4.20 | "Can ChatGPT Diagnose Me?" How Large Language Models will Transform Clinical Care. Thursday, April 27th, 2023 ([RSVP](https://aimi.stanford.edu/events/can-chatgpt-diagnose-me-how-large-language-models-will-transform-clinical-care)) |
| 4.20 | StableLM: Stability AI Language Models ([:octocat:](https://github.com/stability-AI/stableLM/)![GitHub Repo stars](https://img.shields.io/github/stars/stability-AI/stableLM?style=social)), ([Blog](https://stability.ai/blog/stability-ai-launches-the-first-of-its-stablelm-suite-of-language-models)) |
| 4.19 | Fundamental Limitations of Alignment in Large Language Models ([:x:](https://arxiv.org/abs/2304.11082)), ([:paperclip:](https://arxiv.org/pdf/2304.11082.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11082)) |
| 4.19 | Scaling Transformer to 1M tokens and beyond with RMT ([:x:](https://arxiv.org/abs/2304.11062)), ([:paperclip:](https://arxiv.org/pdf/2304.11062.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11062)), ([:octocat:](https://github.com/booydar/t5-experiments/tree/scaling-report)) |
| 4.19 | Occupational Heterogeneity in Exposure to Generative AI - ([paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4414065)), ([:paperclip:](https://papers.ssrn.com/sol3/Delivery.cfm/SSRN_ID4414065_code2763040.pdf?abstractid=4414065&mirid=1)) |
| 4.19 | The Unintended Consequences of Censoring Digital Technology -- Evidence from Italy's ChatGPT Ban ([:x:](https://arxiv.org/abs/2304.09339)), ([:paperclip:](https://arxiv.org/pdf/2304.09339.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09339)) |
| 4.19 | CompressGPT: Decrease Token Usage by ~70% ([blog](https://musings.yasyf.com/compressgpt-decrease-token-usage-by-70/)) |
| 4.19 | Language Models Enable Simple Systems for Generating Structured Views of Heterogeneous Data Lakes ([:x:](https://arxiv.org/abs/2304.09433)), ([:paperclip:](https://arxiv.org/pdf/2304.09433.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09433)), ([:octocat:](https://github.com/HazyResearch/evaporate)(https://img.shields.io/github/stars/HazyResearch/evaporate?style=social)) |
| 4.19 | LLM as A Robotic Brain: Unifying Egocentric Memory and Control ([:x:](https://arxiv.org/abs/2304.09349)), ([:paperclip:](https://arxiv.org/pdf/2304.09349.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09349)) |
| 4.19 | Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agent ([:x:](https://arxiv.org/abs/2304.09542)), ([:paperclip:](https://arxiv.org/pdf/2304.09542.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09542)) |
| 4.19 | Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models ([:x:](https://arxiv.org/abs/2304.09842)), ([:paperclip:](https://arxiv.org/pdf/2304.09842.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09842)), ([project page](https://chameleon-llm.github.io/)), ([:octocat:](https://github.com/lupantech/chameleon-llm)![GitHub Repo stars](https://img.shields.io/github/stars/lupantech/chameleon-llm?style=social)) |
| 4.19 | h2oai's LLM repositories - ([h2ogpt](https://github.com/h2oai/h2ogpt)), ([h2o-llmstudio](https://github.com/h2oai/h2o-llmstudio)), ([Huggingface](https://huggingface.co/h2oai)) | 
| 4.19 | Evaluating Verifiability in Generative Search Engines ([:x:](https://arxiv.org/abs/2304.09848)), ([:paperclip:](https://arxiv.org/pdf/2304.09848.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09848)) |
| 4.19 | How to train your own Large Language Models ([Blog](https://blog.replit.com/llm-training)) |
| 4.19 | [AI Playground](https://play.vercel.ai/r/mWjP5Dt) from Vercel Labs ([tweet](https://twitter.com/vercel/status/1648451494440742917)) |
| 4.19 | StanfordBDHG HealthGPT ([tweet](https://twitter.com/varunshenoy_/status/1648374949537775616)), ([:octocat:](https://github.com/StanfordBDHG/HealthGPT)![GitHub Repo stars](https://img.shields.io/github/stars/StanfordBDHG/HealthGPT?style=social)) |
| 4.19 | GPT4All-J : the first Apache-2 Licensed Chatbot that runs locally on your machine ([:octocat:](https://github.com/nomic-ai/gpt4all)![GitHub Repo stars](https://img.shields.io/github/stars/nomic-ai/gpt4all?style=social)), ([:paperclip:](https://static.nomic.ai/gpt4all/2023_GPT4All-J_Technical_Report_2.pdf)) | 
| 4.19 | PersonalPrivate.AI - system to advise on new patent ideas ([tweet](https://twitter.com/BrianRoemmele/status/1648378237633073152)) |
| 4.18 | Computer-Vision Benchmark Segment-Anything Model (SAM) in Medical Images: Accuracy in 12 Datasets ([:x:](https://arxiv.org/abs/2304.09324)), ([:paperclip:](https://arxiv.org/pdf/2304.09324.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09324)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/accuracy-of-segment-anything-model-sam-in)) |
| 4.18 | Exploring the Trade-Offs: Unified Large Language Models vs Local Fine-Tuned Models for Highly-Specific Radiology NLI Task ([:x:](https://arxiv.org/abs/2304.09138)), ([:paperclip:](https://arxiv.org/pdf/2304.09138.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09138)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/exploring-the-trade-offs-unified-large)) |
| 4.18 | [Economist](https://www.economist.com/by-invitation/2023/04/18/the-world-needs-an-international-agency-for-artificial-intelligence-say-two-ai-experts) - The world needs an international agency for artificial intelligence, say two AI experts ([Archive](https://archive.is/jWEJ8#selection-1039.0-1039.87)) |
| 4.18 | CancerGPT: Few-shot Drug Pair Synergy Prediction using Large Pre-trained Language Models ([:x:](https://arxiv.org/abs/2304.10946)), ([:paperclip:](https://arxiv.org/pdf/2304.10946.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.10946)) |
| 4.18 | Think Before You Act: Unified Policy for Interleaving Language Reasoning with Actions ([:x:](https://arxiv.org/abs/2304.11063)), ([:paperclip:](https://arxiv.org/pdf/2304.11063.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.11063)) |
| 4.18 | Nature - [Why open-source generative AI models are an ethical way forward for science](https://www.nature.com/articles/d41586-023-01295-4) |
| 4.18 | Autonomous Agents(BabyAGI, AutoGPT) & Agent Simulations(CAMEL, Generative Agents) ([Blog](https://blog.langchain.dev/agents-round/)) |
| 4.18 | AutoTaskFormer: Searching Vision Transformers for Multi-task Learning ([:x:](https://arxiv.org/abs/2304.08756)), ([:paperclip:](https://arxiv.org/pdf/2304.08756.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08756)) |
| 4.18 | SAM Fails to Segment Anything? -- SAM-Adapter: Adapting SAM in Underperformed Scenes: Camouflage, Shadow, and More ([:x:](https://arxiv.org/abs/2304.09148)), ([:paperclip:](https://arxiv.org/pdf/2304.09148.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09148)), ([Project page](https://tianrun-chen.github.io/SAM-Adaptor/)) |
| 4.18 | Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models ([:x:](https://arxiv.org/abs/2304.08818)), ([:paperclip:](https://arxiv.org/pdf/2304.08818.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08818)), ([Project page](https://research.nvidia.com/labs/toronto-ai/VideoLDM/)) | 
| 4.18 | Google - Differentially private heatmaps ([Blog](https://ai.googleblog.com/2023/04/differentially-private-heatmaps.html)) |
| 4.18 | [The Complete Beginners Guide To Autonomous Agents](https://www.mattprd.com/p/the-complete-beginners-guide-to-autonomous-agents) |
| 4.18 | Llama Lab - A repo dedicated to building cutting-edge AGI projects: llama_agi (inspired by babyagi) and auto_llama (inspired by autogpt) ([:octocat:](https://github.com/run-llama/llama-lab)![GitHub Repo stars](https://img.shields.io/github/stars/run-llama/llama-lab?style=social)), ([Llama Hub](https://llamahub.ai/)) |
| 4.18 | Elon Musk to start ChatGPT rival called “TruthGPT” ([tweet](https://twitter.com/theLionary/status/1648088563874156545)) |
| 4.17 | MasaCtrl: Tuning-Free Mutual Self-Attention Control for Consistent Image Synthesis and Editing ([:x:](https://arxiv.org/abs/2304.08465)), ([:paperclip:](https://arxiv.org/pdf/2304.08465.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08465)), ([:house:](https://huggingface.co/papers/2304.08465)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/masactrl-tuning-free-mutual-self-attention)), ([:octocat:](https://github.com/tencentarc/masactrl)![GitHub Repo stars](https://img.shields.io/github/stars/tencentarc/masactrl?style=social)) |
| 4.17 | Notice of the Cyberspace Administration of China on Public Comments on the "Administrative Measures for Generative Artificial Intelligence Services (Draft for Comment)" ([Announcement](http://www.cac.gov.cn/2023-04/11/c_1682854275475410.htm)) |
| 4.17 | Pretrained Language Models as Visual Planners for Human Assistance ([:x:](https://arxiv.org/abs/2304.09179)), ([:paperclip:](https://arxiv.org/pdf/2304.09179.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09179)) |
| 4.17 | An Evaluation on Large Language Model Outputs: Discourse and Memorization ([:x:](https://arxiv.org/abs/2304.08637)), ([:paperclip:](https://arxiv.org/pdf/2304.08637.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08637)) |
| 4.17 | [Epic, Microsoft bring generative AI to EHRs](https://digitalhealth.modernhealthcare.com/digital-health/himss23-epic-microsoft-bring-openais-gpt-4-ehrs) - ([Microsoft announcement](Microsoft and Epic expand strategic collaboration with integration of Azure OpenAI Service)) |
| 4.17 | BenchMD: A Benchmark for Modality-Agnostic Learning on Medical Images and Sensors ([:x:](https://arxiv.org/abs/2304.08486)), ([:paperclip:](https://arxiv.org/pdf/2304.08486.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08486)) | 
| 4.17 | Towards Robust Prompts on Vision-Language Models ([:x:](https://arxiv.org/abs/2304.08479)), ([:paperclip:](https://arxiv.org/pdf/2304.08479.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08479)) | 
| 4.17 | Tool Learning with Foundation Models ([:x:](https://arxiv.org/abs/2304.08354)), ([:paperclip:](https://arxiv.org/pdf/2304.08354.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08354)), ([:octocat:](https://github.com/OpenBMB/BMTools)![GitHub Repo stars](https://img.shields.io/github/stars/OpenBMB/BMTools?style=social)) | 
| 4.17 | Low-code LLM: Visual Programming over LLMs ([:x:](https://arxiv.org/abs/2304.08103)), ([:paperclip:](https://arxiv.org/pdf/2304.08103.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08103)) |
| 4.17 | Wired - [OpenAI’s CEO Says the Age of Giant AI Models Is Already Over](https://www.wired.com/story/openai-ceo-sam-altman-the-age-of-giant-ai-models-is-already-over/) |
| 4.17 | Synthetic Data from Diffusion Models Improves ImageNet Classification ([:x:](https://arxiv.org/abs/2304.08466)), ([:paperclip:](https://arxiv.org/pdf/2304.08466.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08466)) |
| 4.17 | RedPajama-Data: An Open Source Recipe to Reproduce LLaMA training dataset ([GitHib](https://github.com/togethercomputer/RedPajama-Data)) |
| 4.17 | Visual Instruction Tuning  ([:x:](https://arxiv.org/abs/2304.08485)), ([:paperclip:](https://arxiv.org/pdf/2304.08485.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08485)), ([:octocat:](https://github.com/haotian-liu/LLaVA)![GitHub Repo stars](https://img.shields.io/github/stars/haotian-liu/LLaVA?style=social)), ([Dataset](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K)), ([Model](https://huggingface.co/liuhaotian/LLaVA-13b-delta-v0)), ([Project page](https://llava-vl.github.io/)), ([Demo](https://llava.hliu.cc/)) |
| 4.17 | Learning to Compress Prompts with Gist Tokens ([:x:](https://arxiv.org/abs/2304.08467)), ([:paperclip:](https://arxiv.org/pdf/2304.08467.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08467)) |
| 4.17 | ImpressionGPT: An Iterative Optimizing Framework for Radiology Report Summarization with ChatGPT ([:x:](https://arxiv.org/abs/2304.08448)), ([:paperclip:](https://arxiv.org/pdf/2304.08448.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08448)) |
| 4.17 | Meta - DINOv2: State-of-the-art computer vision models with self-supervised learning ([blog](https://ai.facebook.com/blog/dino-v2-computer-vision-self-supervised-learning/)), ([:octocat:](https://github.com/facebookresearch/dinov2)![GitHub Repo stars](https://img.shields.io/github/stars/facebookresearch/dinov2?style=social)), ([Demo](https://dinov2.metademolab.com/)), ([:x:](https://arxiv.org/abs/2304.07193)), ([:paperclip:](https://arxiv.org/pdf/2304.07193.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.07193)) |
| 4.17 | [TypingMind](https://www.typingmind.com/) - A better UI for ChatGPT ([tweet](https://twitter.com/tdinh_me/status/1647820035820523523)) |
| 4.16 | Understanding Large Language Models ([Blog](https://magazine.sebastianraschka.com/p/understanding-large-language-models)) |
| 4.16 | INSIGHT - an autonomous AI that can do medical research ([:octocat:](https://github.com/oneil512/INSIGHT)![GitHub Repo stars](https://img.shields.io/github/stars/oneil512/INSIGHT?style=social)) |
| 4.16 | GPT4free - use ChatGPT, for free!! - ([:octocat:](https://github.com/xtekky/gpt4free)![GitHub Repo stars](https://img.shields.io/github/stars/xtekky/gpt4free?style=social)) | 
| 4.16 | Solving Math Word Problems by Combining Language Models With Symbolic Solvers ([:x:](https://arxiv.org/abs/2304.09102)), ([:paperclip:](https://arxiv.org/pdf/2304.09102.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09102)) |
| 4.16 | ChatPLUG: Open-Domain Generative Dialogue System with Internet-Augmented Instruction Tuning for Digital Human ([:x:](https://arxiv.org/abs/2304.07849)), ([:paperclip:](https://arxiv.org/pdf/2304.07849.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.07849)) |
| 4.16 | Driving and suppressing the human language network using large language models ([bioRxiv](https://www.biorxiv.org/content/10.1101/2023.04.16.537080v1)), ([:paperclip:](https://www.biorxiv.org/content/10.1101/2023.04.16.537080v1.full.pdf)) |
| 4.16 | MultiGPT ([:octocat:](https://github.com/rumpfmax/Multi-GPT)![GitHub Repo stars](https://img.shields.io/github/stars/rumpfmax/Multi-GPT?style=social)). ([tweet](https://twitter.com/md_rumpf/status/1647911393796956162)) |
| 4.16 | OpenAssistant Conversations - Democratizing Large Language Model Alignment ([:paperclip:](https://drive.google.com/file/d/10iR5hKwFqAKhL3umx8muOWSRm7hs5FqX/view)), ([YouTube](https://www.youtube.com/watch?v=Ft9_RsKxrG4)), ([hacker news](https://news.ycombinator.com/item?id=35582417)) |
| 4.16 | Auto-evaluator - lightweight evaluation tool for question-answering using Langchain ([:octocat:](https://github.com/PineappleExpress808/auto-evaluator)![GitHub Repo stars](https://img.shields.io/github/stars/PineappleExpress808/auto-evaluator?style=social)) | 
| 4.16 | NYT - [Google Devising Radical Search Changes to Beat Back A.I. Rivals](https://www.nytimes.com/2023/04/16/technology/google-search-engine-ai.html) ([Archive](https://archive.is/ti9Ns)) |
| 4.15 | Brex's Prompt Engineering Guide ([:octocat:](https://github.com/brexhq/prompt-engineering)![GitHub Repo stars](https://img.shields.io/github/stars/brexhq/prompt-engineering?style=social)) |
| 4.15 | [Graphologue](https://twitter.com/HaijunXia/status/1646917869115166720) and [Sensecape](https://twitter.com/HaijunXia/status/1646919380704559104) by [UCSD Creativity Lab](https://creativity.ucsd.edu/ai) |
| 4.15 | Tractable Control for Autoregressive Language Generation ([:x:](https://arxiv.org/abs/2304.07438)), ([:paperclip:](https://arxiv.org/pdf/2304.07438.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.07438)) |
| 4.15 | Web LLM - language model chats directly onto web browsers ([Site](https://mlc.ai/web-llm/)), ([:octocat:](https://github.com/mlc-ai/web-llm#how)![GitHub Repo stars](https://img.shields.io/github/stars/mlc-ai/web-llm#how?style=social)) |
| 4.15 | MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models ([Project page](https://minigpt-4.github.io/)). ([Paper]()), ([:octocat:](https://github.com/Vision-CAIR/MiniGPT-4)![GitHub Repo stars](https://img.shields.io/github/stars/Vision-CAIR/MiniGPT-4?style=social)), ([YouTube](https://www.youtube.com/watch?v=__tftoxpBAw)) |
| 4.15 | OpenAssistant - The world's largest open-source replication of ChatGPT ([site](https://open-assistant.io/)), ([:octocat:](https://github.com/LAION-AI/Open-Assistant)![GitHub Repo stars](https://img.shields.io/github/stars/LAION-AI/Open-Assistant?style=social)), ([Dataset - OASST1](https://huggingface.co/datasets/OpenAssistant/oasst1)), ([Paper](https://ykilcher.com/oa-paper)), ([YouTube](https://www.youtube.com/watch?v=ddG2fM9i4Kk&feature=youtu.be)), ([Reddit](https://www.reddit.com/r/OpenAssistant/)) |
| 4.14 | MedAlpaca -- An Open-Source Collection of Medical Conversational AI Models and Training Data ([:x:](https://arxiv.org/abs/2304.08247)), ([:paperclip:](https://arxiv.org/pdf/2304.08247.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.08247)), ([:trophy:papers with code](https://paperswithcode.com/paper/medalpaca-an-open-source-collection-of)) |
| 4.14 | HuaTuo: Tuning LLaMA Model with Chinese Medical Knowledge ([:x:](https://arxiv.org/abs/2304.06975)), ([:paperclip:](https://arxiv.org/pdf/2304.06975.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06975)), ([:trophy:papers with code](https://paperswithcode.com/paper/huatuo-tuning-llama-model-with-chinese)) |
| 4.14 | ChatGPT: Applications, Opportunities, and Threats ([:x:](https://arxiv.org/abs/2304.09103)), ([:paperclip:](https://arxiv.org/pdf/2304.09103.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.09103)) |
| 4.14 | Swin3D: A Pretrained Transformer Backbone for 3D Indoor Scene Understanding ([:x:](https://arxiv.org/abs/2304.06906)), ([:paperclip:](https://arxiv.org/pdf/2304.06906.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06906)) |
| 4.14 | OpenBB Terminal V3.0.0rc2 - ([:octocat:](https://github.com/OpenBB-finance/OpenBBTerminal/releases/tag/v3.0.0rc2)![GitHub Repo stars](https://img.shields.io/github/stars/OpenBB-finance/OpenBBTerminal?style=social)) |
| 4.14 | Delta Denoising Score  ([:x:](https://arxiv.org/abs/2304.07090)), ([:paperclip:](https://arxiv.org/pdf/2304.07090.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.07090)), ([Project page](https://delta-denoising-score.github.io/)) |
| 4.14 | DINOv2: Learning Robust Visual Features without Supervision ([:x:](https://arxiv.org/abs/2304.07193)), ([:paperclip:](https://arxiv.org/pdf/2304.07193.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.07193)) |
| 4.14 | Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved With Text  ([:x:](https://arxiv.org/abs/2304.06939)), ([:paperclip:](https://arxiv.org/pdf/2304.06939.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06939)), ([:octocat:](https://github.com/allenai/mmc4)![GitHub Repo stars](https://img.shields.io/github/stars/allenai/mmc4?style=social)) |
| 4.14 | WSJ - [Elon Musk Creates New Artificial Intelligence Company X.AI](https://www.wsj.com/articles/elon-musks-new-artificial-intelligence-business-x-ai-incorporates-in-nevada-962c7c2f) ([archive](https://archive.is/qzbbb)), ([FT](https://www.ft.com/content/2a96995b-c799-4281-8b60-b235e84aefe4)) |
| 4.14 | Google Med-PaLM 2 - [A responsible path to generative AI in healthcare](https://cloud.google.com/blog/topics/healthcare-life-sciences/sharing-google-med-palm-2-medical-large-language-model?hl=en) |
| 4.14 | Meta's open source Animated Drawings - ([Blog](https://developers.facebook.com/blog/post/2023/04/13/meta-os-animated-drawings/)) |
| 4.14 | ControlNet v1.1 nightly - ([:octocat:](https://github.com/lllyasviel/ControlNet-v1-1-nightly)![GitHub Repo stars](https://img.shields.io/github/stars/lllyasviel/ControlNet-v1-1-nightly?style=social)) |
| 4.13 | Teenage-AGI ([:octocat:](https://github.com/seanpixel/Teenage-AGI)![GitHub Repo stars](https://img.shields.io/github/stars/seanpixel/Teenage-AGI?style=social)) |
| 4.13 | Boosted Prompt Ensembles for Large Language Models ([:x:](https://arxiv.org/abs/2304.05970)), ([:paperclip:](https://arxiv.org/pdf/2304.05970.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.05970)) |
| 4.13 | ChatGPT-4 Outperforms Experts and Crowd Workers in Annotating Political Twitter Messages with Zero-Shot Learning ([:x:](https://arxiv.org/abs/2304.06588)), ([:paperclip:](https://arxiv.org/pdf/2304.06588.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06588)) |
| 4.13 | Soundini: Sound-Guided Diffusion for Natural Video Editing ([:x:](https://arxiv.org/abs/2304.06818)), ([:paperclip:](https://arxiv.org/pdf/2304.06818.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06818)), ([Project page](https://kuai-lab.github.io/soundini-gallery/)) |
| 4.13 | Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study ([:x:](https://arxiv.org/abs/2304.06762)), ([:paperclip:](https://arxiv.org/pdf/2304.06762.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06762)), ([:octocat:](https://github.com/geekyutao/Inpaint-Anything)![GitHub Repo stars](https://img.shields.io/github/stars/geekyutao/Inpaint-Anything?style=social)) |
| 4.13 | Inpaint Anything: Segment Anything Meets Image Inpainting ([:x:](https://arxiv.org/abs/2304.06790)), ([:paperclip:](https://arxiv.org/pdf/2304.06790.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06790)), ([:octocat:](https://github.com/NVIDIA/Megatron-LM#retro)![GitHub Repo stars](https://img.shields.io/github/stars/NVIDIA/Megatron-LM?style=social)) |
| 4.13 | [GoalGPT](https://beta.nando.ai/goalgpt.php) by Nando.ai |
| 4.13 | Power-seeking can be probable and predictive for trained agents ([:x:](https://arxiv.org/abs/2304.06528)), ([:paperclip:](https://arxiv.org/pdf/2304.06528.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06528)) |
| 4.13 | [GoalGPT](https://beta.nando.ai/goalgpt.php) by Nando.ai |
| 4.13 | [Stable Diffusion XL Beta Available for API Customers and DreamStudio Users](https://stability.ai/blog/stable-diffusion-xl-beta-available-for-api-customers-and-dreamstudio-users) |
| 4.13 | [NAB 2023: Introducing Text-Based Editing in Premiere Pro, Properties panel in After Effects, and much more](https://blog.adobe.com/en/publish/2023/04/13/nab-2023-introducing-text-based-editing-premiere-pro-properties-panel-after-effects-more) |
| 4.13 | [Announcing New Tools for Building with Generative AI on AWS](https://aws.amazon.com/ko/blogs/machine-learning/announcing-new-tools-for-building-with-generative-ai-on-aws/) - Amazon LLM (Titan), AWS fine-tuning model (Bedrock), Amazon copilot competitor (Code whisperer) |
| 4.13 | FT - [We must slow down the race to God-like AI](https://www.ft.com/content/03895dc4-a3b7-481e-95cc-336a524f2ac2) ([archive](https://archive.is/jFfBQ#selection-1443.0-1443.41)) |
| 4.13 | Segment Everything Everywhere All at Once ([:x:](https://arxiv.org/abs/2304.06718)), ([:paperclip:](https://arxiv.org/pdf/2304.06718.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06718)) |
| 4.13 | Expressive Text-to-Image Generation with Rich Text ([:x:](https://arxiv.org/abs/2304.06720)), ([:paperclip:](https://arxiv.org/pdf/2304.06720.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06720)), ([Project page](https://rich-text-to-image.github.io/)) |
| 4.13 | AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models ([:x:](https://arxiv.org/abs/2304.06364)), ([:paperclip:](https://arxiv.org/pdf/2304.06364.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06364)), ([:octocat:](https://github.com/microsoft/AGIEval)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/AGIEval?style=social)) |
| 4.12 | Can Large Language Models Transform Computational Social Science? ([:x:](https://arxiv.org/abs/2305.03514)), ([:paperclip:](https://arxiv.org/pdf/2305.03514.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2305.03514)) | 
| 4.12 | Galactic ChitChat: Using Large Language Models to Converse with Astronomy Literature ([:x:](https://arxiv.org/abs/2304.05406)), ([:paperclip:](https://arxiv.org/pdf/2304.05406.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.05406)) | 
| 4.12 | Performance of ChatGPT, GPT-4, and Google Bard on a Neurosurgery Oral Boards Preparation Question Bank ([medRxiv](https://www.medrxiv.org/content/10.1101/2023.04.06.23288265v1)), ([:paperclip:](https://www.medrxiv.org/content/10.1101/2023.04.06.23288265v1.full.pdf)) |
| 4.12 | ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning ([:x:](https://arxiv.org/abs/2304.05613)), ([:paperclip:](https://arxiv.org/pdf/2304.05613.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.05613)) |
| 4.12 | Nature -[Foundation models for generalist medical artificial intelligence](https://www.nature.com/articles/s41586-023-05881-4) ([:paperclip:](https://www.nature.com/articles/s41586-023-05881-4.pdf)) |
| 4.12 | Dolly v2 - 12B parameter language model ([Model weight](https://huggingface.co/databricks/dolly-v2-12b)), ([:octocat:](https://github.com/databrickslabs/dolly/tree/master/data)![GitHub Repo stars](https://img.shields.io/github/stars/databrickslabs/dolly?style=social)), ([Blog](https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm)) | 
| 4.11 | Re-imagine the Negative Prompt Algorithm: Transform 2D Diffusion into 3D, alleviate Janus problem and Beyond ([:x:](https://arxiv.org/abs/2304.04968)), ([:paperclip:](https://arxiv.org/pdf/2304.04968.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.04968)), ([Project page](https://perp-neg.github.io/)), ([:octocat:](https://github.com/Perp-Neg/Perp-Neg-stablediffusion)![GitHub Repo stars](https://img.shields.io/github/stars/Perp-Neg/Perp-Neg-stablediffusion?style=social)), ([Colab](https://github.com/Perp-Neg/Perp-Neg-stablediffusion/blob/main/notebooks/demo.ipynb)), ([Hugging face](https://huggingface.co/spaces/rezaarmand/Perp-Neg)) | 
| 4.11 | Toxicity in ChatGPT: Analyzing Persona-assigned Language Models ([:x:](https://arxiv.org/abs/2304.05335)), ([:paperclip:](https://arxiv.org/pdf/2304.05335.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.05335)) | 
| 4.11 | Multi-step Jailbreaking Privacy Attacks on ChatGPT ([:x:](https://arxiv.org/abs/2304.05197)), ([:paperclip:](https://arxiv.org/pdf/2304.05197.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.05197)) | 
| 4.11 | [Building LLM applications for production](https://huyenchip.com/2023/04/11/llm-engineering.html) |
| 4.11 | Emergent autonomous scientific research capabilities of large language models ([:x:](https://arxiv.org/abs/2304.05332)), ([:paperclip:](https://arxiv.org/pdf/2304.05332.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.05332)) |
| 4.11 | [OpenAI’s Bug Bounty Program](https://openai.com/blog/bug-bounty-program) |
| 4.11 | [NTIA’s “AI Accountability Policy Request for Comment”](https://ntia.gov/issues/artificial-intelligence/request-for-comments) |
| 4.11 | WSJ - [Biden Administration Weighs Possible Rules for AI Tools Like ChatGPT](https://www.wsj.com/amp/articles/biden-administration-weighs-possible-rules-for-ai-tools-like-chatgpt-46f8257b?fbclid=IwAR1GauvAq8cuHIQQlZ8dlxiKkYuszBMPHqr_K6iZiAeTz2yCjGu9vP_S3cc), ([archive](https://archive.is/6phfS)) |
| 4.11 | ChemCrow: Augmenting large-language models with chemistry tools ([:x:](https://arxiv.org/abs/2304.05376)), ([:paperclip:](https://arxiv.org/pdf/2304.05376.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.05376)) |
| 4.11 | [LangChainJS Support for Multiple JS Environments](https://blog.langchain.dev/js-envs/) ([tweet](https://twitter.com/LangChainAI/status/1645831073358815232)) |
| 4.11 | Teaching Large Language Models to Self-Debug ([:x:](https://arxiv.org/abs/2304.05128)), ([:paperclip:](https://arxiv.org/pdf/2304.05128.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.05128)) |
| 4.10 | Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models ([Paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4412788)), ([:paperclip:](https://papers.ssrn.com/sol3/Delivery.cfm/SSRN_ID4429709_code2675263.pdf?abstractid=4412788&mirid=1)) |
| 4.10 | On the Possibilities of AI-Generated Text Detection ([:x:](https://arxiv.org/abs/2304.04736)), ([:paperclip:](https://arxiv.org/pdf/2304.04736.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.04736)) |
| 4.10 | OpenAGI: When LLM Meets Domain Experts ([:x:](https://arxiv.org/abs/2304.04370)), ([:paperclip:](https://arxiv.org/pdf/2304.04370.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.04370)), ([:octocat:](https://github.com/agiresearch/OpenAGI)![GitHub Repo stars](https://img.shields.io/github/stars/agiresearch/OpenAGI?style=social)) |
| 4.9 | ChatAll - oncurrently chat with ChatGPT, Bing Chat, bard, Alpaca, Vincuna, Claude, ChatGLM, MOSS, iFlytek Spark, ERNIE and more, discover the best answers ([:octocat:](https://github.com/sunner/ChatALL)![GitHub Repo stars](https://img.shields.io/github/stars/sunner/ChatALL?style=social)) |
| 4.9 | BabyAGI JS - ([:octocat:](https://github.com/ericciarla/babyagijs)![GitHub Repo stars](https://img.shields.io/github/stars/ericciarla/babyagijs?style=social)) |
| 4.9 | AgentGPT - Auto-GPT directly in the browser ([tweet](https://twitter.com/asimdotshrestha/status/1644883727707959296)), ([:octocat:](https://github.com/reworkd/AgentGPT)![GitHub Repo stars](https://img.shields.io/github/stars/reworkd/AgentGPT?style=social)), ([demo](https://agentgpt.reworkd.ai/)) |
| 4.8 | [A Recipe for Training Large Models](https://wandb.ai/craiyon/report/reports/Recipe-Training-Large-Models--VmlldzozNjc4MzQz) |
| 4.7 | [SuperPrompt Engineer Encourages ChatGPT Hallucinations](https://metanews.com/superprompt-engineer-encourages-chatgpt-hallucinations/) |
| 4.7 | Cerebras-GPT: Open Compute-Optimal Language Models Trained on the Cerebras Wafer-Scale Cluster ([:x:](https://arxiv.org/abs/2304.03208)), ([:paperclip:](https://arxiv.org/pdf/2304.03208.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.03208)) |
| 4.7 | Why think step-by-step? Reasoning emerges from the locality of experience ([:x:](https://arxiv.org/abs/2304.03843)), ([:paperclip:](https://arxiv.org/pdf/2304.03843.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.03843)) |
| 4.7 | Generative Agents: Interactive Simulacra of Human Behavior ([:x:](https://arxiv.org/abs/2304.03442)), ([:paperclip:](https://arxiv.org/pdf/2304.03442.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.03442)), ([Project](https://reverie.herokuapp.com/arXiv_Demo/)) | 
| 4.7 | Vicuna-7B: small, efficient, yet capable ([:octocat:](https://github.com/lm-sys/FastChat)![GitHub Repo stars](https://img.shields.io/github/stars/lm-sys/FastChat?style=social)), ([Weight](https://huggingface.co/lmsys/vicuna-7b-delta-v0)) |
| 4.7 | StackLlama ([Blog](https://huggingface.co/blog/stackllama)), ([Demo](https://huggingface.co/spaces/trl-lib/stack-llama)), ([:octocat:](https://github.com/lvwerra/trl/tree/main/examples/stack_llama/scripts)![GitHub Repo stars](https://img.shields.io/github/stars/lvwerra/trl?style=social)) |
| 4.7 | SegGPT: Segmenting Everything In Context ([:x:](https://arxiv.org/abs/2304.03284)), ([:paperclip:](https://arxiv.org/pdf/2304.03284.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.03284)), ([:octocat:](https://github.com/baaivision/Painter)![GitHub Repo stars](https://img.shields.io/github/stars/baaivision/Painter?style=social)), ([Demo](https://huggingface.co/spaces/BAAI/SegGPT)) |
| 4.6 | Synthetic Data in Healthcare ([:x:](https://arxiv.org/abs/2304.03243)), ([:paperclip:](https://arxiv.org/pdf/2304.03243.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.03243)), ([:house:](https://huggingface.co/papers/2304.03243)), ([:eight_spoked_asterisk:]()) |
| 4.6 | Chrome ships WebGPU ([Blog](https://developer.chrome.com/blog/webgpu-release/)) |
| 4.6 | GPT detectors are biased against non-native English writers ([:x:](https://arxiv.org/abs/2304.02819)), ([:paperclip:](https://arxiv.org/pdf/2304.02819.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/02819.03411)) |
| 4.6 | ChaosGPT: Empowering GPT with Internet and Memory to Destroy Humanity ([YouTube](https://www.youtube.com/watch?v=g7YJIpkk7KM&t=912s)) |
| 4.6 | InstantBooth: Personalized Text-to-Image Generation without Test-Time Finetuning ([:x:](https://arxiv.org/abs/2304.03411)), ([:paperclip:](https://arxiv.org/pdf/2304.03411.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.03411)), ([Project](https://jshi31.github.io/InstantBooth/)) | 
| 4.6 | Wired - [AI Desperately Needs Global Oversight](https://www.wired.com/story/ai-desperately-needs-global-oversight/) |
| 4.6 | Instruction Tuning with GPT-4 ([:x:](https://arxiv.org/abs/2304.03277)), ([:paperclip:](https://arxiv.org/pdf/2304.03277.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.03277)), ([:octocat:](https://instruction-tuning-with-gpt-4.github.io/)) |
| 4.6 | GeNVS: Generative Novel View Synthesis with 3D-Aware Diffusion Models ([:x:](https://arxiv.org/abs/2304.02602)), ([:paperclip:](https://arxiv.org/pdf/2304.02602.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.02602)), ([:octocat:](https://nvlabs.github.io/genvs/)) |
| 4.6 | Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark ([:x:](https://arxiv.org/abs/2304.03279)), ([:paperclip:](https://arxiv.org/pdf/2304.03279.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.03279)) |
| 4.5 | Yoshua Bengio - [Slowing down development of AI systems passing the Turing test](https://yoshuabengio.org/2023/04/05/slowing-down-development-of-ai-systems-passing-the-turing-test/) | 
| 4.5 | Language models are on Replicate - FLAN-T5, GPT-J, and LLaMA ([Blog](https://replicate.com/blog/language-models)) |
| 4.5 | [Meta's  Segment Anything Model (SAM)](https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/?utm_source=twitter&utm_medium=organic_social&utm_campaign=segmentanything&utm_content=gif) ([Paper](https://ai.facebook.com/research/publications/segment-anything/)), ([:paperclip:](https://scontent-ssn1-1.xx.fbcdn.net/v/t39.2365-6/10000000_6331779526880473_6748528980292947838_n.pdf?_nc_cat=102&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=lnYqcLNTtLQAX80UVfV&_nc_ht=scontent-ssn1-1.xx&oh=00_AfAAtzQrBx242Tl4miOfzWrYrJAhLw3VCm1FeWuMs319zw&oe=6432ACEA)), ([:octocat:](https://github.com/facebookresearch/segment-anything)![GitHub Repo stars](https://img.shields.io/github/stars/facebookresearch/segment-anything?style=social)), ([Demo](https://segment-anything.com/)), ([:x:](https://arxiv.org/abs/2304.02643)), ([:paperclip:](https://arxiv.org/pdf/2304.02643.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.02643)) | 
| 4.4 | Leveraging GPT-4 for Post Hoc Transformation of Free-text Radiology Reports into Structured Reporting: A Multilingual Feasibility Study (RSNA Radiology, [https://doi.org/10.1148/radiol.230725](https://pubs.rsna.org/doi/10.1148/radiol.230725)) |
| 4.4 | Calibrated Chaos: Variance Between Runs of Neural Network Training is Harmless and Inevitable ([:x:](https://arxiv.org/abs/2304.01910)), ([:paperclip:](https://arxiv.org/pdf/2304.01910.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.01910)) |
| 4.4 | One Small Step for Generative AI, One Giant Leap for AGI: A Complete Survey on ChatGPT in AIGC Era ([:x:](https://arxiv.org/abs/2304.06488)), ([:paperclip:](https://arxiv.org/pdf/2304.06488.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06488)) |
| 4.4 | [LangCahin raised $10 million in seed funding](https://blog.langchain.dev/announcing-our-10m-seed-round-led-by-benchmark/) |
| 4.4 | Kandinsky 2.1 ([:octocat:](https://github.com/ai-forever/Kandinsky-2)![GitHub Repo stars](https://img.shields.io/github/stars/ai-forever/Kandinsky-2?style=social)), ([HuggingFace](https://huggingface.co/ai-forever/Kandinsky_2.1)) |
| 4.4 | The weights of Vicuna-13B released ([WebUI demo](https://chat.lmsys.org/)) ([:octocat:](https://github.com/lm-sys/FastChat/#vicuna-weights)![GitHub Repo stars](https://img.shields.io/github/stars/lm-sys/FastChat?style=social)) |
| 4.4 | LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models ([:x:](https://arxiv.org/abs/2304.01933)), ([:paperclip:](https://arxiv.org/pdf/2304.01933.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.01933)), ([:octocat:](https://github.com/AGI-Edgerunners/LLM-Adapters)![GitHub Repo stars](https://img.shields.io/github/stars/AGI-Edgerunners/LLM-Adapters?style=social)) |
| 4.4 | Summary of ChatGPT/GPT-4 Research and Perspective Towards the Future of Large Language Models ([:x:](https://arxiv.org/abs/2304.01852)), ([:paperclip:](https://arxiv.org/pdf/2304.01852.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.01852)) |
| 4.3 | Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling ([:x:](https://arxiv.org/abs/2304.01373)), ([:paperclip:](https://arxiv.org/pdf/2304.01373.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.01373)) |
| 4.3 | Vicuna-13B: An Open-Source ChatGPT Alternative That Impresses GPT-4 ([Blog](https://docs.kanaries.net/articles/vicuna-chatgpt-alternative)), ([:octocat:](https://github.com/lm-sys/FastChat)![GitHub Repo stars](https://img.shields.io/github/stars/lm-sys/FastChat?style=social)) |
| 4.3 | Baby AGI ([:octocat:](https://github.com/yoheinakajima/babyagi)![GitHub Repo stars](https://img.shields.io/github/stars/yoheinakajima/babyagi?style=social)) |
| 4.3 | [Berkley just released Koala-13B!](https://bair.berkeley.edu/blog/2023/04/03/koala/) ([Demo](https://chat.lmsys.org/?model=koala-13b)) |
| 4.3 | [2023 Artificial Intelligence (AI) Index Report](https://aiindex.stanford.edu/report/) Published by Stanford Institute for Human-Centered Artificial Intelligence (HAI) |
| 4.3 | The LLM playground - open source ([:octocat:](https://github.com/nat/openplayground)) |
| 4.3 | Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data ([:x:](https://arxiv.org/abs/2304.01196)), ([:paperclip:](https://arxiv.org/pdf/2304.01196.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.01196)), ([:octocat:](https://github.com/project-baize/baize)![GitHub Repo stars](https://img.shields.io/github/stars/project-baize/baize?style=social)) |
| 4.2 | GPTCache : A Library for Creating Semantic Cache for LLM Queries - ([:octocat:]()) |
| 4.2 | Better Language Models of Code through Self-Improvement ([:x:](https://arxiv.org/abs/2304.01228)), ([:paperclip:](https://arxiv.org/pdf/2304.01228.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.01228)) |
| 4.2 | Eight Things to Know about Large Language Models ([:x:](https://arxiv.org/abs/2304.00612)), ([:paperclip:](https://arxiv.org/pdf/2304.00612.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.00612)) |
| 4.2 | LLMMaps -- A Visual Metaphor for Stratified Evaluation of Large Language Models ([:x:](https://arxiv.org/abs/2304.00457)), ([:paperclip:](https://arxiv.org/pdf/2304.00457.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.00457)) |
| 4.1 | Evaluating Large Language Models on a Highly-specialized Topic, Radiation Oncology Physics ([:x:](https://arxiv.org/abs/2304.01938)),  ([:paperclip:](https://arxiv.org/pdf/2304.01938.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.01938)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/evaluating-large-language-models-on-a-highly))	|
| 4.1 | [Italy curbs ChatGPT, starts probe over privacy concerns](https://www.cnbc.com/2023/04/01/italy-curbs-chatgpt-starts-probe-over-privacy-concerns.html) |
| 3.31 | Evaluating GPT-4 and ChatGPT on Japanese Medical Licensing Examinations ([:x:](https://arxiv.org/abs/2303.18027)), ([:paperclip:](https://arxiv.org/pdf/2303.18027.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.18027)), ([:house:](https://huggingface.co/papers/2303.18027)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/evaluating-gpt-4-and-chatgpt-on-japanese)), ([:octocat:](https://github.com/jungokasai/igakuqa)![GitHub Repo stars](https://img.shields.io/github/stars/jungokasai/igakuqa?style=social))  |
| 3.31 | Choose Your Weapon: Survival Strategies for Depressed AI Academics ([:x:](https://arxiv.org/abs/2304.06035)), ([:paperclip:](https://arxiv.org/pdf/2304.06035.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06035)) |
| 3.31 | CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society ([:x:](https://arxiv.org/abs/2303.17760)), ([:paperclip:](https://arxiv.org/pdf/2303.17760.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.17760)), ([:octocat:](https://github.com/lightaime/camel))![GitHub Repo stars](https://img.shields.io/github/stars/lightaime/camel?style=social) |
| 3.31 | A Survey of Large Language Models - Version 1 ([:x:](https://arxiv.org/abs/2303.18223v1)), ([:paperclip:](https://arxiv.org/pdf/2303.18223v1.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.18223v1)) |
| 3.31 | (SCIENTIFIC AMERICAN) [AI Chatbots Can Diagnose Medical Conditions at Home. How Good Are They?](https://www.scientificamerican.com/article/ai-chatbots-can-diagnose-medical-conditions-at-home-how-good-are-they/) |
| 3.30 | ChatGPT in Healthcare: A Taxonomy and Systematic Review ([medRxiv](https://www.medrxiv.org/content/10.1101/2023.03.30.23287899v1.full)), ([:paperclip:](https://www.medrxiv.org/content/10.1101/2023.03.30.23287899v1.full.pdf)) |
| 3.30 | Launching the Generative AI Open Source (GenOS) Index - ([Index](https://www.decibel.vc/articles/launching-the-generative-ai-open-source-genos-index)), ([Tweet](https://twitter.com/chakrabartis/status/1641447121042964482)) |
| 3.30 | Whose Opinions Do Language Models Reflect? ([:x:](https://arxiv.org/abs/2303.17548)), ([:paperclip:](https://arxiv.org/pdf/2303.17548.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.17548)), ([:octocat:](https://github.com/tatsu-lab/opinions_qa)![GitHub Repo stars](https://img.shields.io/github/stars/tatsu-lab/opinions_qa?style=social)) |
| 3.30 | Language Models can Solve Computer Tasks ([:x:](https://arxiv.org/abs/2303.17491)), ([:paperclip:](https://arxiv.org/pdf/2303.17491.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.17491)) |
| 3.30 | Self-Refine: Iterative Refinement with Self-Feedback ([:x:](https://arxiv.org/abs/2303.17651)), ([:paperclip:](https://arxiv.org/pdf/2303.17651.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.17651)) |
| 3.30 | Humans in Humans Out: On GPT Converging Toward Common Sense in both Success and Failure ([:x:](https://arxiv.org/abs/2303.17276)), ([:paperclip:](https://arxiv.org/pdf/2303.17276.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.17276)) |
| 3.30 | [List of Open Sourced Fine-Tuned Large Language Models (LLM)](https://medium.com/geekculture/list-of-open-sourced-fine-tuned-large-language-models-llm-8d95a2e0dc76) |
| 3.30 | [NEJM - Benefits, Limits, and Risks of GPT-4 as an AI Chatbot for Medicine](https://www.nejm.org/doi/pdf/10.1056/NEJMsr2214184) |
| 3.30 | BloombergGPT: A Large Language Model for Finance ([:x:](https://arxiv.org/abs/2303.17564)), ([:paperclip:](https://arxiv.org/pdf/2303.17564.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.17564)) |
| 3.30 | [Got It AI’s ELMAR challenges GPT-4 and LLaMa, scores well on hallucination benchmarks](https://venturebeat.com/ai/got-it-ai-elmar-challenges-gpt-4-and-llama) |
| 3.30 | HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace ([:x:](https://arxiv.org/abs/2303.17580)), ([:paperclip:](https://arxiv.org/pdf/2303.17580.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.17580)) |
| 3.30 | [CAIDP claims "The FTC should investigate OpenAI and block GPT over ‘deceptive’ behavior"](https://edition.cnn.com/2023/03/30/tech/ftc-openai-gpt-ai-think-tank/index.html) |
| 3.30 | [Epic to use Microsoft's GPT-4 in EHRs](https://www.beckershospitalreview.com/ehrs/epic-to-use-microsofts-open-ai-in-ehrs.html) |
| 3.30 | Auto-GPT: An Autonomous GPT-4 Experiment ([:octocat:](https://github.com/Torantulino/Auto-GPT)![GitHub Repo stars](https://img.shields.io/github/stars/Torantulino/Auto-GPT?style=social)) |
| 3.29 | AnnoLLM: Making Large Language Models to Be Better Crowdsourced Annotators ([:x:](https://arxiv.org/abs/2303.16854)), ([:paperclip:](https://arxiv.org/pdf/2303.16854.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.16854)) |
| 3.29 | [nucleotide transformers - genomics LLM, ranging from 500M to 2.5B parameters](https://twitter.com/instadeepai/status/1641075963051012097) - ([:octocat:](https://github.com/instadeepai/nucleotide-transformer)![GitHub Repo stars](https://img.shields.io/github/stars/nucleotide-transformer?style=social)) |
| 3.29 | [GeoV-9b - 9 billion parameter causal language model](https://twitter.com/labmlai/status/1641357802009395201) ([code](https://github.com/geov-ai/geov), [weights](https://huggingface.co/GeoV/GeoV-9b), [colab](https://colab.research.google.com/github/geov-ai/geov/blob/master/notebooks/generate.ipynb)) |
|	3.29	|	[GPT4All - 7B param language model finetuned from a curated set of 400k GPT-Turbo-3.5](https://twitter.com/andriy_mulyar/status/1640836003194630144)  	|
|	3.29	|	[LLaMA-Adapter!: Efficient Fine-tuning of Language Models with Zero-init Attention](https://twitter.com/lupantech/status/1640899600281395200)	|
|	3.29	|	[MacGPT 3.2](https://www.macgpt.com/)	|
| 3.29 | GPTEval: NLG Evaluation using GPT-4 with Better Human Alignment ([:x:](https://arxiv.org/abs/2303.16634)), ([:paperclip:](https://arxiv.org/pdf/2303.16634.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.16634)) |
| 3.29 | TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs  ([:x:](https://arxiv.org/abs/2303.16434)), ([:paperclip:](https://arxiv.org/pdf/2303.16434.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.16434)) |
| 3.28 | Natural Selection Favors AIs over Humans [:x:](https://arxiv.org/abs/2303.16200)), ([:paperclip:](https://arxiv.org/pdf/2303.16200.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.16200)) |
| 3.28 | ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks ([:x:](https://arxiv.org/abs/2303.15056)), ([:paperclip:](https://arxiv.org/pdf/2303.15056.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.15056)) |
|	3.28	|	[LLaMA voice chat + Siri TTS](https://twitter.com/ggerganov/status/1640416314773700608)	|
|	3.28	|	[Cerebras-GPT - 111M to 13B parameters trained using the Chinchilla formula](https://twitter.com/CerebrasSystems/status/1640725880711569408)	|
|	3.28	|	[Microsoft Security Copilot: Empowering defenders at the speed of AI](https://blogs.microsoft.com/blog/2023/03/28/introducing-microsoft-security-copilot-empowering-defenders-at-the-speed-of-ai/)	|
| 3.28 | [Google pix2struct launched today, a multimodal model specializing in screenshot data](https://twitter.com/danielgross/status/1640515851014004737) |
|	3.28	|	[OpenFlamingo - a framework that enables training and evaluation of large multimodal models (LMMs)](https://laion.ai/blog/open-flamingo/)	|
| 3.27 | Microsoft JARVIS ([:octocat:](https://github.com/microsoft/JARVIS)![GitHub Repo stars](https://img.shields.io/github/stars/microsoft/JARVIS?style=social)) |
| 3.27 | [ChatGPT Survey: Performance on NLP datasets](http://opensamizdat.com/posts/chatgpt_survey/) |
| 3.27 | GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models ([:x:](https://arxiv.org/abs/2303.10130)), ([:paperclip:](https://arxiv.org/pdf/2303.10130.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.10130)) |
| 3.26 | AI-Generated Content (AIGC): A Survey ([:x:](https://arxiv.org/abs/2304.06632)), ([:paperclip:](https://arxiv.org/pdf/2304.06632.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.06632)), ([:house:](https://huggingface.co/papers/2304.06632)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/ai-generated-content-aigc-a-survey) |
| 3.26 | Nature Language Reasoning, A Survey ([:x:](https://arxiv.org/abs/2303.14725)), ([:paperclip:](https://arxiv.org/pdf/2303.14725.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.14725)) |
|	3.26	|	[Sam Altman: OpenAI CEO on GPT-4, ChatGPT, and the Future of AI - Lex Fridman Podcast #367](https://www.youtube.com/watch?v=L_Guz73e6fw)	|
|	3.26	|	[LLaMA voice chat](https://twitter.com/ggerganov/status/1640022482307502085)	|
|	3.26	|	[Japanese Alpaca LoRA](https://twitter.com/kun1em0n/status/1639965140429963264)	|
| 3.24 | LLM for Patient-Trial Matching: Privacy-Aware Data Augmentation Towards Better Performance and Generalizability ([:x:](https://arxiv.org/abs/2303.16756)),  ([:paperclip:](https://arxiv.org/pdf/2303.16756.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.16756)), ([:house:](https://huggingface.co/papers/2303.16756)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/llm-for-patient-trial-matching-privacy-aware)) |
| 3.24 | Progressively Optimized Local Radiance Fields for Robust View Synthesis ([:x:](https://arxiv.org/abs/2303.13791)),  ([:paperclip:](https://arxiv.org/pdf/2303.13791.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.13791)), ([:house:](https://huggingface.co/papers/2303.13791)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/progressively-optimized-local-radiance-fields)), (CVPR 2023)	|
| 3.24 | Efficient Methods for Natural Language Processing: A Survey ([:x:](https://arxiv.org/abs/2209.00099)),  ([:paperclip:](https://arxiv.org/pdf/2209.00099.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2209.00099)) |
|	3.24	|	[NYT OPINION - You Can Have the Blue Pill or the Red Pill, and We’re Out of Blue Pills](https://www.nytimes.com/2023/03/24/opinion/yuval-harari-ai-chatgpt.html)	([archive](https://archive.is/AUKPm)) |
|	3.24	|	[Dolly - open source LLM](https://twitter.com/databricks/status/1639239800145465344) 	|
|	3.24	|	[Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators](https://twitter.com/_akhaliq/status/1639062868850266112)	|
|	3.24	|	ChatDoctor: A Medical Chat Model Fine-tuned on LLaMA Model using Medical Domain Knowledge ([:x:](https://arxiv.org/abs/2303.14070v1)),  ([:paperclip:](https://arxiv.org/pdf/2303.14070v1.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.14070v1)), ([:octocat:](https://github.com/Kent0n-Li/ChatDoctor)![GitHub Repo stars](https://img.shields.io/github/stars/Kent0n-Li/ChatDoctor?style=social))	|
| 3.24 | Do large language models need sensory grounding for meaning and understanding? @YannLeCun |
|	3.23	|	[OpenAI: ChatGPT Plugins](https://openai.com/blog/chatgpt-plugins)	|
|	3.23	|	[Opera brings AI ChatGPT bot sidebar to browsers](https://www.deccanherald.com/business/technology/opera-brings-ai-chatgpt-bot-sidebar-to-browsers-1202781.html)	|
| 3.22 | Artificial muses: Generative Artificial Intelligence Chatbots Have Risen to Human-Level Creativity ([:x:](https://arxiv.org/abs/2303.12003)), ([:paperclip:](https://arxiv.org/pdf/2303.12003.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.12003)), ([:house:](https://huggingface.co/papers/2303.12003)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/sparks-of-artificial-general-intelligence)) |	
|	3.22	|	[GitHub: Copilot X](https://github.blog/2023-03-22-github-copilot-x-the-ai-powered-developer-experience)	|
|	3.22	|	Sparks of Artificial General Intelligence: Early experiments with GPT-4 ([:x:](https://arxiv.org/abs/2303.12712)), ([:paperclip:](https://arxiv.org/pdf/2303.12712.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.12712)), ([YouTube](https://www.youtube.com/watch?v=qbIk7-JPB2c)) |
|	3.22	|	[Pause Giant AI Experiments: An Open Letter](https://futureoflife.org/open-letter/pause-giant-ai-experiments/)	|
| 3.21 | WSJ - [Generative AI Makes Headway in Healthcare](https://www.wsj.com/articles/generative-ai-makes-headway-in-healthcare-cb5d4ee2) |
|	3.21	|	[NVIDIA Brings Generative AI to World’s Enterprises](https://nvidianews.nvidia.com/news/nvidia-brings-generative-ai-to-worlds-enterprises-with-cloud-services-for-creating-large-language-and-visual-models)	|
|	3.21	|	[Adobe launches Firefly](https://www.cnbc.com/2023/03/21/adobe-firefly-generative-ai-lets-you-type-to-edit-images.html)	|
|	3.21	|	[Google launches Bard in the US and UK](https://blog.google/technology/ai/try-bard)	|
|	3.21	|	[Microsoft: Bing Image Creator](https://blogs.microsoft.com/blog/2023/03/21/create-images-with-your-words-bing-image-creator-comes-to-the-new-bing)	|
|	3.21	|	[Stability AI Launches Stable Diffusion Reimagine](https://stability.ai/blog/stable-diffusion-reimagine)	|
| 3.20 | Reflexion: an autonomous agent with dynamic memory and self-reflection ([:x:](https://arxiv.org/abs/2303.11366)), ([:paperclip:](https://arxiv.org/pdf/2303.11366.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.11366)), ([:octocat:](https://github.com/noahshinn024/reflexion)![GitHub Repo stars](https://img.shields.io/github/stars/noahshinn024/reflexion?style=social)) |
|	3.20	|	[March 20 ChatGPT outage: Here’s what happened](https://openai.com/blog/march-20-chatgpt-outage)	|
|	3.20	|	[Runway Gen-2](https://research.runwayml.com/gen2)	|
|	3.20	|	[Paper: Capabilities of GPT-4 on Medical Challenge Problems](https://arxiv.org/abs/2303.13375)	|
| 3.20 | [Making Music with GPT 4](https://www.youtube.com/watch?v=Cvl30rn03Hg) by [(Wavtool)](https://wavtool.com/) |
| 3.19 | Simple LLM Finetuner ([:octocat:](https://github.com/lxe/simple-llm-finetuner)![GitHub Repo stars](https://img.shields.io/github/stars/lxe/simple-llm-finetuner?style=social)) |
| 3.18 | Data-centric Artificial Intelligence: A Survey ([:x:](https://arxiv.org/abs/2303.10158)), ([:paperclip:](https://arxiv.org/pdf/2303.10158.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.10158)), ([:octocat:](https://github.com/daochenzha/data-centric-AI)![GitHub Repo stars](https://img.shields.io/github/stars/data-centric-AI?style=social)) |
| 3.17 | Can AI-Generated Text be Reliably Detected? ([:x:](https://arxiv.org/abs/2303.11156)), ([:paperclip:](https://arxiv.org/pdf/2303.11156.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.11156)) |
| 3.17 | GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models  ([:x:](https://arxiv.org/abs/2303.10130)), ([:paperclip:](https://arxiv.org/pdf/2303.10130.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.10130)) |
| 3.16 | WebSHAP: Towards Explaining Any Machine Learning Models Anywhere ([:x:](https://arxiv.org/abs/2303.09545)), ([:paperclip:](https://arxiv.org/pdf/2303.09545.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.09545)), ([:octocat:](https://poloclub.github.io/webshap/)) |
| 3.16 | LERF: Language Embedded Radiance Fields ([:x:](https://arxiv.org/abs/2303.09553)), ([:paperclip:](https://arxiv.org/pdf/2303.09553.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.09553)), ([:octocat:](https://www.lerf.io/)) |
|	3.16	|	[Microsoft: Microsoft 365 Copilot](https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work)	|
|	3.16	|	[Alpaca LoRA: instruct tune LLAMA on consumer hardware](https://twitter.com/_akhaliq/status/1636416647518097408)	|
|	3.16	|	[OpenAI CEO Sam Altman says AI will reshape society, acknowledges risks: 'A little bit scared of this'](https://abcnews.go.com/Technology/openai-ceo-sam-altman-ai-reshape-society-acknowledges/story?id=97897122)	|
|	3.15	|	[A new era for AI and Google Workspace](https://workspace.google.com/blog/product-announcements/generative-ai?hl=en)	|
|	3.15	|	[PyTorch 2.0: Our next generation release](https://pytorch.org/blog/pytorch-2.0-release/)	|
|	3.15	|	[Baidu: ERNIE Bot](https://www.youtube.com/watch?v=ukvEUI3x0vI)	|
|	3.15	|	[Midjourney: Midjourney V5](https://twitter.com/midjourney/status/1636130389365497857)	|
|	3.15	|	[arXiv - GPT-4 Technical report](https://arxiv.org/abs/2303.08774)	|
| 3.14 | Text-to-image Diffusion Models in Generative AI: A Survey ([:x:](https://arxiv.org/abs/2303.07909)), ([:paperclip:](https://arxiv.org/pdf/2303.07909.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.07909)), ([:house:](https://huggingface.co/papers/2303.07909)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/text-to-image-diffusion-model-in-generative)) |
| 3.14 | The Lancet - [Attention is not all you need: the complicated case of ethically using large language models in healthcare and medicine](https://www.thelancet.com/journals/ebiom/article/PIIS2352-3964(23)00077-4/fulltext) |
|	3.14	|	THUDM releases ChatGLM-6B	|
| 3.14 | Langflow - a UI for LangChain ([:octocat:](https://github.com/logspace-ai/langflow)![GitHub Repo stars](https://img.shields.io/github/stars/logspace-ai/langflow?style=social)) |
|	3.14	|	[Anthropic: Claude](https://www.anthropic.com/index/introducing-claude)	|
|	3.14	|	[Google: PaLM API & Workspace](https://blog.google/technology/ai/ai-developers-google-cloud-workspace)	|
|	3.14	|	[OpenAI: GPT-4](https://openai.com/research/gpt-4)	|
|	3.13	|	[Stanford Alpaca 7B](https://crfm.stanford.edu/2023/03/13/alpaca.html)	|
|	3.13	|	[Microsoft lays off team that taught employees how to make AI tools responsibly](https://www.theverge.com/2023/3/13/23638823/microsoft-ethics-society-team-responsible-ai-layoffs)	|
|	3.13	|	[MiniLLM: Large Language Models on Consumer GPUs](https://github.com/kuleshov/minillm)	|
| 3.13 | Chatbot UI ([:octocat:](https://github.com/mckaywrigley/chatbot-ui)(https://img.shields.io/github/stars/mckaywrigley/chatbot-ui?style=social)) |
|	3.12	|	[GM explores using ChatGPT in vehicles](https://europe.autonews.com/automakers/gm-explores-using-chatgpt-vehicles)	|
|	3.10	|	[Google: PaLM-E](https://ai.googleblog.com/2023/03/palm-e-embodied-multimodal-language.html)	|
|	3.9	|	[multi-model playground - https://nat.dev](https://nat.dev/)	|
|	3.9	|	[GPT-4 is coming next week](https://www.heise.de/news/GPT-4-is-coming-next-week-and-it-will-be-multimodal-says-Microsoft-Germany-7540972.html)	|
| 3.8 | Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models ([:x:](https://arxiv.org/abs/2303.04671)), ([:paperclip:](https://arxiv.org/pdf/2303.04671.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.04671)) |
|	3.8	|	[NYT, Opinion - Noam Chomsky: The False Promise of ChatGPT](https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html)	([archive](https://archive.is/qvR3Q))|
| 3.7 | A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT ([:x:](https://arxiv.org/abs/2303.04226)), ([:paperclip:](https://arxiv.org/pdf/2303.04226.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.04226)) |
| 3.7 | Radiology - [The Role and Limitations of Large Language Models Such as ChatGPT in Clinical Settings and Medical Journalism](https://pubs.rsna.org/doi/10.1148/radiol.230276) |
|	3.7	|	[Stability AI Acquires Image Editing App Clipdrop](https://stability.ai/blog/stability-ai-acquires-init-ml-makers-of-clipdrop-application)	|
|	3.6	|	[Google: Universal Speech Model](https://ai.googleblog.com/2023/03/universal-speech-model-usm-state-of-art.html)	|
|	3.5	|	[Generative AI: Perspectives from Stanford HAI](https://hai.stanford.edu/generative-ai-perspectives-stanford-hai)	|
|	3.5	|	[UpStage, ChatGPT bot (Askup) on Line](https://github.com/hunkim/line-gpt)	|
|	3.5	|	[UpStage, ChatGPT bot (Askup) on KakaoTalk](https://github.com/hunkim/kakao-gpt)	|
| 3.2 | Consistency Models  ([:x:](https://arxiv.org/abs/2303.01469)), ([:paperclip:](https://arxiv.org/pdf/2303.01469.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.01469)), ([:octocat:](https://github.com/openai/consistency_models)![GitHub Repo stars](https://img.shields.io/github/stars/openai/consistency_models?style=social)) |
| 3.1 | Almanac: Retrieval-Augmented Language Models for Clinical Medicine ([:x:](https://arxiv.org/abs/2303.01229)), ([:paperclip:](https://arxiv.org/pdf/2303.01229.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.01229)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/almanac-knowledge-grounded-language-models)) |
|	3.1	|	[OpenAI: ChatGPT and Whisper API](https://openai.com/blog/introducing-chatgpt-and-whisper-apis)	|
| 2.28 | Large Language Models Are State-of-the-Art Evaluators of Translation Quality ([:x:](https://arxiv.org/abs/2302.14520)), ([:paperclip:](https://arxiv.org/pdf/2302.14520.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2302.14520)) |
| 2.27 | Best Practices for Using AI When Writing Scientific Manuscripts ([ACS Nano 2023, 17, 5, 4091–4093](https://doi.org/10.1021/acsnano.3c01544)) |
|	2.27	|	[Fighting ‘Woke AI,’ Musk Recruits Team to Develop OpenAI Rival](https://www.theinformation.com/articles/fighting-woke-ai-musk-recruits-team-to-develop-openai-rival)	|
| 2.25 | The Lancet - [The promise of large language models in health care](https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(23)00216-7/fulltext) |
| 2.25 | AugGPT: Leveraging ChatGPT for Text Data Augmentation ([:x:](https://arxiv.org/abs/2302.13007)), ([:paperclip:](https://arxiv.org/pdf/2302.13007.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2302.13007)) |
|	2.24	|	[Sam Altman, Planning for AGI and beyond](https://openai.com/blog/planning-for-agi-and-beyond)	|
|	2.24	|	[Meta: LLaMA](https://ai.facebook.com/blog/large-language-model-llama-meta-ai)	|
| 2.23 | Radiology - [ChatGPT and the Future of Medical Writing](https://pubs.rsna.org/doi/10.1148/radiol.223312) |
|	2.23	|	[Instagram co-founders launch AI-powered news app Artifact on Android, iOS](https://www.thehindubusinessline.com/info-tech/social-media/instagram-co-founders-launch-ai-powered-news-app-artifact-on-android-ios/article66543779.ece)	|
|	2.23	|	[Notion.AI launch](http://notion.ai/)	|
| 2.22 | The alignment problem from a deep learning perspective ([:x:](https://arxiv.org/abs/2209.00626)), ([:paperclip:](https://arxiv.org/pdf/2209.00626.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2209.00626))	|
|	2.22	|	[Microsoft: Bing announcement on mobile and Skype](https://blogs.microsoft.com/blog/2023/02/22/the-new-bing-preview-experience-arrives-on-bing-and-edge-mobile-apps-introducing-bing-now-in-skype)	|
|	2.22	|	Science - [As scientists explore AI-written text, journals hammer out policies](https://www.science.org/content/article/scientists-explore-ai-written-text-journals-hammer-policies)	|
| 2.21 | BadGPT: Exploring Security Vulnerabilities of ChatGPT via Backdoor Attacks to InstructGPT ([:x:](https://arxiv.org/abs/2304.12298)), ([:paperclip:](https://arxiv.org/pdf/2304.12298.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2304.12298))	|
| 2.21 | Hyena Hierarchy: Towards Larger Convolutional Language Models ([:x:](https://arxiv.org/abs/2302.10866)), ([:paperclip:](https://arxiv.org/pdf/2302.10866.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2302.10866))	|
|	2.21	|	[The PNAS Journals Outline Their Policies for ChatGPT and Generative AI](https://www.pnas.org/post/update/pnas-policy-for-chatgpt-generative-ai)	|
|	2.21	|	ChatGPT: Jack of all trades, master of none ([:x:](https://arxiv.org/abs/2302.10724)), ([:paperclip:](https://arxiv.org/pdf/2302.10724.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2302.10724))	|
| 2.20 | ChatGPT for Robotics: Design Principles and Model Abilities ([:x:](https://arxiv.org/abs/2306.17582)), ([:paperclip:](https://arxiv.org/pdf/2306.17582.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2306.17582)),  ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-survey-on-generative-diffusion-model)),  ([:octocat:](https://github.com/chq1155/A-Survey-on-Generative-Diffusion-Model)![GitHub Repo stars](https://img.shields.io/github/stars/chq1155/A-Survey-on-Generative-Diffusion-Model?style=social)) |
|	2.17	|	[Time, ChatGPT cover](https://time.com/6255952/ai-impact-chatgpt-microsoft-google/)	|
|	2.17	|	OpenAI, Foundry Product Brief	|
|	2.17	|	[Generative AI on Roblox: Our Vision for the Future of Creation](https://blog.roblox.com/2023/02/generative-ai-roblox-vision-future-creation/)	|
| 2.16 | Do We Still Need Clinical Language Models? ([:x:](https://arxiv.org/abs/2302.08091)), ([:paperclip:](https://arxiv.org/pdf/2302.08091.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2302.08091)) |
|	2.16	|	[Startup Replit launches a ChatGPT-like bot for coders](https://www.semafor.com/article/02/15/2023/startup-replit-launches-a-chatgpt-like-bot-for-coders)	|
|	2.15	|	[A&O announces exclusive launch partnership with Harvey](https://www.allenovery.com/en-gb/global/news-and-insights/news/ao-announces-exclusive-launch-partnership-with-harvey)	|
| 2.14 | What Is ChatGPT Doing … and Why Does It Work? ([Stephen Wolfram Writings](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)) |
|	2.14	|	1M ChatGPT plus user 	|
|	2.14	|	[The Gen AI Conference Hosted by Jasper](https://www.joingen.ai/)	|
|	2.13	|	[Google: Vision Transformer 22B](https://twitter.com/m__dehghani/status/1625186144001396737)	|
| 2.12 | Transformer models: an introduction and catalog ([:x:](https://arxiv.org/abs/2302.07730)), ([:paperclip:](https://arxiv.org/pdf/2302.07730.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2302.07730)), ([Blog](https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/)) |
|	2.10	|	[arXivGPT launches](https://news.ycombinator.com/item?id=34770108)	|
|	2.10	|	[OpenAI, ChatGPT plus announce (20$)](https://openai.com/blog/chatgpt-plus)	|
|	2.9	|	[Disastrous Chatbot Demo Costs Google $140 Billion](https://www.channelnews.com.au/google-shares-tank-after-disastrous-chatbot-demo/)	|
|	2.9	|	[Meta: Toolformer](https://arxiv.org/abs/2302.04761)	|
| 2.8 | A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity ([:x:](https://arxiv.org/abs/2302.04023)), ([:paperclip:](https://arxiv.org/pdf/2302.04023.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2302.04023)) | 
|	2.8	|	[Runway launches ground-breaking Gen-1 video generation AI system](https://www.ghacks.net/2023/02/08/runway-launches-ground-breaking-gen-1-video-generation-ai-system/)	|
|	2.7	|	[Microsoft: Bing ChatGPT](https://blogs.microsoft.com/blog/2023/02/07/reinventing-search-with-a-new-ai-powered-microsoft-bing-and-edge-your-copilot-for-the-web/)	|
|	2.7	|	[Getty Images sues AI art generator Stable Diffusion in the US for copyright infringement](https://www.theverge.com/2023/2/6/23587393/ai-art-copyright-lawsuit-getty-images-stable-diffusion)	|
| 2.6 | The Lancet - [ChatGPT: friend or foe?](https://www.thelancet.com/journals/landig/article/PIIS2589-7500%2823%2900023-7/fulltext) |
|	2.6	|	[Google: Bard announcement](https://blog.google/technology/ai/bard-google-ai-search-updates)	|
| 2.4 | Theory of Mind May Have Spontaneously Emerged in Large Language Models  ([:x:](https://arxiv.org/abs/2302.02083)), ([:paperclip:](https://arxiv.org/pdf/2302.02083.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2302.02083)) |
|	2.4	|	[POE.com open](http://poe.com/)	|
|	2.3	|	[Google invests in Anthropic, maker of ChatGPT rival](https://fortune.com/2023/02/04/google-invests-300m-anthropic-openai-rival-making-chatgpt-challenger-claude-ai-chatbot-battle/) 	|
|	2.3	|	Naver, SearchGPT announcement	|
| 2.2 | Creating a Large Language Model of a Philosopher ([:x:](https://arxiv.org/abs/2302.01339)), ([:paperclip:](https://arxiv.org/pdf/2302.01339.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2302.01339)) |
|	2.2	|	[ChatGPT reaches 100 million users two months after launch](https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-fastest-growing-app)	|
| 2.1 | The Diagnostic and Triage Accuracy of the GPT-3 Artificial Intelligence Model ([medrXiv](https://www.medrxiv.org/content/10.1101/2023.01.30.23285067v1 )|
|	2.1	|	[OpenAI, released a software tool to help identify text generated by AI](https://eandt.theiet.org/content/articles/2023/02/chatgpt-owner-launches-imperfect-tool-to-detect-ai-generated-text/)	|
|	1.31	|	[JAMA Network - Nonhuman “Authors” and Implications for the Integrity of Scientific Publication and Medical Knowledge](https://jamanetwork.com/journals/jama/fullarticle/2801170)	|
| 1.30 | SingSong: Generating musical accompaniments from singing ([:x:](https://arxiv.org/abs/2301.12662)), ([:paperclip:](https://arxiv.org/pdf/2301.12662.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2301.12662)), ([:octocat:](https://storage.googleapis.com/sing-song/index.html)) |
|	1.30	|	[China's biggest search engine is to set launch a ChatGPT rival in March](https://www.engadget.com/chinas-baidu-is-adding-a-chatgpt-type-bot-to-its-search-engine-110452638.html)	|
|	1.26	|	[Science Journal - ChatGPT is fun, but not an author](https://www.science.org/doi/10.1126/science.adg7879)	|
|	1.26	|	DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature ([:x:](https://arxiv.org/abs/2301.11305)), ([:paperclip:](https://arxiv.org/pdf/2301.11305.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2301.11305))	|
|	1.26	|	[ChatGPT Is Coming for Classrooms. Don't Panic](https://www.wired.com/story/chatgpt-is-coming-for-classrooms-dont-panic/)	|
|	1.26	|	[ChatGPT passes exams from law and business schools](https://edition.cnn.com/2023/01/26/tech/chatgpt-passes-exams/index.html)	|
|	1.26	|	[Google’s new AI turns text into music - MusicLM](https://google-research.github.io/seanet/musiclm/examples/)	|
| 1.24 | Putting ChatGPT's Medical Advice to the (Turing) Test ([:x:](https://arxiv.org/abs/2301.10035)), ([:paperclip:](https://arxiv.org/pdf/2301.10035.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2301.10035)) |
|	1.24	|	[Nature policy - Tools such as ChatGPT threaten transparent science; here are our ground rules for their use](https://www.nature.com/articles/d41586-023-00191-1)	|
|	1.20	|	[WAME policy - Chatbots, ChatGPT, and Scholarly Manuscripts](https://wame.org/page3.php?id=106)	|
|	1.17	|	[Meet Claude: Anthropic’s Rival to ChatGPT](https://scale.com/blog/chatgpt-vs-claude)	|
|	1.14	|	[Microsoft in talks to acquire a 49% stake in ChatGPT owner OpenAI](https://watcher.guru/news/microsoft-plans-to-acquire-a-49-stake-in-chatgpt-owner-openai)	|
| 1.12 | Multimodal Deep Learning ([:x:](https://arxiv.org/abs/2301.04856)), ([:paperclip:](https://arxiv.org/pdf/2301.04856.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2301.04856)) |
|	1.11	|	[This Voice Doesn't Exist - Generative Voice AI](https://blog.elevenlabs.io/enter-the-new-year-with-a-bang/)	|
|	1.9	|	[Microsoft is looking at OpenAI’s GPT for Word, Outlook, and PowerPoint](https://www.theverge.com/2023/1/9/23546144/microsoft-openai-word-powerpoint-outlook-gpt-integration-rumor)	|
|	1.5	|	[Apple launches AI-powered book narrations](https://techcrunch.com/2023/01/05/apple-launches-ai-powered-book-narrations/)	|
|	1.5	|	[Microsoft, VALL-E](https://valle-demo.github.io/)	|
|	1.4	|	[ICML conference responds to LLM ethics rule](https://venturebeat.com/ai/thats-so-meta-ml-conference-debates-use-of-chatgpt-in-papers/)	|
|	1.3	|	[Enter GPTZeo](https://twitter.com/edward_the6/status/1610067688449007618?ref_src=twsrc%5Etfw)	|
|	2023.01.01	|	Collected by Jonghong Jeon (hollobit@etri.re.kr)	|
|	12.29	|	GPT Takes the Bar Exam ([:x:](https://arxiv.org/abs/2212.14402)), ([:paperclip:](https://arxiv.org/pdf/2212.14402.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2212.14402))	|
|	12.27	|	[bioarXiv - Comparing scientific abstracts generated by ChatGPT to original abstracts using an artificial intelligence output detector, plagiarism detector, and blinded human reviewers](https://www.biorxiv.org/content/10.1101/2022.12.23.521610v1)	|
| 12. 15 | Constitutional AI: Harmlessness from AI Feedback ([:x:](https://arxiv.org/abs/2212.08073)), ([:paperclip:](https://arxiv.org/pdf/2212.08073.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2212.08073)), ([:house:](https://huggingface.co/papers/2212.08073)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/constitutional-ai-harmlessness-from-ai)), ([:octocat:](https://github.com/anthropics/constitutionalharmlessnesspaper)![GitHub Repo stars](https://img.shields.io/github/stars/anthropics/constitutionalharmlessnesspaper?style=social)) |
|	11.30	|	[OpenAI, ChatGPT service](https://openai.com/blog/chatgpt)	|
|	11.28	|	[NeurIPS 2022 conference](https://nips.cc/Conferences/2022)	|
| 11.21 | VectorFusion: Text-to-SVG by Abstracting Pixel-Based Diffusion Models ([:x:](https://arxiv.org/abs/2211.11319)), ([:paperclip:](https://arxiv.org/pdf/2211.11319.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2211.11319)), ([:house:](https://huggingface.co/papers/2211.11319)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/vectorfusion-text-to-svg-by-abstracting-pixel)), (CVPR 2023) |
|	11.17	|	[InstructPix2Pix: Learning to Follow Image Editing Instructions](https://arxiv.org/abs/2211.09800)	|
| 11.16 | Holistic Evaluation of Language Models ([:x:](https://arxiv.org/abs/2211.09110)), ([:paperclip:](https://arxiv.org/pdf/2211.09110.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2211.09110))	|
| 11.14 | Diffusion Models for Medical Image Analysis: A Comprehensive Survey ([:x:](https://arxiv.org/abs/2211.07804)), ([:paperclip:](https://arxiv.org/pdf/2211.07804.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2211.07804)),  ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/diffusion-models-for-medical-image-analysis-a)),  ([:octocat:](https://github.com/amirhossein-kz/awesome-diffusion-models-in-medical-imaging)![GitHub Repo stars](https://img.shields.io/github/stars/amirhossein-kz/awesome-diffusion-models-in-medical-imaging?style=social)) |
| 11.1 | MedSegDiff: Medical Image Segmentation with Diffusion Probabilistic Model ([:x:](https://arxiv.org/abs/2211.00611)), ([:paperclip:](https://arxiv.org/pdf/2211.00611.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2211.00611)),  ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/medsegdiff-medical-image-segmentation-with)),  ([:octocat:](https://github.com/wujunde/medsegdiff)![GitHub Repo stars](https://img.shields.io/github/stars/wujunde/medsegdiff?style=social)) |
|	10.30	|	[LlamaIndex (GPT Index) GitHub project](https://github.com/jerryjliu/llama_index)![GitHub Repo stars](https://img.shields.io/github/stars/jerryjliu/llama_index?style=social)	|
|	10.23	|	[LangChain GitHub project](https://github.com/hwchase17/langchain)![GitHub Repo stars](https://img.shields.io/github/stars/hwchase17/langchain?style=social)	|
| 9.27 | What Does DALL-E 2 Know About Radiology? ([JMIR](https://www.jmir.org/2023/1/e43110/)), ([:x:](https://arxiv.org/abs/2209.13696)), ([:paperclip:](https://arxiv.org/pdf/2209.13696.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2209.13696)), ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/what-does-dall-e-2-know-about-radiology)) |
|	9.19	|	[SEQUOIA - Generative AI: A Creative New World](https://www.sequoiacap.com/article/generative-ai-a-creative-new-world/)	|
| 9.15 | Brain Imaging Generation with Latent Diffusion Models [:x:](https://arxiv.org/abs/2209.07162)), ([:paperclip:](https://arxiv.org/pdf/2209.07162.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2209.07162)),  ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/brain-imaging-generation-with-latent)) |
| 9.6 | A Survey on Generative Diffusion Model ([:x:](https://arxiv.org/abs/2209.02646)), ([:paperclip:](https://arxiv.org/pdf/2209.02646.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2209.02646)),  ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/a-survey-on-generative-diffusion-model)),  ([:octocat:](https://github.com/chq1155/A-Survey-on-Generative-Diffusion-Model)![GitHub Repo stars](https://img.shields.io/github/stars/chq1155/A-Survey-on-Generative-Diffusion-Model?style=social)) |
| 8.25 | Understanding Diffusion Models: A Unified Perspective ([:x:](https://arxiv.org/abs/2208.11970)), ([:paperclip:](https://arxiv.org/pdf/2208.11970.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2208.11970)), ([Blog](https://calvinyluo.com/2022/08/26/diffusion-tutorial.html)) |
| 7.4 | Shifting machine learning for healthcare from development to deployment and from models to data (nature biomedical engineering, [https://doi.org/10.1038/s41551-022-00898-y](https://www.nature.com/articles/s41551-022-00898-y)), ([PDF](https://www.nature.com/articles/s41551-022-00898-y.pdf)) |
| 3.29 | Training Compute-Optimal Large Language Models  ([:x:](https://arxiv.org/abs/2303.15556)), ([:paperclip:](https://arxiv.org/pdf/2303.15556.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2303.15556)), ([:house:](https://huggingface.co/papers/2303.15556)) |
|	3.15	|	OpenAI, GPT 3.5 announce	|
| 2.11 | Compute Trends Across Three Eras of Machine Learning ([:x:](https://arxiv.org/abs/2202.05924)), ([:paperclip:](https://arxiv.org/pdf/2202.05924.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2202.05924)) |
| 2022.01.01 | |
| 8.16 | On the Opportunities and Risks of Foundation Models ([:x:](https://arxiv.org/abs/2108.07258)), ([:paperclip:](https://arxiv.org/pdf/2108.07258.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2108.07258)),  ([:eight_spoked_asterisk:](https://paperswithcode.com/paper/on-the-opportunities-and-risks-of-foundation)) |
| 6.15 | Synthetic data in machine learning for medicine and healthcare (nature biomedical engineering, [https://doi.org/10.1038/s41551-021-00751-8](https://www.nature.com/articles/s41551-021-00751-8)), ([PDF](https://www.nature.com/articles/s41551-021-00751-8.pdf?pdf=button%20sticky)) |
| 4.18 | The Power of Scale for Parameter-Efficient Prompt Tuning ([:x:](https://arxiv.org/abs/2104.08691)), ([:paperclip:](https://arxiv.org/pdf/2104.08691.pdf)), ([:orange_book:](https://www.arxiv-vanity.com/papers/2104.08691))
| 2021.01.01 | | 
|		|	**Last Modified 2023/07/03 PM19:40** KST	|

## Additional Links
* [LLM-evaluation](https://github.com/Hannibal046/Awesome-LLM/blob/main/paper_list/evaluation.md)
* [Awesome-LLM](https://github.com/Hannibal046/Awesome-LLM)![GitHub Repo stars](https://img.shields.io/github/stars/Hannibal046/Awesome-LLM?style=social)
* [Examples and guides for using the OpenAI API](https://github.com/openai/openai-cookbook)![GitHub Repo stars](https://img.shields.io/github/stars/openai/openai-cookbook?style=social)
* [Ultimate-Awesome-Transformer-Attention](https://github.com/cmhungsteve/Awesome-Transformer-Attention)![GitHub Repo stars](https://img.shields.io/github/stars/cmhungsteve/Awesome-Transformer-Attention?style=social)
* [Awesome Segment Anything](https://github.com/Hedlen/awesome-segment-anything)![GitHub Repo stars](https://img.shields.io/github/stars/Hedlen/awesome-segment-anything?style=social)
* [Segment Anything Model (SAM) for Medical Image Segmentation](https://github.com/YichiZhang98/SAM4MIS)![GitHub Repo stars](https://img.shields.io/github/stars/YichiZhang98/SAM4MIS?style=social)
* [GPT-4登場以降に出てきたChatGPT/LLMに関する論文や技術の振り返り](https://blog.brainpad.co.jp/entry/2023/06/05/153034) 
* [LLM Collection](https://www.promptingguide.ai/models/collection)
* [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
* [AI Incident Database](https://incidentdatabase.ai/)
* [Daily papers by AK](https://huggingface.co/papers)
* [Awesome-Generative-RecSys](https://github.com/jihoo-kim/Awesome-Generative-RecSys)![GitHub Repo stars](https://img.shields.io/github/stars/jihoo-kim/Awesome-Generative-RecSys?style=social) - A curated list of Generative Recommender Systems (Paper & Code)
* [Prompt Engineering Guide](https://www.promptingguide.ai/) - [papers](https://www.promptingguide.ai/papers) - [:octocat:](https://github.com/dair-ai/Prompt-Engineering-Guide)![GitHub Repo stars](https://img.shields.io/github/stars/dair-ai/Prompt-Engineering-Guide?style=social)
* [awesome-ChatGPT-repositories](https://github.com/taishi-i/awesome-ChatGPT-repositories)![GitHub Repo stars](https://img.shields.io/github/stars/taishi-i/awesome-ChatGPT-repositories?style=social) 
* [The Rundown](https://www.therundown.ai/)
* [WEEKLY PAPERS](https://papers.labml.ai/papers/weekly)
* [Primo.ai LLM wiki](https://primo.ai/index.php?title=Large_Language_Model_(LLM))
* [ML Papers of the Week](https://github.com/dair-ai/ML-Papers-of-the-Week)![GitHub Repo stars](https://img.shields.io/github/stars/dair-ai/ML-Papers-of-the-Week?style=social)
* [CS 324 - Advances in Foundation Models](https://stanford-cs324.github.io/winter2023/)
* [ML timeline](https://github.com/osanseviero/ml_timeline)![GitHub Repo stars](https://img.shields.io/github/stars/osanseviero/ml_timeline?style=social)
* [ChatGPT Timeline](https://timelines.issarice.com/wiki/Timeline_of_ChatGPT)
* [OpenAI Timeline](https://www.jointjs.com/demos/chatgpt-timeline)
* [Generative Artificial Intelligence Stack Language](https://www.reddit.com/r/AILinksandTools/comments/126z1pd/the_generative_ai_tech_stack_for_language_march/)
<img src="https://i.redd.it/r2kr7trwwxqa1.png">
* [Awesome-Multimodal-Large-Language-Models](https://github.com/bradyfu/awesome-multimodal-large-language-models)
<img src="https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/blob/main/images/xmind.png?raw=true">
* [SEQUOIA - The New Language Model Stack](https://www.sequoiacap.com/article/llm-stack-perspective/)
<img src="https://www.sequoiacap.com/wp-content/uploads/sites/6/2023/06/llm-landscape-9.png">
* The Rise and Rise of A.I. LLMs
<img src="https://pbs.twimg.com/media/FwTUtyKacAAgQbQ?format=jpg&name=large">
* [The Practical Guides for Large Language Models](https://github.com/Mooler0410/LLMsPracticalGuide)
<img src="https://github.com/Mooler0410/LLMsPracticalGuide/blob/main/imgs/survey-gif-test.gif">
* [AI / ML / LLM / Transformer Models Timeline](https://ai.v-gar.de/ml/transformer/timeline/) 
<img src="https://ai.v-gar.de/ml/transformer/timeline/timeline.png">
* [Transformer models: an introduction and catalog — 2023 Edition](https://amatriain.net/blog/transformer-models-an-introduction-and-catalog-2d1e9039f376/)
<img src="https://amatriain.net/blog/images/02-05.png" bgcolor=white>
<img src="https://amatriain.net/blog/images/02-09.png">
* [open-source LLMs](https://twitter.com/theaievangelist/status/1645809824314298368)
<img src="https://pbs.twimg.com/media/FtZQSU3aMAI4BP1?format=jpg&name=4096x4096">
* Got It AI’s LLM hallucination rate comparison
<img src="https://lh5.googleusercontent.com/cgHE-XSe8AZBUuFIQw-Vu6XqYFxvKWj5BjCPsWAxkre2G8WLLkVLhp0DyDTlSTYFQiUyG_XUvZU2ZtM212SuU9rfbNxEtQI0kEpm8sSKF7CUsJZpu0pY9FaT2qHVpPgrBRLeJZdsdyBaKMw5Tac8M7Y">
* [A summary of large language models (A Survey of Large Language Models)](https://arxiv.org/abs/2303.18223)
 <img src="https://github.com/hollobit/GenAI_LLM_timeline/assets/998803/9a855dea-7223-4523-924e-3952b1f3734d">
* [A history of the most important ge![Uploading 스크린샷 2023-05-18 오후 5.58.51.png…]()
nerative AI models, from 2014 to 2023 @davidtfoster](https://www.linkedin.com/feed/update/urn:li:activity:7044233450295316480/)
 <img src="https://github.com/hollobit/GenAI_LLM_timeline/assets/998803/09140224-638f-448c-a990-1201741927c7">
